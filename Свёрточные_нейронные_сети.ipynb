{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Свёрточные нейронные сети.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyPxzMgvSzQZrkwfD6ZUVtzr",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Compling/blob/master/%D0%A1%D0%B2%D1%91%D1%80%D1%82%D0%BE%D1%87%D0%BD%D1%8B%D0%B5_%D0%BD%D0%B5%D0%B9%D1%80%D0%BE%D0%BD%D0%BD%D1%8B%D0%B5_%D1%81%D0%B5%D1%82%D0%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AY3YULfsp5de",
        "colab_type": "code",
        "outputId": "14065240-d066-4ee3-ca6c-855bb906100e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "!unzip data.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  data.zip\n",
            "replace quora.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: "
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Um9BHtjPtj8d",
        "colab_type": "code",
        "outputId": "b295741b-7140-417a-84b3-a1068a0da2f2",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 221
        }
      },
      "source": [
        "!pip install pandas scikit-learn matplotlib"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (1.0.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (0.22.2.post1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.6/dist-packages (3.2.1)\n",
            "Requirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.6/dist-packages (from pandas) (1.18.3)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from pandas) (2.8.1)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (0.14.1)\n",
            "Requirement already satisfied: scipy>=0.17.0 in /usr/local/lib/python3.6/dist-packages (from scikit-learn) (1.4.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (0.10.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (1.2.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.6/dist-packages (from matplotlib) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.6.1->pandas) (1.12.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p1vaM-j6uLz8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BBE3I8SyuPe5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from string import punctuation\n",
        "from sklearn.model_selection import train_test_split\n",
        "from collections import Counter\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lj0cKSnbu1SJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import backend as K\n",
        "def f1(y_true, y_pred):\n",
        "    def recall(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "        recall = true_positives / (possible_positives + K.epsilon())\n",
        "        return recall\n",
        "\n",
        "    def precision(y_true, y_pred):\n",
        "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "        precision = true_positives / (predicted_positives + K.epsilon())\n",
        "        return precision\n",
        "    precision = precision(y_true, y_pred)\n",
        "    recall = recall(y_true, y_pred)\n",
        "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmZokSeEvAJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "quora = pd.read_csv('quora.csv')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q5LWLwqgvj4s",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab = Counter()\n",
        "\n",
        "for sym in quora.question_text:\n",
        "    sym = sym.lower()\n",
        "    vocab.update(sym)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4eOdhPDcvQoV",
        "colab_type": "code",
        "outputId": "08b983b0-482e-43f0-e79b-bb5ed445f20b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(vocab)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1949"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HtaFscBCza7T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_vocab = set()\n",
        "\n",
        "for sym in vocab:\n",
        "    if vocab[sym] > 5:\n",
        "        filtered_vocab.add(sym)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9BzFywgpzxRY",
        "colab_type": "code",
        "outputId": "be6ee66f-61c0-4115-ec02-cea0bef95229",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "len(filtered_vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "413"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tusyAD7Oz3uj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sym2id = {'UNK':1, 'PAD':0}\n",
        "\n",
        "for sym in filtered_vocab:\n",
        "    sym2id[sym] = len(sym2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UPhbKBVZ0oLm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "id2sym = {i:sym for sym, i in sym2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lVrjgYdt1bKE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = []\n",
        "\n",
        "for text in quora.question_text:\n",
        "    text = text.lower()\n",
        "    ids = [sym2id.get(sym, 1) for sym in text]\n",
        "    X.append(ids)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aHr4RhuR2q28",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = max(len(x) for x in X)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Mtx6vwbtccm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MEAN_LEN = np.median([len(x) for x in X])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib8f3eYAtgXD",
        "colab_type": "code",
        "outputId": "3a680404-8f73-4839-c934-4e78cc58d7a3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "MAX_LEN, MEAN_LEN"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1017, 60.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JLZ8Z3xNT_II",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = 200"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1-yy_f7BuAzN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=MAX_LEN)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "04aqmoVtuJpx",
        "colab_type": "code",
        "outputId": "a7467793-d49d-4c19-9f76-6b7d94f9f8f9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X.shape"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1306122, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2iRkbW7kvlJ3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y = quora.target.values"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tVM0oRXnv7yX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.05, stratify=y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YrfjvunKzFzh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "checkpoint = tf.keras.callbacks.ModelCheckpoint('model.weights', \n",
        "                                                monitor='val_f1',\n",
        "                                                verbose=1,\n",
        "                                                save_weights_only=True,\n",
        "                                                save_best_only=True,\n",
        "                                                mode='max',\n",
        "                                                save_freq='epoch'\n",
        "                                               )\n",
        "\n",
        "early_stop = tf.keras.callbacks.EarlyStopping(monitor='val_f1', \n",
        "                                              min_delta=0.01,\n",
        "                                              patience=20,\n",
        "                                              verbose=1, \n",
        "                                              mode='max',\n",
        "                                              )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTis-bjE9UU0",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(sym2id), output_dim=10)(inputs)\n",
        "drop1 = tf.keras.layers.Dropout(0.3)(embeddings)\n",
        "conv1 = tf.keras.layers.Conv1D(kernel_size=16, filters=128, strides=1, \n",
        "                                               kernel_regularizer='l2',\n",
        "                                              activation='relu')(embeddings)\n",
        "conv2 = tf.keras.layers.Conv1D(kernel_size=32, filters=128, strides=2, \n",
        "                                               kernel_regularizer='l2',\n",
        "                                              activation='relu')(conv1)\n",
        "\n",
        "drop2 = tf.keras.layers.Dropout(0.5)(conv2)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(drop2)\n",
        "dense = tf.keras.layers.Dense(50, activation='relu')(flatten)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ypBK99Nh-ZEQ",
        "colab_type": "code",
        "outputId": "d786f8ab-cb76-4e32-c41e-ef95477fe6ed",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=2000,\n",
        "          epochs=10,\n",
        "          callbacks=[checkpoint, early_stop])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.2484 - f1: 2.4966e-05\n",
            "Epoch 00001: val_f1 improved from -inf to 0.00000, saving model to model.weights\n",
            "621/621 [==============================] - 340s 548ms/step - loss: 0.2484 - f1: 2.4966e-05 - val_loss: 0.2113 - val_f1: 0.0000e+00\n",
            "Epoch 2/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.2054 - f1: 0.0000e+00\n",
            "Epoch 00002: val_f1 did not improve from 0.00000\n",
            "621/621 [==============================] - 337s 542ms/step - loss: 0.2054 - f1: 0.0000e+00 - val_loss: 0.1991 - val_f1: 0.0000e+00\n",
            "Epoch 3/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1946 - f1: 0.0000e+00\n",
            "Epoch 00003: val_f1 did not improve from 0.00000\n",
            "621/621 [==============================] - 335s 539ms/step - loss: 0.1946 - f1: 0.0000e+00 - val_loss: 0.1905 - val_f1: 0.0000e+00\n",
            "Epoch 4/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1871 - f1: 0.0366\n",
            "Epoch 00004: val_f1 improved from 0.00000 to 0.08279, saving model to model.weights\n",
            "621/621 [==============================] - 333s 537ms/step - loss: 0.1871 - f1: 0.0366 - val_loss: 0.1831 - val_f1: 0.0828\n",
            "Epoch 5/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1821 - f1: 0.1402\n",
            "Epoch 00005: val_f1 did not improve from 0.08279\n",
            "621/621 [==============================] - 333s 537ms/step - loss: 0.1821 - f1: 0.1402 - val_loss: 0.1840 - val_f1: 0.0698\n",
            "Epoch 6/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1773 - f1: 0.2010\n",
            "Epoch 00006: val_f1 improved from 0.08279 to 0.25316, saving model to model.weights\n",
            "621/621 [==============================] - 333s 537ms/step - loss: 0.1773 - f1: 0.2010 - val_loss: 0.1719 - val_f1: 0.2532\n",
            "Epoch 7/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1725 - f1: 0.2607\n",
            "Epoch 00007: val_f1 improved from 0.25316 to 0.31499, saving model to model.weights\n",
            "621/621 [==============================] - 333s 536ms/step - loss: 0.1725 - f1: 0.2607 - val_loss: 0.1672 - val_f1: 0.3150\n",
            "Epoch 8/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1689 - f1: 0.3002\n",
            "Epoch 00008: val_f1 improved from 0.31499 to 0.38043, saving model to model.weights\n",
            "621/621 [==============================] - 332s 535ms/step - loss: 0.1689 - f1: 0.3002 - val_loss: 0.1675 - val_f1: 0.3804\n",
            "Epoch 9/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1677 - f1: 0.3214\n",
            "Epoch 00009: val_f1 did not improve from 0.38043\n",
            "621/621 [==============================] - 332s 535ms/step - loss: 0.1677 - f1: 0.3214 - val_loss: 0.1638 - val_f1: 0.3134\n",
            "Epoch 10/10\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1638 - f1: 0.3459\n",
            "Epoch 00010: val_f1 did not improve from 0.38043\n",
            "621/621 [==============================] - 332s 534ms/step - loss: 0.1638 - f1: 0.3459 - val_loss: 0.1609 - val_f1: 0.3394\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f92e05421d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FIA5qsXh895J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "inputs = tf.keras.layers.Input(shape=(MAX_LEN,))\n",
        "\n",
        "embeddings = tf.keras.layers.Embedding(input_dim=len(sym2id), output_dim=10)(inputs)\n",
        "conv1 = tf.keras.layers.Conv1D(kernel_size=16, filters=128, strides=1, kernel_regularizer='l2', activation='relu')(embeddings)\n",
        "conv2 = tf.keras.layers.Conv1D(kernel_size=32, filters=128, strides=2, kernel_regularizer='l2', activation='relu')(conv1)\n",
        "pool1 = tf.keras.layers.AveragePooling1D()(conv2)\n",
        "drop1 = tf.keras.layers.Dropout(0.1)(pool1)\n",
        "conv3 = tf.keras.layers.Conv1D(kernel_size=64, filters=32)(embeddings)\n",
        "conv4 = tf.keras.layers.Conv1D(kernel_size=32, filters=32, strides=1)(conv3)\n",
        "conv5 = tf.keras.layers.Conv1D(kernel_size=32, filters=32, strides=1, activation='relu')(conv4)\n",
        "pool2 = tf.keras.layers.AveragePooling1D()(conv5)\n",
        "conv6 = tf.keras.layers.Conv1D(kernel_size=32, filters=32, strides=2)(embeddings)\n",
        "conv7 = tf.keras.layers.Conv1D(kernel_size=32, filters=32, strides=2, activation='relu')(conv6)\n",
        "conv8 = tf.keras.layers.Conv1D(kernel_size=27, filters=32, strides=1, kernel_regularizer='l2')(conv7)\n",
        "drop2 = tf.keras.layers.Dropout(0.2)(conv8)\n",
        "conv9 = tf.keras.layers.Conv1D(kernel_size=32, filters=32, strides=1, kernel_regularizer='l2', activation='relu')(embeddings)\n",
        "conv10 = tf.keras.layers.Conv1D(kernel_size=16, filters=32, padding='same',strides=1)(conv9)\n",
        "conv11 = tf.keras.layers.Conv1D(kernel_size=32, filters=16, strides=3)(conv10)\n",
        "conv12 = tf.keras.layers.Conv1D(kernel_size=16, filters=8, strides=2)(conv11)\n",
        "drop3 = tf.keras.layers.Dropout(0.3)(conv12)\n",
        "\n",
        "flatten = tf.keras.layers.Flatten()(drop3)\n",
        "dense = tf.keras.layers.Dense(50, activation='relu')(flatten)\n",
        "outputs = tf.keras.layers.Dense(1, activation='sigmoid')(dense)\n",
        "\n",
        "model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n",
        "model.compile(optimizer=optimizer,\n",
        "              loss='binary_crossentropy',\n",
        "              metrics=[f1])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "diKN0eDqPV4k",
        "colab_type": "code",
        "outputId": "1d09337b-c0e2-4bd2-dc65-f23b8e2be30d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "model.fit(X_train, y_train, \n",
        "          validation_data=(X_valid, y_valid),\n",
        "          batch_size=2000,\n",
        "          epochs=40,\n",
        "          callbacks=[checkpoint, early_stop])"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.2379 - f1: 0.0010\n",
            "Epoch 00001: val_f1 did not improve from 0.14673\n",
            "621/621 [==============================] - 24s 39ms/step - loss: 0.2379 - f1: 0.0010 - val_loss: 0.2047 - val_f1: 4.9677e-04\n",
            "Epoch 2/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1970 - f1: 0.0266\n",
            "Epoch 00002: val_f1 did not improve from 0.14673\n",
            "621/621 [==============================] - 21s 34ms/step - loss: 0.1970 - f1: 0.0266 - val_loss: 0.1883 - val_f1: 0.0758\n",
            "Epoch 3/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1867 - f1: 0.1441\n",
            "Epoch 00003: val_f1 did not improve from 0.14673\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1867 - f1: 0.1441 - val_loss: 0.1840 - val_f1: 0.1235\n",
            "Epoch 4/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1805 - f1: 0.2138\n",
            "Epoch 00004: val_f1 improved from 0.14673 to 0.20848, saving model to model.weights\n",
            "621/621 [==============================] - 26s 42ms/step - loss: 0.1805 - f1: 0.2138 - val_loss: 0.1784 - val_f1: 0.2085\n",
            "Epoch 5/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1772 - f1: 0.2430\n",
            "Epoch 00005: val_f1 improved from 0.20848 to 0.24252, saving model to model.weights\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1772 - f1: 0.2430 - val_loss: 0.1765 - val_f1: 0.2425\n",
            "Epoch 6/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1754 - f1: 0.2544\n",
            "Epoch 00006: val_f1 improved from 0.24252 to 0.28717, saving model to model.weights\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1754 - f1: 0.2544 - val_loss: 0.1745 - val_f1: 0.2872\n",
            "Epoch 7/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1745 - f1: 0.2593\n",
            "Epoch 00007: val_f1 did not improve from 0.28717\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1745 - f1: 0.2593 - val_loss: 0.1811 - val_f1: 0.1376\n",
            "Epoch 8/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1734 - f1: 0.2650\n",
            "Epoch 00008: val_f1 improved from 0.28717 to 0.29484, saving model to model.weights\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1734 - f1: 0.2650 - val_loss: 0.1740 - val_f1: 0.2948\n",
            "Epoch 9/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1726 - f1: 0.2716\n",
            "Epoch 00009: val_f1 improved from 0.29484 to 0.32761, saving model to model.weights\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1726 - f1: 0.2716 - val_loss: 0.1734 - val_f1: 0.3276\n",
            "Epoch 10/40\n",
            "619/621 [============================>.] - ETA: 0s - loss: 0.1721 - f1: 0.2717\n",
            "Epoch 00010: val_f1 did not improve from 0.32761\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1721 - f1: 0.2712 - val_loss: 0.1730 - val_f1: 0.2080\n",
            "Epoch 11/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1718 - f1: 0.2710\n",
            "Epoch 00011: val_f1 did not improve from 0.32761\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1718 - f1: 0.2710 - val_loss: 0.1729 - val_f1: 0.2493\n",
            "Epoch 12/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1715 - f1: 0.2749\n",
            "Epoch 00012: val_f1 did not improve from 0.32761\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1715 - f1: 0.2747 - val_loss: 0.1764 - val_f1: 0.1911\n",
            "Epoch 13/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1711 - f1: 0.2796\n",
            "Epoch 00013: val_f1 improved from 0.32761 to 0.33586, saving model to model.weights\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1711 - f1: 0.2796 - val_loss: 0.1727 - val_f1: 0.3359\n",
            "Epoch 14/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1709 - f1: 0.2803\n",
            "Epoch 00014: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1709 - f1: 0.2803 - val_loss: 0.1729 - val_f1: 0.2473\n",
            "Epoch 15/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1705 - f1: 0.2811\n",
            "Epoch 00015: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1705 - f1: 0.2811 - val_loss: 0.1739 - val_f1: 0.2252\n",
            "Epoch 16/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1704 - f1: 0.2792\n",
            "Epoch 00016: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1704 - f1: 0.2792 - val_loss: 0.1732 - val_f1: 0.3045\n",
            "Epoch 17/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1705 - f1: 0.2819\n",
            "Epoch 00017: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1705 - f1: 0.2819 - val_loss: 0.1742 - val_f1: 0.2436\n",
            "Epoch 18/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1700 - f1: 0.2835\n",
            "Epoch 00018: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1700 - f1: 0.2835 - val_loss: 0.1746 - val_f1: 0.3095\n",
            "Epoch 19/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1702 - f1: 0.2842\n",
            "Epoch 00019: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1702 - f1: 0.2843 - val_loss: 0.1755 - val_f1: 0.2423\n",
            "Epoch 20/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1698 - f1: 0.2848\n",
            "Epoch 00020: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1698 - f1: 0.2848 - val_loss: 0.1734 - val_f1: 0.3246\n",
            "Epoch 21/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1699 - f1: 0.2817\n",
            "Epoch 00021: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 24s 39ms/step - loss: 0.1699 - f1: 0.2817 - val_loss: 0.1727 - val_f1: 0.2958\n",
            "Epoch 22/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1699 - f1: 0.2857\n",
            "Epoch 00022: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1699 - f1: 0.2857 - val_loss: 0.1741 - val_f1: 0.2293\n",
            "Epoch 23/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1697 - f1: 0.2856\n",
            "Epoch 00023: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1697 - f1: 0.2856 - val_loss: 0.1748 - val_f1: 0.2936\n",
            "Epoch 24/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1696 - f1: 0.2879\n",
            "Epoch 00024: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1696 - f1: 0.2879 - val_loss: 0.1740 - val_f1: 0.2987\n",
            "Epoch 25/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1697 - f1: 0.2857\n",
            "Epoch 00025: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 24s 39ms/step - loss: 0.1697 - f1: 0.2857 - val_loss: 0.1729 - val_f1: 0.2723\n",
            "Epoch 26/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1700 - f1: 0.2837\n",
            "Epoch 00026: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1700 - f1: 0.2837 - val_loss: 0.1742 - val_f1: 0.3091\n",
            "Epoch 27/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1693 - f1: 0.2878\n",
            "Epoch 00027: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1693 - f1: 0.2878 - val_loss: 0.1739 - val_f1: 0.3098\n",
            "Epoch 28/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1695 - f1: 0.2858\n",
            "Epoch 00028: val_f1 did not improve from 0.33586\n",
            "621/621 [==============================] - 26s 42ms/step - loss: 0.1695 - f1: 0.2858 - val_loss: 0.1746 - val_f1: 0.2669\n",
            "Epoch 29/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1696 - f1: 0.2855\n",
            "Epoch 00029: val_f1 improved from 0.33586 to 0.34825, saving model to model.weights\n",
            "621/621 [==============================] - 24s 39ms/step - loss: 0.1696 - f1: 0.2855 - val_loss: 0.1740 - val_f1: 0.3482\n",
            "Epoch 30/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1691 - f1: 0.2892\n",
            "Epoch 00030: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 21s 35ms/step - loss: 0.1691 - f1: 0.2892 - val_loss: 0.1734 - val_f1: 0.2964\n",
            "Epoch 31/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1695 - f1: 0.2861\n",
            "Epoch 00031: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1695 - f1: 0.2860 - val_loss: 0.1737 - val_f1: 0.3072\n",
            "Epoch 32/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1693 - f1: 0.2878\n",
            "Epoch 00032: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1693 - f1: 0.2878 - val_loss: 0.1734 - val_f1: 0.2467\n",
            "Epoch 33/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1691 - f1: 0.2908\n",
            "Epoch 00033: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1691 - f1: 0.2908 - val_loss: 0.1740 - val_f1: 0.3207\n",
            "Epoch 34/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1692 - f1: 0.2905\n",
            "Epoch 00034: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 21s 35ms/step - loss: 0.1692 - f1: 0.2905 - val_loss: 0.1734 - val_f1: 0.3040\n",
            "Epoch 35/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1691 - f1: 0.2915\n",
            "Epoch 00035: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 26s 42ms/step - loss: 0.1691 - f1: 0.2915 - val_loss: 0.1733 - val_f1: 0.3052\n",
            "Epoch 36/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1691 - f1: 0.2929\n",
            "Epoch 00036: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 26s 41ms/step - loss: 0.1691 - f1: 0.2929 - val_loss: 0.1736 - val_f1: 0.2988\n",
            "Epoch 37/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1691 - f1: 0.2928\n",
            "Epoch 00037: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 25s 40ms/step - loss: 0.1691 - f1: 0.2928 - val_loss: 0.1726 - val_f1: 0.2990\n",
            "Epoch 38/40\n",
            "621/621 [==============================] - ETA: 0s - loss: 0.1691 - f1: 0.2888\n",
            "Epoch 00038: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 22s 35ms/step - loss: 0.1691 - f1: 0.2888 - val_loss: 0.1734 - val_f1: 0.3063\n",
            "Epoch 39/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1690 - f1: 0.2934\n",
            "Epoch 00039: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 26s 42ms/step - loss: 0.1690 - f1: 0.2937 - val_loss: 0.1732 - val_f1: 0.3067\n",
            "Epoch 40/40\n",
            "620/621 [============================>.] - ETA: 0s - loss: 0.1689 - f1: 0.2953\n",
            "Epoch 00040: val_f1 did not improve from 0.34825\n",
            "621/621 [==============================] - 25s 41ms/step - loss: 0.1689 - f1: 0.2952 - val_loss: 0.1739 - val_f1: 0.2699\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f52d82724a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zNb-1jNYMisJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 493
        },
        "outputId": "dfe339a1-db82-4082-ed92-b5a2779fcb22"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_4\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_6 (InputLayer)         [(None, 200)]             0         \n",
            "_________________________________________________________________\n",
            "embedding_5 (Embedding)      (None, 200, 10)           4150      \n",
            "_________________________________________________________________\n",
            "conv1d_62 (Conv1D)           (None, 169, 32)           10272     \n",
            "_________________________________________________________________\n",
            "conv1d_63 (Conv1D)           (None, 138, 32)           32800     \n",
            "_________________________________________________________________\n",
            "dropout_17 (Dropout)         (None, 138, 32)           0         \n",
            "_________________________________________________________________\n",
            "conv1d_64 (Conv1D)           (None, 138, 32)           16416     \n",
            "_________________________________________________________________\n",
            "conv1d_65 (Conv1D)           (None, 36, 16)            16400     \n",
            "_________________________________________________________________\n",
            "flatten_4 (Flatten)          (None, 576)               0         \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 50)                28850     \n",
            "_________________________________________________________________\n",
            "dense_9 (Dense)              (None, 1)                 51        \n",
            "=================================================================\n",
            "Total params: 108,939\n",
            "Trainable params: 108,939\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}