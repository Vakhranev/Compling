{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Копия блокнота \"Homework 2.ipynb\"",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Compling/blob/master/Vakhranev_AY_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PauhqetfmwFy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "586e7c1c-c810-4666-c8d2-8e4e3bfde585"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from data import Downloader, Parser"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-27 20:42:07--  https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10563 (10K) [text/plain]\n",
            "Saving to: ‘data.py’\n",
            "\n",
            "data.py             100%[===================>]  10.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-12-27 20:42:08 (106 MB/s) - ‘data.py’ saved [10563/10563]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkj-KkyFmwGE"
      },
      "source": [
        "### Загружаем файл с эмбеддингами для английского языка\n",
        "Они нам понадобятся чуть позже.  \n",
        "Для других языков можете найти здесь: https://fasttext.cc/docs/en/crawl-vectors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_lth05VmwGG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d32832ac-b328-4bd1-db39-a9b11d53ecdc"
      },
      "source": [
        "# раскомментируйте и скачайте\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-12-27 20:42:11--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 172.67.9.4, 104.22.74.142, 104.22.75.142, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|172.67.9.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  27.0MB/s    in 25s     \n",
            "\n",
            "2020-12-27 20:42:37 (26.3 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1bwsmP5mwGV"
      },
      "source": [
        "# путь к данным\n",
        "data_path = './data/'"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_ThM59tmwGh"
      },
      "source": [
        "### Читалка данные\n",
        "Не стоит вдаваться в подробности, просто эта штука скачивает данные, затем парсит и делает из них три датасета:\n",
        "- тренировочный\n",
        "- валидационный\n",
        "- неразмеченный\n",
        "\n",
        "Неразмеченные данные необазятельны, но могут вам понадобиться, например, для языковой модели или улучшения эмбеддингов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAp_0GoumwGj"
      },
      "source": [
        "downloader = Downloader(data_path=data_path)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4PXrpMymwGw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5e8a95fa-58d9-42ed-f951-6fe3c0c0b0d2"
      },
      "source": [
        "downloader.run()"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "single: 100%|██████████| 21/21 [00:15<00:00,  1.36it/s]\n",
            "multiple: 100%|██████████| 17/17 [00:18<00:00,  1.08s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzGKfthjmwG8"
      },
      "source": [
        "parser = Parser(data_path=data_path)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g7DkPr1mwHG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "767b6a25-2459-4ee9-e3db-e4d38b426323"
      },
      "source": [
        "unlabeled, train, valid = parser.run()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading: 100%|██████████| 38/38 [02:34<00:00,  4.07s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z9fJ3trmwHW"
      },
      "source": [
        "### Посмотрим на датасеты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOb7ee6emwHY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "0a2bb070-421b-495c-acd6-99abadc1ff04"
      },
      "source": [
        "unlabeled"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>has anyone used wagner thermoquiets, how do th...</td>\n",
              "      <td>installed on my 96 acorrd for aprox.10k and th...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>are these good for nighttime?  my son is fully...</td>\n",
              "      <td>i only used them at night, but for a younger b...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is there a gelatin in it?</td>\n",
              "      <td>the label does not mention the capsule content...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>does it work on motorcycle tires as well and s...</td>\n",
              "      <td>if the valve steam has the same dimension than...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>does it fit most standard snowmobiles ? (examp...</td>\n",
              "      <td>i am unable to say for sure if it will fit the...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137275</th>\n",
              "      <td>does this product scan to a pdf?  does it scan...</td>\n",
              "      <td>it will scan to pdf or jpg.  it does scan from...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137276</th>\n",
              "      <td>how far does the flipper stick out when closed...</td>\n",
              "      <td>the flipper sticks out 5/16\". i don't own the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137277</th>\n",
              "      <td>hi... does this phone works in 1900 mhz 3g ban...</td>\n",
              "      <td>dear rixio, sorry but this phone ido not work ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137278</th>\n",
              "      <td>i recently purchased a shadow billet grill tha...</td>\n",
              "      <td>i'm not really sure.unless that particular gri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137279</th>\n",
              "      <td>what are the dimensions of the air compressor ...</td>\n",
              "      <td>from the slime website...4.75&amp;#8243;h x 3.875&amp;...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137280 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question                                           response\n",
              "0       has anyone used wagner thermoquiets, how do th...  installed on my 96 acorrd for aprox.10k and th...\n",
              "1       are these good for nighttime?  my son is fully...  i only used them at night, but for a younger b...\n",
              "2                               is there a gelatin in it?  the label does not mention the capsule content...\n",
              "3       does it work on motorcycle tires as well and s...  if the valve steam has the same dimension than...\n",
              "4       does it fit most standard snowmobiles ? (examp...  i am unable to say for sure if it will fit the...\n",
              "...                                                   ...                                                ...\n",
              "137275  does this product scan to a pdf?  does it scan...  it will scan to pdf or jpg.  it does scan from...\n",
              "137276  how far does the flipper stick out when closed...  the flipper sticks out 5/16\". i don't own the ...\n",
              "137277  hi... does this phone works in 1900 mhz 3g ban...  dear rixio, sorry but this phone ido not work ...\n",
              "137278  i recently purchased a shadow billet grill tha...  i'm not really sure.unless that particular gri...\n",
              "137279  what are the dimensions of the air compressor ...  from the slime website...4.75&#8243;h x 3.875&...\n",
              "\n",
              "[137280 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7lEMssqmwHi",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "1e214451-f499-42f4-df45-60f313ec28b9"
      },
      "source": [
        "train"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>do these retro phones come with internal answe...</td>\n",
              "      <td>this one doesn't..but good quality phone.</td>\n",
              "      <td>office products</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i am new to owning a cat and inherited this 8 ...</td>\n",
              "      <td>it is your job to clip your cats nails. please...</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is this a smartphone</td>\n",
              "      <td>yes.thank you</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>does this gate have a manual open and close (o...</td>\n",
              "      <td>yes. you can make it so you don't have to use ...</td>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>do it sheds alot ?</td>\n",
              "      <td>no not at all but you can only wear it syray</td>\n",
              "      <td>beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>how do you open the container? just recieved o...</td>\n",
              "      <td>what i got came in a jar as pictured, but with...</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>can this be used with cases? looking at otterb...</td>\n",
              "      <td>yes the otter box defender will work with this...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>how many positions does the seat recline  befo...</td>\n",
              "      <td>you pull a lever and place it where you want.</td>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>can i use xl catrige for this printer?</td>\n",
              "      <td>yes you can.</td>\n",
              "      <td>office products</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>is this pen good for writing on the backs of p...</td>\n",
              "      <td>i have never tried writing on the back of phot...</td>\n",
              "      <td>office products</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  ...                     category\n",
              "0       do these retro phones come with internal answe...  ...              office products\n",
              "1       i am new to owning a cat and inherited this 8 ...  ...                 pet supplies\n",
              "2                                    is this a smartphone  ...  cell phones and accessories\n",
              "3       does this gate have a manual open and close (o...  ...                         baby\n",
              "4                                      do it sheds alot ?  ...                       beauty\n",
              "...                                                   ...  ...                          ...\n",
              "249995  how do you open the container? just recieved o...  ...                 pet supplies\n",
              "249996  can this be used with cases? looking at otterb...  ...  cell phones and accessories\n",
              "249997  how many positions does the seat recline  befo...  ...                         baby\n",
              "249998             can i use xl catrige for this printer?  ...              office products\n",
              "249999  is this pen good for writing on the backs of p...  ...              office products\n",
              "\n",
              "[250000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BVzMvo9mwHu",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "41f19852-60cb-47d4-932e-3e45bbff55ca"
      },
      "source": [
        "valid"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>can i use this with metro pcs 4g?</td>\n",
              "      <td>i dont recommend this phone. i don't want to t...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>they come with 2 trucks or one?</td>\n",
              "      <td>this ad is for 1 set of (2) trucks.</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is it compatible with ios 7?</td>\n",
              "      <td>yes it is !</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>are these crossbows 2013 modles? the reason i ...</td>\n",
              "      <td>mine says 385</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will this fit on an a1286 antiglare display ma...</td>\n",
              "      <td>yes it should. the key point is the model (128...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>how big is the bottle opening? i know it sound...</td>\n",
              "      <td>yup! i have a pump on mine as well, and it's a...</td>\n",
              "      <td>grocery and gourmet food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>why does a search for a cover for a 2008 silve...</td>\n",
              "      <td>i am not sure why the search does not reveal r...</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>what is the difference between this holster an...</td>\n",
              "      <td>don't buy it sucks</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>will this scope fit my crosman vigilante co2 p...</td>\n",
              "      <td>didn't fit mine, your better off going to walm...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>can i use this a few times a week for a month ...</td>\n",
              "      <td>hell no</td>\n",
              "      <td>beauty</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  ...                     category\n",
              "0                      can i use this with metro pcs 4g?  ...  cell phones and accessories\n",
              "1                        they come with 2 trucks or one?  ...          sports and outdoors\n",
              "2                           is it compatible with ios 7?  ...  cell phones and accessories\n",
              "3      are these crossbows 2013 modles? the reason i ...  ...          sports and outdoors\n",
              "4      will this fit on an a1286 antiglare display ma...  ...  cell phones and accessories\n",
              "...                                                  ...  ...                          ...\n",
              "49995  how big is the bottle opening? i know it sound...  ...     grocery and gourmet food\n",
              "49996  why does a search for a cover for a 2008 silve...  ...                   automotive\n",
              "49997  what is the difference between this holster an...  ...          sports and outdoors\n",
              "49998  will this scope fit my crosman vigilante co2 p...  ...          sports and outdoors\n",
              "49999  can i use this a few times a week for a month ...  ...                       beauty\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIiK5k5ymwH3"
      },
      "source": [
        "## Задача\n",
        "Классифицировать поле question в одну из категорий в поле category.  \n",
        "Это данные с сервиса Amazon QA, то есть такой сервис, на котором можно задать вопрос и получить ответ от других пользователей.\n",
        "\n",
        "Идея задачи такая: давайте поможем клиенту определить в какую категорию выложить его вопрос, чтобы быстрее получить максимально релевантный ответ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIAnIDrwmwH4"
      },
      "source": [
        "### Перевод класса в индекс\n",
        "Мы сделаем некоторый маппер, который текст класса переводит в конкретный уникальный индекс. Нам это понадобиться, потому что наша \n",
        "модель работает не напрямую с классом, а с его индексом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MYpScz5mwH6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f3c9578-0d32-4255-d543-ac449a2dea5c"
      },
      "source": [
        "# проверим, что в трейне и валидации одинаковые категории\n",
        "set(train.category.unique().tolist()) == set(valid.category.unique().tolist())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicC4JIhmwIE"
      },
      "source": [
        "unique_categories = set(train.category.unique().tolist() + valid.category.unique().tolist())"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhX3-l1rmwIP"
      },
      "source": [
        "category2index = {category: index for index, category in enumerate(unique_categories)}"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sPH75E9mwIc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "186e7823-2d22-4162-aa8a-ff81e9204d29"
      },
      "source": [
        "category2index"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'automotive': 7,\n",
              " 'baby': 1,\n",
              " 'beauty': 4,\n",
              " 'cell phones and accessories': 5,\n",
              " 'grocery and gourmet food': 0,\n",
              " 'office products': 6,\n",
              " 'pet supplies': 2,\n",
              " 'sports and outdoors': 3}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CfVU0CimwIo"
      },
      "source": [
        "train['target'] = train.category.map(category2index)\n",
        "valid['target'] = valid.category.map(category2index)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xVDWJpjmwIy",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "6253d8ac-963d-4d25-db3e-aadd0065957d"
      },
      "source": [
        "train"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>do these retro phones come with internal answe...</td>\n",
              "      <td>this one doesn't..but good quality phone.</td>\n",
              "      <td>office products</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>i am new to owning a cat and inherited this 8 ...</td>\n",
              "      <td>it is your job to clip your cats nails. please...</td>\n",
              "      <td>pet supplies</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>is this a smartphone</td>\n",
              "      <td>yes.thank you</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>does this gate have a manual open and close (o...</td>\n",
              "      <td>yes. you can make it so you don't have to use ...</td>\n",
              "      <td>baby</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>do it sheds alot ?</td>\n",
              "      <td>no not at all but you can only wear it syray</td>\n",
              "      <td>beauty</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>how do you open the container? just recieved o...</td>\n",
              "      <td>what i got came in a jar as pictured, but with...</td>\n",
              "      <td>pet supplies</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>can this be used with cases? looking at otterb...</td>\n",
              "      <td>yes the otter box defender will work with this...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>how many positions does the seat recline  befo...</td>\n",
              "      <td>you pull a lever and place it where you want.</td>\n",
              "      <td>baby</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>can i use xl catrige for this printer?</td>\n",
              "      <td>yes you can.</td>\n",
              "      <td>office products</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>is this pen good for writing on the backs of p...</td>\n",
              "      <td>i have never tried writing on the back of phot...</td>\n",
              "      <td>office products</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  ... target\n",
              "0       do these retro phones come with internal answe...  ...      6\n",
              "1       i am new to owning a cat and inherited this 8 ...  ...      2\n",
              "2                                    is this a smartphone  ...      5\n",
              "3       does this gate have a manual open and close (o...  ...      1\n",
              "4                                      do it sheds alot ?  ...      4\n",
              "...                                                   ...  ...    ...\n",
              "249995  how do you open the container? just recieved o...  ...      2\n",
              "249996  can this be used with cases? looking at otterb...  ...      5\n",
              "249997  how many positions does the seat recline  befo...  ...      1\n",
              "249998             can i use xl catrige for this printer?  ...      6\n",
              "249999  is this pen good for writing on the backs of p...  ...      6\n",
              "\n",
              "[250000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQpyjh3DmwI6"
      },
      "source": [
        "### Torch Dataset, DataLoader\n",
        "\n",
        "Очень важная абстракция для торча.\n",
        "Мы всегда будем ее использовать, чтобы работать с данными.\n",
        "\n",
        "Dataset - класс, от которого нужно наследоваться, чтобы написать свой обработчик данных. Внутри него нужно реализовать два метода, \n",
        "о которых будет чуть ниже. То есть в данном классе вы описывает как нужно преобразовать ваши данные в торчовый формат. Перевести тексты \n",
        "в индексы слов и тд.\n",
        "\n",
        "DataLoader - класс, который будет за вас семплировать данные батчами. Это итератор, поэтому формат работы с ним примерно такой:\n",
        "```python\n",
        "for batch in data_loader:\n",
        "    ...\n",
        "```\n",
        "То есть на каждой итерации отдается по одному батчу данных. Итерирование заканчивается, когда вы пройдете все батчи.\n",
        "\n",
        "Зачем нужны эти абстракции? Чтобы упростить и унифицировать работу с данными.\n",
        "Вообще вы можете реализовать что-то свое, но это упрощение данной задачи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXACcy5OmwI_"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H_DSJzvmwJL"
      },
      "source": [
        "# игрушечный датасет\n",
        "# 121535 примера, 4 фичи, 3 класса\n",
        "some_data_x = np.random.rand(121535, 4)\n",
        "some_data_y = np.random.randint(3, size=(121535,))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPQz5lwAmwJU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5e1fd1b-d207-4451-a8d4-585ab6b8f439"
      },
      "source": [
        "# просто рандомные цифры\n",
        "some_data_x[:10]"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.08638647, 0.03800717, 0.46663545, 0.21257999],\n",
              "       [0.39067389, 0.9385148 , 0.60444444, 0.6288957 ],\n",
              "       [0.51720048, 0.61244477, 0.74715835, 0.77869737],\n",
              "       [0.01570653, 0.41460045, 0.70228668, 0.45624623],\n",
              "       [0.3599341 , 0.4332824 , 0.7557122 , 0.46946626],\n",
              "       [0.15759993, 0.08188013, 0.64019966, 0.26926746],\n",
              "       [0.44527888, 0.83584888, 0.64462564, 0.69378026],\n",
              "       [0.50340357, 0.2904353 , 0.56935949, 0.83840229],\n",
              "       [0.60808616, 0.80979437, 0.50969328, 0.51425608],\n",
              "       [0.55638892, 0.55397949, 0.54293486, 0.38598163]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO506pvFmwJd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "122340cf-cec4-44f1-eef9-c0a9b03ff87d"
      },
      "source": [
        "# и классы\n",
        "some_data_y"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 2, 1, ..., 0, 0, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERMQy7AWmwJn"
      },
      "source": [
        "### Пример надобности\n",
        "Для обучения модели вам нужно подавать в нее батчи данных. Как бы могли это реализовать, если бы у нас не было Dataset и DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otp2vKj0mwJp"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "for i_batch in range(math.ceil(some_data_x.shape[0] / batch_size)):\n",
        "    \n",
        "    x_batch = some_data_x[i_batch * batch_size:(i_batch + 1) * batch_size]\n",
        "    y_batch = some_data_y[i_batch * batch_size:(i_batch + 1) * batch_size]\n",
        "    \n",
        "    x_batch = torch.tensor(x_batch)\n",
        "    y_batch = torch.tensor(y_batch)\n",
        "    \n",
        "    break"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCtwvxBZmwJy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5926a231-b990-43fd-b607-2bb93f346091"
      },
      "source": [
        "x_batch"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0864, 0.0380, 0.4666, 0.2126],\n",
              "        [0.3907, 0.9385, 0.6044, 0.6289],\n",
              "        [0.5172, 0.6124, 0.7472, 0.7787],\n",
              "        [0.0157, 0.4146, 0.7023, 0.4562],\n",
              "        [0.3599, 0.4333, 0.7557, 0.4695],\n",
              "        [0.1576, 0.0819, 0.6402, 0.2693],\n",
              "        [0.4453, 0.8358, 0.6446, 0.6938],\n",
              "        [0.5034, 0.2904, 0.5694, 0.8384],\n",
              "        [0.6081, 0.8098, 0.5097, 0.5143],\n",
              "        [0.5564, 0.5540, 0.5429, 0.3860],\n",
              "        [0.4610, 0.9529, 0.3618, 0.1034],\n",
              "        [0.2463, 0.3541, 0.1161, 0.1363],\n",
              "        [0.5350, 0.4149, 0.6859, 0.9938],\n",
              "        [0.8152, 0.3636, 0.8799, 0.9992],\n",
              "        [0.3972, 0.1933, 0.9574, 0.5197],\n",
              "        [0.2227, 0.1377, 0.5347, 0.2037]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2xydSIrmwJ5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f4a1fb-d192-483a-b795-29e53021f72b"
      },
      "source": [
        "x_batch.shape, y_batch.shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 4]), torch.Size([16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VfZ6XRgmwKA"
      },
      "source": [
        "Это достаточно простой пример. Мы смогли справиться сами, но почти всегда обработка данных для подачи ее в модель делается сложнее. \n",
        "И некоторые вещи часто нужны более одного раза, например, если мы хотим каждую эпоху шафлить наши данные, чтобы получать разные батчи.\n",
        "Мы сможем это сделать, но для этого нам придется тащить с собой некоторый код из проекта в проект. К тому же совместная разработка или \n",
        "просто чтение чужого кода сильно упрощается, когда вы используете унифицированные форматы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qywWBKphmwKC"
      },
      "source": [
        "### Перейдем к Dataset\n",
        "И обернем наши данные в этот обработчик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHdvtHmfmwKF"
      },
      "source": [
        "class ToyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data_x, data_y):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.data_x = data_x\n",
        "        self.data_y = data_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        # нужно обязательно определить эту функцию\n",
        "        # должна возвращать размер датасета\n",
        "        # нужен для DataLoader, чтобы семплировать батчи\n",
        "        \n",
        "        return len(self.data_x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # еще нужно определить этот метод\n",
        "        # то есть как мы будем доставать наши данные по индексу\n",
        "        \n",
        "        return self.data_x[idx], self.data_y[idx]"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-9ETa8mwKS"
      },
      "source": [
        "some_dataset = ToyDataset(some_data_x, some_data_y)"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMgG_0kkmwKb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1bde1a58-5090-44e9-df85-d487171cafcc"
      },
      "source": [
        "some_dataset[5], some_dataset[467]"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([0.15759993, 0.08188013, 0.64019966, 0.26926746]), 1),\n",
              " (array([0.7354074 , 0.85413089, 0.5715419 , 0.48697449]), 0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBLF-l4omwKm"
      },
      "source": [
        "### Кажется, что смысла в этом нет, но это самый простой пример"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-xiNy7gmwKn"
      },
      "source": [
        "### DataLoader\n",
        "В него мы можем задать некоторые параметры, например, батч сайз и нужно ли шафлить каждый новый проход по данным эти самые данные, \n",
        "чтобы получать разные батчи, то есть по разному компоновать эти батчи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZvHJwY1mwKo"
      },
      "source": [
        "some_loader = DataLoader(some_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywM_MeFjmwKv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5e874bb-5c87-4813-bb16-2c549cca0e8d"
      },
      "source": [
        "for x, y in some_loader:\n",
        "    break\n",
        "    \n",
        "x"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0097, 0.8532, 0.4664, 0.5398],\n",
              "        [0.4653, 0.1156, 0.4672, 0.8099],\n",
              "        [0.1259, 0.0556, 0.3919, 0.4828],\n",
              "        [0.8191, 0.5687, 0.5632, 0.4424],\n",
              "        [0.4727, 0.4465, 0.5692, 0.3014],\n",
              "        [0.7858, 0.0388, 0.1625, 0.4642],\n",
              "        [0.2544, 0.3052, 0.7089, 0.1462],\n",
              "        [0.9101, 0.7934, 0.5823, 0.1311],\n",
              "        [0.8214, 0.4497, 0.6710, 0.3547],\n",
              "        [0.6884, 0.1024, 0.7512, 0.8907],\n",
              "        [0.6264, 0.3024, 0.1026, 0.2298],\n",
              "        [0.8830, 0.4672, 0.8924, 0.4637],\n",
              "        [0.3349, 0.6619, 0.3936, 0.5651],\n",
              "        [0.7602, 0.0088, 0.1508, 0.3991],\n",
              "        [0.9172, 0.5534, 0.0412, 0.2502],\n",
              "        [0.0849, 0.2727, 0.7924, 0.6793]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ugsw7VmwK7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "61596f76-51a8-4a66-8e1b-3badef414497"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwRXGXMImwLE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "19a6bab7-4b29-4ffa-9c3f-921052607a6c"
      },
      "source": [
        "for x, y in some_loader:\n",
        "    pass\n",
        "\n",
        "len(x)"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Imyx8umwLN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "033df0ee-fd6b-48f7-8e4a-e74195026b40"
      },
      "source": [
        "# почему 15?\n",
        "# потому что количество наших данных нацело не делится на 16\n",
        "# и поэтому последний батч меньше 16-ти\n",
        "len(some_dataset) % 16"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9R8ZpRymwLV"
      },
      "source": [
        "### Усложним обработчик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ignw8wuXmwLX"
      },
      "source": [
        "class ToyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data_x, data_y):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.data_x = data_x\n",
        "        self.data_y = data_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        # нужно обязательно определить эту функцию\n",
        "        # должна возвращать размер датасета\n",
        "        # нужен для DataLoader, чтобы семплировать батчи\n",
        "        \n",
        "        return len(self.data_x)\n",
        "    \n",
        "    @staticmethod\n",
        "    def pow_features(x, n=2):\n",
        "        \n",
        "        return x ** n\n",
        "    \n",
        "    @staticmethod\n",
        "    def log_features(x):\n",
        "        \n",
        "        return np.log(x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # еще нужно определить этот метод\n",
        "        # то есть как мы будем доставать наши данные по индексу\n",
        "        \n",
        "        x = self.data_x[idx]\n",
        "        \n",
        "        # внутри датасета мы можем делать все что угодно с нашими данными\n",
        "        # например выше определим функции, которые добавляют степенные фичи\n",
        "        x_p_2 = self.pow_features(x, n=2)\n",
        "        x_p_3 = self.pow_features(x, n=3)\n",
        "        # и еще возьмем логарифмические фичи\n",
        "        x_log = self.log_features(x)\n",
        "        \n",
        "        # сконкатенируем наши фичи\n",
        "        x = np.concatenate([x, x_p_2, x_p_3, x_log])\n",
        "        \n",
        "        y = self.data_y[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynRZTBEDmwLg"
      },
      "source": [
        "toy_dataset = ToyDataset(some_data_x, some_data_y)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdWS1NNfmwLo"
      },
      "source": [
        "toy_loader = DataLoader(dataset=toy_dataset, batch_size=128)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nECo_cnNmwLz"
      },
      "source": [
        "for x, y in toy_loader:\n",
        "    break"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECM6zR-3mwL9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "942ebd84-da86-4b7d-dfa5-6b583acf5335"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11cPrRC-mwMF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40a4cffb-619f-4ae3-8f41-e259d7bd8587"
      },
      "source": [
        "# заметим, что мы сразу получаем торчовый формат данных, который получился из автоматического преобразования из numpy\n",
        "x"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.0864,  0.0380,  0.4666,  ..., -3.2700, -0.7622, -1.5484],\n",
              "        [ 0.3907,  0.9385,  0.6044,  ..., -0.0635, -0.5034, -0.4638],\n",
              "        [ 0.5172,  0.6124,  0.7472,  ..., -0.4903, -0.2915, -0.2501],\n",
              "        ...,\n",
              "        [ 0.2988,  0.2075,  0.1120,  ..., -1.5724, -2.1894, -1.6828],\n",
              "        [ 0.2784,  0.7709,  0.3820,  ..., -0.2602, -0.9623, -1.8131],\n",
              "        [ 0.4726,  0.5038,  0.7518,  ..., -0.6855, -0.2853, -3.9354]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7RPNtDmwMO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4a29fa36-7c09-4fcc-8122-a95bd65d33aa"
      },
      "source": [
        "y"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 2, 1, 2, 1, 1, 2, 1, 1, 1, 0, 0, 0, 0, 0, 2, 0, 1, 1, 1, 0, 1, 1, 1,\n",
              "        1, 2, 1, 2, 2, 0, 0, 1, 2, 2, 1, 1, 0, 0, 2, 2, 0, 1, 0, 2, 0, 0, 0, 0,\n",
              "        0, 2, 1, 2, 2, 2, 1, 2, 2, 0, 1, 2, 2, 0, 0, 1, 2, 1, 1, 0, 0, 1, 0, 2,\n",
              "        0, 1, 0, 2, 2, 2, 2, 0, 0, 2, 0, 1, 0, 1, 2, 0, 0, 2, 0, 0, 0, 2, 0, 2,\n",
              "        2, 2, 0, 1, 0, 1, 0, 1, 1, 2, 1, 2, 2, 1, 1, 0, 1, 0, 0, 2, 1, 2, 1, 0,\n",
              "        2, 0, 2, 1, 2, 1, 0, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ4OzH3mmwMY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1999b90-5ae6-4b44-b34b-3d655ec3acd8"
      },
      "source": [
        "# сделаем небольшую модель и посчитаем лосс\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(16, 8),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(8, 4),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(4, 3))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    prediction = model(x.float())\n",
        "\n",
        "    loss = criterion(prediction, y)\n",
        "    \n",
        "loss.item()"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1485671997070312"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkDBO1cfmwMp"
      },
      "source": [
        "### Сделаем датасет для наших текстовых данных\n",
        "Будем отдавать строку и таргет по индексу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4lOJj4FmwMr"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        return text, target"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhkuK2x1mwMy"
      },
      "source": [
        "# подготовим данные\n",
        "train_x = list(train.question)\n",
        "train_y = list(train.target)\n",
        "\n",
        "valid_x = list(valid.question)\n",
        "valid_y = list(valid.target)"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE07XIwkmwND"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=list(train.question), targets=list(train.target))"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw4MJ7W8mwNL"
      },
      "source": [
        "# семплируем данные\n",
        "text, target = train_dataset[0]"
      ],
      "execution_count": 43,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsgIoI4NmwNW",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "3d55340f-a851-4f53-de40-43ca90cbaf2f"
      },
      "source": [
        "text"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'do these retro phones come with internal answering service'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkSczglhmwNf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b295da16-0bde-43cb-f775-095fdcd2d6e3"
      },
      "source": [
        "target"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DusOSVpOmwNn"
      },
      "source": [
        "### Смысл обработчика\n",
        "Состоит в том, что нам нужно преобразовать наши данные в формат, который мы уже сможем передать в модель.\n",
        "Сейчас у нас строки, а торч ничего не знает про строки, ему нужны тензоры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBgeGoermwNo"
      },
      "source": [
        "### Загружаем эмбеддинги\n",
        "Чтобы работать с текстовыми данными мы можем разбить наши строки на слова, а слова перевести в вектора. Откуда нам взять эти вектора?\n",
        "Мы говорили про такой метод как word2vec и в начале этой тетрадки загружали файл с этими самыми векторами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umc0ZdammwNq"
      },
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbv94NMzmwNz"
      },
      "source": [
        "def load_embeddings(zip_path, filename, pad_token='PAD', max_words=100_000, verbose=True):\n",
        "    \n",
        "    vocab = dict()\n",
        "    embeddings = list()\n",
        "\n",
        "    with zipfile.ZipFile(zip_path) as zipped_file:\n",
        "        with zipped_file.open(filename) as file_object:\n",
        "\n",
        "            vocab_size, embedding_dim = file_object.readline().decode('utf-8').strip().split()\n",
        "\n",
        "            vocab_size = int(vocab_size)\n",
        "            embedding_dim = int(embedding_dim)\n",
        "            \n",
        "            # в файле 1 000 000 слов с векторами, давайте ограничим для простоты этот словарь\n",
        "            max_words = vocab_size if max_words <= 0 else max_words\n",
        "            \n",
        "            # добавим пад токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
        "            vocab[pad_token] = len(vocab)\n",
        "            embeddings.append(np.zeros(embedding_dim))\n",
        "\n",
        "            progress_bar = tqdm(total=max_words, disable=not verbose)\n",
        "\n",
        "            for line in file_object:\n",
        "                parts = line.decode('utf-8').strip().split()\n",
        "\n",
        "                token = ' '.join(parts[:-embedding_dim]).lower()\n",
        "                \n",
        "                if token in vocab:\n",
        "                    continue\n",
        "                \n",
        "                word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
        "\n",
        "                vocab[token] = len(vocab)\n",
        "                embeddings.append(word_vector)\n",
        "\n",
        "                progress_bar.update()\n",
        "                \n",
        "                if len(vocab) == max_words:\n",
        "                    break\n",
        "\n",
        "            progress_bar.close()\n",
        "\n",
        "    embeddings = np.stack(embeddings)\n",
        "    \n",
        "    return vocab, embeddings"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ggeKh1GvmwN9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e30a2ebe-8bb4-40e3-f72c-c1ddbf0b685e"
      },
      "source": [
        "vocab, embeddings = load_embeddings('./wiki-news-300d-1M.vec.zip', 'wiki-news-300d-1M.vec', max_words=100_000)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 99999/100000 [00:12<00:00, 7888.61it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2A4szMHmwOG"
      },
      "source": [
        "### Посмотрим на ближайших соседей слова по эмбеддингам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1RKRQyWmwOH"
      },
      "source": [
        "index2token = {index: token for token, index in vocab.items()}"
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP7IP1RvmwOY"
      },
      "source": [
        "emb_norms = np.linalg.norm(embeddings, axis=1)"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ9XwMj_mwOk"
      },
      "source": [
        "def get_k_nearest_neighbors(word, embeddings, emb_norms, vocab, index2token, k=5):\n",
        "    \n",
        "    if word not in vocab:\n",
        "        print('Not in vocab')\n",
        "        return\n",
        "    \n",
        "    word_index = vocab[word]\n",
        "\n",
        "    word_vector = embeddings[word_index]\n",
        "    word_vector = np.expand_dims(word_vector, 0)\n",
        "\n",
        "    scores = (word_vector @ embeddings.T)[0]\n",
        "    \n",
        "    # переводим в косинусы, поделив на нормы векторов\n",
        "    # эпсилон 1e-6 для того, чтобы не делить на 0\n",
        "    scores = scores / (emb_norms + 1e-6) / emb_norms[word_index]\n",
        "    \n",
        "    # 1:k+1 потому что первый вариант это само слово\n",
        "    for idx in scores.argsort()[::-1][1:k+1]:\n",
        "        print(f'Слово {index2token[idx]} близко на {scores[idx]:.2f} к слову {word}')"
      ],
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1DGLYDgmwOu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "815c8544-64fd-45f6-b59a-bfd1aed8e884"
      },
      "source": [
        "get_k_nearest_neighbors('anna', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово maria близко на 0.73 к слову anna\n",
            "Слово emma близко на 0.66 к слову anna\n",
            "Слово kristina близко на 0.65 к слову anna\n",
            "Слово laura близко на 0.65 к слову anna\n",
            "Слово emily близко на 0.65 к слову anna\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExhJDpg_mwO3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d7c37d0f-723d-431f-de12-f56cf752625f"
      },
      "source": [
        "get_k_nearest_neighbors('mom', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово dad близко на 0.85 к слову mom\n",
            "Слово mum близко на 0.78 к слову mom\n",
            "Слово mother близко на 0.76 к слову mom\n",
            "Слово moms близко на 0.75 к слову mom\n",
            "Слово kid близко на 0.68 к слову mom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHfEe1-DmwO-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2fd58718-61e2-4e3e-c29b-d146aaaaba9d"
      },
      "source": [
        "get_k_nearest_neighbors('have', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово has близко на 0.78 к слову have\n",
            "Слово been близко на 0.75 к слову have\n",
            "Слово 've близко на 0.75 к слову have\n",
            "Слово had близко на 0.74 к слову have\n",
            "Слово ahve близко на 0.74 к слову have\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0emkbwsXmwPQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "97e0b577-d8a3-46bc-de9d-39da92aaeb0b"
      },
      "source": [
        "get_k_nearest_neighbors('money', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово cash близко на 0.72 к слову money\n",
            "Слово funds близко на 0.72 к слову money\n",
            "Слово monies близко на 0.72 к слову money\n",
            "Слово moneys близко на 0.67 к слову money\n",
            "Слово dosh близко на 0.63 к слову money\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyx9Gl2RmwPX",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9b6da01f-c1f1-4aae-821c-559a65ba0e4c"
      },
      "source": [
        "get_k_nearest_neighbors('music', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово musical близко на 0.71 к слову music\n",
            "Слово songs близко на 0.69 к слову music\n",
            "Слово tunes близко на 0.69 к слову music\n",
            "Слово musics близко на 0.68 к слову music\n",
            "Слово composer близко на 0.68 к слову music\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1x26_qumwPg"
      },
      "source": [
        "### Выбор метода токенизации\n",
        "У нас сейчас есть маппинг, что некоторому слову соответствует некоторый эмбеддинг этого слова.\n",
        "Токенизация - процесс разбиения текста на токены, то есть части этого текста.   \n",
        "Чем \"слово\" отличается от \"токена\": токен это более обобщенное понятие, то есть, например, цифра это токен"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Nk0fCumwPi"
      },
      "source": [
        "# про различия подробнее можно найти, например, здесь\n",
        "# https://stackoverflow.com/questions/50240029/nltk-wordpunct-tokenize-vs-word-tokenize\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDMfHEltmwPq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd124738-6a42-4f80-a6b2-f08c1b3275ab"
      },
      "source": [
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация по пробелу\n",
        "    tokens = sample.split()\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:01<00:00, 177105.69it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 512180 слов из 3606201 слов в датасете\n",
            "Что составляет 14.20% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 119197\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkEc8tqsmwPw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "533f440b-0615-464d-a0e1-ef6bf1e2eacc"
      },
      "source": [
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация\n",
        "    tokens = wordpunct_tokenize(sample)\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:02<00:00, 102724.93it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 111115 слов из 4202739 слов в датасете\n",
            "Что составляет 2.64% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 36270\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRZs41zgmwP4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "02f4d188-c64f-42b2-b23c-e9191abe47ae"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация\n",
        "    tokens = word_tokenize(sample)\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:46<00:00, 5383.83it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 151779 слов из 4103252 слов в датасете\n",
            "Что составляет 3.70% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 54139\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2E1Ct9wmwP-"
      },
      "source": [
        "### Результаты\n",
        "- Скорость у word_tokenize сильно ниже, чем у wordpunct_tokenize\n",
        "- Используя word_tokenize, мы теряем примерно 1% информации из датасета по сравнению с wordpunct_tokenize\n",
        "\n",
        "### Выбор очевиден в сторону wordpunct_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGDViu55mwQA"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        \n",
        "        # переведем наши индексы токенов в торчовый тензор\n",
        "        # таргет переведется самостоятельно\n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcS-teH4mwQI"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3NxkEocmwQO"
      },
      "source": [
        "x, y = train_dataset[5]"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clziyBYImwQW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b5e79965-4617-4cb1-a54d-01333c0ac6d2"
      },
      "source": [
        "x"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  128,   122, 88992,   471,     7,     2,  2354,    37])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfthifOKmwQb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5186b376-7aeb-4d00-b48c-7f14e43787f5"
      },
      "source": [
        "y"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5UeEkzgmwQg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75e2f6e7-d0e0-40eb-e6b5-db38a55fe639"
      },
      "source": [
        "# мы можем восстановить текст обратно по индексам слов\n",
        "[index2token[idx.item()] for idx in x]"
      ],
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['how', 'many', 'diaphragms', 'come', 'in', 'the', 'package', '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXOgBrp_mwQn"
      },
      "source": [
        "### У нас остается проблема разных длин текстов\n",
        "Чтобы поместить батч текстов в один тензор нам нужны одинаковые длины"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpOqkvW3mwQo"
      },
      "source": [
        "## это не отработает, можете раскомментировать и проверить\n",
        "\n",
        "# x = [\n",
        "#     [1, 2, 3],\n",
        "#     [1, 2, 3, 4, 5],\n",
        "#     [1, 2, 3, 4, 5, 6, 7]\n",
        "# ]\n",
        "\n",
        "# torch.tensor(x), torch.tensor(x).shape"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov2z96hQmwQ2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9cc3b39d-932d-48e4-ca00-b8ebb2637d17"
      },
      "source": [
        "# это сработает\n",
        "\n",
        "x = [\n",
        "    [1, 2, 3, 0, 0, 0, 0],\n",
        "    [1, 2, 3, 4, 5, 0, 0],\n",
        "    [1, 2, 3, 4, 5, 6, 7]\n",
        "]\n",
        "\n",
        "torch.tensor(x), torch.tensor(x).shape"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 4, 5, 0, 0],\n",
              "         [1, 2, 3, 4, 5, 6, 7]]), torch.Size([3, 7]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOWRDQ8tmwQ9"
      },
      "source": [
        "### Длина текста\n",
        "Нам нужно понять до какой длины нам падить каждый наш пример. \n",
        "Мы можем найти в наших данных максимальную длину примера в токенах и падить до этой длины, но у этого подхода есть минус:\n",
        "у нас могут быть несколько текстов с аномально большой длиной, то есть некоторые выбросы.  \n",
        "\n",
        "В таком случае нам легче ограничить длину этих текстов до определенной статистики по нашему датасет, то есть, например, 95% наших текстов\n",
        "длиной в 25 слов и нам этого достаточно. То есть мы ограничимся этой длиной, потому что почти весь датасет влезает в эту длину\n",
        "и нам не нужно будет падить до большой длины.\n",
        "\n",
        "Паддинг нужен нам для того, чтобы мы могли поместить разные примеры в один батч, но мы не хотим учитывать эти токены, то есть \n",
        "по сути это будут холостые прогоны и за счет этого компромисса, что бОльшая часть датасета не больше n слов мы можем оптимизировать \n",
        "наше обучение.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "> Почему бы нам просто не выкинуть эти длинные тексты?\n",
        "\n",
        "Дело в том, что мы хотим прийти к некоторому компромиссу между максимальной длиной и потерей информации. Если мы возьмем 95-й перцинтиль наших длин (то есть 95% наших текстов не больше n), то, выкинув остальные 5%, мы потеряем существенную часть примеров.\n",
        "С другой стороны может показаться неправильным ограничение длины и это действительно может сломать смысл примеры, но зачастую этим \n",
        "принебрегают."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRLb6YzPmwQ-",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d9ade7b1-5e8c-4bc9-f05f-c0582fc77bbd"
      },
      "source": [
        "train_lengths = [len(wordpunct_tokenize(sample)) for sample in tqdm(train_x)]"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:01<00:00, 192368.10it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRd_EMC-mwRG",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "0ed78b67-ee8f-47fb-a210-0a0d67adafac"
      },
      "source": [
        "sns.distplot(train_lengths)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7fa348528be0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tScNTdhkmwRO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a20b0018-267d-4b2c-a5d3-ce4ac4ccfd8e"
      },
      "source": [
        "# видим большие выбросы в данных\n",
        "# 97% наших текстов не больше вот стольки токенов\n",
        "np.percentile(train_lengths, 95)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzVn2M-umwRY"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab, pad_index=0, max_length=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def padding(self, tokenized_text):\n",
        "        \n",
        "        tokenized_text = tokenized_text[:self.max_length]\n",
        "        \n",
        "        tokenized_text += [self.pad_index] * (self.max_length - len(tokenized_text))\n",
        "        \n",
        "        return tokenized_text\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        tokenized_text = self.padding(tokenized_text)\n",
        "        \n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq11AJqgmwRg"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uv6F_F9mwRo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "58c66ce9-3d4c-4be0-b8f0-8355d643bf28"
      },
      "source": [
        "x, y = train_dataset[0]\n",
        "x"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([   97,   130, 19818,  4944,   471,    18,  2194,  7198,   303,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI4OO3aGmwRu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7dd9f6aa-779e-409d-9550-e48b3311edce"
      },
      "source": [
        "[index2token[idx.item()] for idx in x]"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['do',\n",
              " 'these',\n",
              " 'retro',\n",
              " 'phones',\n",
              " 'come',\n",
              " 'with',\n",
              " 'internal',\n",
              " 'answering',\n",
              " 'service',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXXrt51ymwR1"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)\n",
        "valid_dataset = TextClassificationDataset(texts=valid_x, targets=valid_y, vocab=vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU9b64Y2mwR8"
      },
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJsKAFfUmwSC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0d45c40a-9294-4dae-a4c4-9187e84605b9"
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 32]), torch.Size([128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGZS8dhYmwSI"
      },
      "source": [
        "### Как мы можем задавать слои"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az1oWNcomwSL"
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOIWrRV8mwSX"
      },
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
        "                               embedding_dim=embeddings.shape[-1],\n",
        "                               padding_idx=0)"
      ],
      "execution_count": 80,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6lvUBYmwSc"
      },
      "source": [
        "x_embed = embedding_layer(x)"
      ],
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFhmcEaTmwSi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "580f3f8f-281b-4e7d-b662-485767e34e4e"
      },
      "source": [
        "x_embed"
      ],
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-1.5032,  0.5244, -0.0188,  ..., -0.0563,  1.3449,  0.2796],\n",
              "         [-0.4550,  0.7821, -2.3234,  ...,  1.2823, -0.8049, -0.3680],\n",
              "         [-0.7654,  1.1716,  0.2131,  ..., -0.4465, -0.4284, -1.2080],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.1407,  1.6161,  0.1731,  ..., -2.0524, -1.3058, -0.4026],\n",
              "         [-0.3832,  0.0110, -0.5930,  ...,  0.1208,  0.7506, -0.5068],\n",
              "         [ 0.8138,  0.7669,  0.2090,  ...,  1.0196,  0.5303, -0.7073],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[-0.1672, -1.2065,  0.0213,  ..., -0.8832,  0.3029, -0.2014],\n",
              "         [ 0.2399, -0.1744,  0.3792,  ...,  0.1306, -1.4302,  0.7744],\n",
              "         [-1.2383, -0.5101,  0.3284,  ..., -0.9117,  1.4421,  0.0857],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-0.1672, -1.2065,  0.0213,  ..., -0.8832,  0.3029, -0.2014],\n",
              "         [ 0.2399, -0.1744,  0.3792,  ...,  0.1306, -1.4302,  0.7744],\n",
              "         [-1.2383, -0.5101,  0.3284,  ..., -0.9117,  1.4421,  0.0857],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 2.0656,  1.0720, -0.6253,  ...,  1.3135,  0.0112,  1.3140],\n",
              "         [-0.3010,  0.3854,  0.9205,  ...,  1.4038, -1.7070,  2.8267],\n",
              "         [ 1.0420, -0.6750,  0.1578,  ..., -0.3014,  0.1989,  1.1347],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 0.1407,  1.6161,  0.1731,  ..., -2.0524, -1.3058, -0.4026],\n",
              "         [ 0.5402, -0.0732,  2.8063,  ...,  0.6953,  1.1679, -1.8387],\n",
              "         [ 1.2199, -0.2566, -0.4096,  ..., -2.6054,  0.4902, -1.4586],\n",
              "         ...,\n",
              "         [-0.8145, -2.0432, -0.7354,  ..., -0.8575, -1.0338, -1.0227],\n",
              "         [ 1.5152,  0.5460, -0.8226,  ...,  0.4582,  0.5435, -0.3316],\n",
              "         [-0.3925,  1.7140, -1.1289,  ..., -0.7613, -0.4031, -1.1957]]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsiFyyNnmwSo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "83b86fa8-aaf3-4a5f-82b9-d3d9940be92d"
      },
      "source": [
        "x_embed.shape"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRcyJ9hEmwSw"
      },
      "source": [
        "### Но мы ведь прочитали нашу матрицу эмбеддингов\n",
        "Таким образом она инициализируется предобученными весами.  \n",
        "При такой инициализации по умолчанию она замораживается, внутри ```.from_pretrained(embeddings, padding_idx=0)``` есть флаг ```freeze```, который отвечает за необходимость заморозки весов. То есть эти веса в процессе обучения не будут обновляться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sZguS0amwSy"
      },
      "source": [
        "embeddings = torch.tensor(embeddings).float()"
      ],
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9wxstMqmwS3"
      },
      "source": [
        "embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)"
      ],
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhBjsss2mwS_"
      },
      "source": [
        "x_embed = embedding_layer(x)"
      ],
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWtZEG4RmwTF"
      },
      "source": [
        "### Немного LSTM\n",
        "Ниже будет про ```batch_first=True```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFAor2_NmwTG"
      },
      "source": [
        "lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)"
      ],
      "execution_count": 87,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMMNlB1DmwTM"
      },
      "source": [
        "x_lstm, _ = lstm(x_embed)"
      ],
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7XGmnUxmwTU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "668e2717-19d1-4fd5-9c1e-4a32c53b775f"
      },
      "source": [
        "# 256 потому что это конкатенация лстмки, которая прочитала текст слева направо\n",
        "# и лстмки, которая прочитала текст справа налево\n",
        "x_lstm.shape"
      ],
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7cPfgemwTb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef1c390a-a625-4fff-8ecd-1241ed3b64e3"
      },
      "source": [
        "# избавились от временной размерности\n",
        "x_lstm.mean(dim=1).shape"
      ],
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W753-EMmwTg"
      },
      "source": [
        "### Сделаем свою сеть\n",
        "В первой домашке в конце есть более подробная информация почему мы используем классы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFl-JIVfmwTh"
      },
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n",
        "        \n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=embeddings.shape[-1])\n",
        "        \n",
        "        self.linear_1 = nn.Linear(in_features=embeddings.shape[-1], out_features=linear_1_size)\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # переводим индексы слов в эмбеддинги этих слов\n",
        "        # (batch_size, sequence_length) -> (batch_size, sequence_length, embedding_dim)\n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        # агрегируем наши эмбеддинги по размерности время\n",
        "        # (batch_size, sequence_length, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        x = x.sum(dim=1)\n",
        "        \n",
        "        # делаем нормирование\n",
        "        # (batch_size, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        x = self.batch_norm(x)\n",
        "        \n",
        "        # прогоняем через первый линейный слой\n",
        "        # (batch_size, embedding_dim) -> (batch_size, linear_1_size)\n",
        "        x = self.linear_1(x)\n",
        "        \n",
        "        # применяем нелинейность\n",
        "        # (batch_size, linear_1_size) -> (batch_size, linear_1_size)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        # прогоняем через второй линейный слой\n",
        "        # (batch_size, linear_1_size) -> (batch_size, linear_2_size)\n",
        "        x = self.linear_2(x)\n",
        "        \n",
        "        # применяем нелинейность\n",
        "        # (batch_size, linear_2_size) -> (batch_size, linear_2_size)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        # переводим с помощью линейного преобразования в количество классов\n",
        "        # (batch_size, linear_2_size) -> (batch_size, n_classes)\n",
        "        x = self.linear_3(x)\n",
        "        \n",
        "        ## по идеи здесь должен был быть софтмакс\n",
        "        ## но мы будем использовать лосс nn.CrossEntropyLoss()\n",
        "        ## в его документации написано\n",
        "        ## This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.\n",
        "        ## это некоторая оптимизация, которая включает в себя сразу и софтмакс и сам negative log likelihood лосс\n",
        "        ## так как у нас в лоссе есть софтмакс, то мы не будем применять его в сетке\n",
        "        ## на этапе предсказания (а не обучения) мы будем отдельно делать софтмакс для получения распределения классов\n",
        "        ## \n",
        "        ## (batch_size, n_classes) -> (batch_size, n_classes)\n",
        "        # x = torch.softmax(x, dim=-1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": 91,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuo1BYevmwTl"
      },
      "source": [
        "model = DeepAverageNetwork(embeddings=embeddings,\n",
        "                           linear_1_size=256, \n",
        "                           linear_2_size=128, \n",
        "                           n_classes=len(category2index))"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTH8HEiLmwTq"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# задайте оптимизатор\n",
        "optimizer = torch.optim.Adam(params=model.parameters())"
      ],
      "execution_count": 93,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T44SyjAMmwT2"
      },
      "source": [
        "### Напишите цикл обучения\n",
        "Что он должен в себя включать:\n",
        "1. Получение предсказаний модели\n",
        "1. Расчет функции потерь\n",
        "1. Расчет градиентов\n",
        "1. Шаг градиентного спуска\n",
        "1. Обнуление градиентов\n",
        "1. Записывание значения лосса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VYqV_5GmwT3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5824f3d1-e8f2-49b9-e276-76f552dff1ce"
      },
      "source": [
        "losses = list()\n",
        "\n",
        "# в обучении моделей у нас есть такая ситуация, что некоторые слои ведут себя по разному на этапе тренировки и предсказания\n",
        "# например, батч норм (а так же все остальные нормировки) и дропаут\n",
        "# это переводит модель в режим тренировки\n",
        "model.train()\n",
        "for x, y in train_loader:\n",
        "  prediction = model.forward(x)\n",
        "  loss = criterion(prediction, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  losses.append(loss)\n",
        "print(f\"Train loss: {loss}\")"
      ],
      "execution_count": 94,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss: 1.647088646888733\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFb7SVOZidA2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "62179405-7f08-4e1b-83a0-ef221456790d"
      },
      "source": [
        "print(losses)"
      ],
      "execution_count": 95,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(2.0773, grad_fn=<NllLossBackward>), tensor(2.0346, grad_fn=<NllLossBackward>), tensor(2.0108, grad_fn=<NllLossBackward>), tensor(2.0097, grad_fn=<NllLossBackward>), tensor(1.9603, grad_fn=<NllLossBackward>), tensor(1.8956, grad_fn=<NllLossBackward>), tensor(1.9280, grad_fn=<NllLossBackward>), tensor(1.8975, grad_fn=<NllLossBackward>), tensor(1.8810, grad_fn=<NllLossBackward>), tensor(1.9160, grad_fn=<NllLossBackward>), tensor(1.8440, grad_fn=<NllLossBackward>), tensor(1.9020, grad_fn=<NllLossBackward>), tensor(1.8204, grad_fn=<NllLossBackward>), tensor(1.8374, grad_fn=<NllLossBackward>), tensor(1.6289, grad_fn=<NllLossBackward>), tensor(1.8457, grad_fn=<NllLossBackward>), tensor(1.8093, grad_fn=<NllLossBackward>), tensor(1.6804, grad_fn=<NllLossBackward>), tensor(1.6072, grad_fn=<NllLossBackward>), tensor(1.5779, grad_fn=<NllLossBackward>), tensor(1.5963, grad_fn=<NllLossBackward>), tensor(1.5446, grad_fn=<NllLossBackward>), tensor(1.4888, grad_fn=<NllLossBackward>), tensor(1.5211, grad_fn=<NllLossBackward>), tensor(1.4727, grad_fn=<NllLossBackward>), tensor(1.3690, grad_fn=<NllLossBackward>), tensor(1.4729, grad_fn=<NllLossBackward>), tensor(1.3497, grad_fn=<NllLossBackward>), tensor(1.5649, grad_fn=<NllLossBackward>), tensor(1.3066, grad_fn=<NllLossBackward>), tensor(1.4943, grad_fn=<NllLossBackward>), tensor(1.2809, grad_fn=<NllLossBackward>), tensor(1.5321, grad_fn=<NllLossBackward>), tensor(1.4548, grad_fn=<NllLossBackward>), tensor(1.4860, grad_fn=<NllLossBackward>), tensor(1.3273, grad_fn=<NllLossBackward>), tensor(1.5422, grad_fn=<NllLossBackward>), tensor(1.3539, grad_fn=<NllLossBackward>), tensor(1.3611, grad_fn=<NllLossBackward>), tensor(1.3955, grad_fn=<NllLossBackward>), tensor(1.2260, grad_fn=<NllLossBackward>), tensor(1.3149, grad_fn=<NllLossBackward>), tensor(1.3399, grad_fn=<NllLossBackward>), tensor(1.2932, grad_fn=<NllLossBackward>), tensor(1.3172, grad_fn=<NllLossBackward>), tensor(1.3636, grad_fn=<NllLossBackward>), tensor(1.2688, grad_fn=<NllLossBackward>), tensor(1.1826, grad_fn=<NllLossBackward>), tensor(1.2370, grad_fn=<NllLossBackward>), tensor(1.2567, grad_fn=<NllLossBackward>), tensor(1.1430, grad_fn=<NllLossBackward>), tensor(1.2911, grad_fn=<NllLossBackward>), tensor(1.3769, grad_fn=<NllLossBackward>), tensor(1.2382, grad_fn=<NllLossBackward>), tensor(1.2564, grad_fn=<NllLossBackward>), tensor(1.4631, grad_fn=<NllLossBackward>), tensor(1.2402, grad_fn=<NllLossBackward>), tensor(1.2188, grad_fn=<NllLossBackward>), tensor(1.1682, grad_fn=<NllLossBackward>), tensor(1.2477, grad_fn=<NllLossBackward>), tensor(1.1983, grad_fn=<NllLossBackward>), tensor(1.3241, grad_fn=<NllLossBackward>), tensor(1.1194, grad_fn=<NllLossBackward>), tensor(1.2511, grad_fn=<NllLossBackward>), tensor(1.1972, grad_fn=<NllLossBackward>), tensor(1.1851, grad_fn=<NllLossBackward>), tensor(1.2490, grad_fn=<NllLossBackward>), tensor(1.2370, grad_fn=<NllLossBackward>), tensor(1.1155, grad_fn=<NllLossBackward>), tensor(1.1503, grad_fn=<NllLossBackward>), tensor(1.3562, grad_fn=<NllLossBackward>), tensor(1.1386, grad_fn=<NllLossBackward>), tensor(1.0447, grad_fn=<NllLossBackward>), tensor(1.2955, grad_fn=<NllLossBackward>), tensor(1.2455, grad_fn=<NllLossBackward>), tensor(1.0956, grad_fn=<NllLossBackward>), tensor(1.2335, grad_fn=<NllLossBackward>), tensor(1.2146, grad_fn=<NllLossBackward>), tensor(1.2020, grad_fn=<NllLossBackward>), tensor(1.1319, grad_fn=<NllLossBackward>), tensor(1.3328, grad_fn=<NllLossBackward>), tensor(1.1453, grad_fn=<NllLossBackward>), tensor(1.3232, grad_fn=<NllLossBackward>), tensor(1.0146, grad_fn=<NllLossBackward>), tensor(1.0484, grad_fn=<NllLossBackward>), tensor(1.2252, grad_fn=<NllLossBackward>), tensor(1.2678, grad_fn=<NllLossBackward>), tensor(1.1460, grad_fn=<NllLossBackward>), tensor(1.1939, grad_fn=<NllLossBackward>), tensor(1.0203, grad_fn=<NllLossBackward>), tensor(0.9886, grad_fn=<NllLossBackward>), tensor(1.1778, grad_fn=<NllLossBackward>), tensor(1.2147, grad_fn=<NllLossBackward>), tensor(0.9905, grad_fn=<NllLossBackward>), tensor(0.9956, grad_fn=<NllLossBackward>), tensor(1.0448, grad_fn=<NllLossBackward>), tensor(1.1595, grad_fn=<NllLossBackward>), tensor(1.1072, grad_fn=<NllLossBackward>), tensor(1.0071, grad_fn=<NllLossBackward>), tensor(1.0725, grad_fn=<NllLossBackward>), tensor(1.0639, grad_fn=<NllLossBackward>), tensor(1.0384, grad_fn=<NllLossBackward>), tensor(1.2106, grad_fn=<NllLossBackward>), tensor(1.2652, grad_fn=<NllLossBackward>), tensor(1.0839, grad_fn=<NllLossBackward>), tensor(1.1796, grad_fn=<NllLossBackward>), tensor(1.1644, grad_fn=<NllLossBackward>), tensor(1.4651, grad_fn=<NllLossBackward>), tensor(1.0942, grad_fn=<NllLossBackward>), tensor(1.0674, grad_fn=<NllLossBackward>), tensor(1.2032, grad_fn=<NllLossBackward>), tensor(1.0885, grad_fn=<NllLossBackward>), tensor(1.0285, grad_fn=<NllLossBackward>), tensor(1.2296, grad_fn=<NllLossBackward>), tensor(1.0783, grad_fn=<NllLossBackward>), tensor(1.0535, grad_fn=<NllLossBackward>), tensor(1.1348, grad_fn=<NllLossBackward>), tensor(0.9939, grad_fn=<NllLossBackward>), tensor(0.9926, grad_fn=<NllLossBackward>), tensor(0.9810, grad_fn=<NllLossBackward>), tensor(1.0860, grad_fn=<NllLossBackward>), tensor(0.9043, grad_fn=<NllLossBackward>), tensor(1.0410, grad_fn=<NllLossBackward>), tensor(1.3345, grad_fn=<NllLossBackward>), tensor(1.1610, grad_fn=<NllLossBackward>), tensor(1.1818, grad_fn=<NllLossBackward>), tensor(1.1893, grad_fn=<NllLossBackward>), tensor(1.2227, grad_fn=<NllLossBackward>), tensor(1.1833, grad_fn=<NllLossBackward>), tensor(1.2115, grad_fn=<NllLossBackward>), tensor(0.9879, grad_fn=<NllLossBackward>), tensor(1.1353, grad_fn=<NllLossBackward>), tensor(1.1077, grad_fn=<NllLossBackward>), tensor(1.1862, grad_fn=<NllLossBackward>), tensor(0.9400, grad_fn=<NllLossBackward>), tensor(1.2367, grad_fn=<NllLossBackward>), tensor(0.9790, grad_fn=<NllLossBackward>), tensor(1.0570, grad_fn=<NllLossBackward>), tensor(1.1217, grad_fn=<NllLossBackward>), tensor(1.0190, grad_fn=<NllLossBackward>), tensor(0.9173, grad_fn=<NllLossBackward>), tensor(1.1548, grad_fn=<NllLossBackward>), tensor(1.0495, grad_fn=<NllLossBackward>), tensor(1.1003, grad_fn=<NllLossBackward>), tensor(1.1436, grad_fn=<NllLossBackward>), tensor(1.0850, grad_fn=<NllLossBackward>), tensor(1.3128, grad_fn=<NllLossBackward>), tensor(1.1549, grad_fn=<NllLossBackward>), tensor(0.9640, grad_fn=<NllLossBackward>), tensor(0.9143, grad_fn=<NllLossBackward>), tensor(1.0835, grad_fn=<NllLossBackward>), tensor(1.2743, grad_fn=<NllLossBackward>), tensor(0.8145, grad_fn=<NllLossBackward>), tensor(0.9454, grad_fn=<NllLossBackward>), tensor(1.2075, grad_fn=<NllLossBackward>), tensor(1.1171, grad_fn=<NllLossBackward>), tensor(1.0183, grad_fn=<NllLossBackward>), tensor(1.1015, grad_fn=<NllLossBackward>), tensor(1.0629, grad_fn=<NllLossBackward>), tensor(1.0678, grad_fn=<NllLossBackward>), tensor(1.0767, grad_fn=<NllLossBackward>), tensor(1.0112, grad_fn=<NllLossBackward>), tensor(1.1028, grad_fn=<NllLossBackward>), tensor(1.1497, grad_fn=<NllLossBackward>), tensor(0.9968, grad_fn=<NllLossBackward>), tensor(1.1350, grad_fn=<NllLossBackward>), tensor(1.0155, grad_fn=<NllLossBackward>), tensor(1.0114, grad_fn=<NllLossBackward>), tensor(1.0159, grad_fn=<NllLossBackward>), tensor(1.0520, grad_fn=<NllLossBackward>), tensor(1.2503, grad_fn=<NllLossBackward>), tensor(1.1549, grad_fn=<NllLossBackward>), tensor(1.0570, grad_fn=<NllLossBackward>), tensor(0.8954, grad_fn=<NllLossBackward>), tensor(0.9794, grad_fn=<NllLossBackward>), tensor(1.0547, grad_fn=<NllLossBackward>), tensor(1.0020, grad_fn=<NllLossBackward>), tensor(1.1570, grad_fn=<NllLossBackward>), tensor(1.0093, grad_fn=<NllLossBackward>), tensor(1.1886, grad_fn=<NllLossBackward>), tensor(1.0195, grad_fn=<NllLossBackward>), tensor(1.1835, grad_fn=<NllLossBackward>), tensor(0.9413, grad_fn=<NllLossBackward>), tensor(1.1633, grad_fn=<NllLossBackward>), tensor(1.2199, grad_fn=<NllLossBackward>), tensor(1.1042, grad_fn=<NllLossBackward>), tensor(1.0902, grad_fn=<NllLossBackward>), tensor(1.0773, grad_fn=<NllLossBackward>), tensor(1.3100, grad_fn=<NllLossBackward>), tensor(1.0261, grad_fn=<NllLossBackward>), tensor(1.0301, grad_fn=<NllLossBackward>), tensor(1.1428, grad_fn=<NllLossBackward>), tensor(1.1528, grad_fn=<NllLossBackward>), tensor(1.0962, grad_fn=<NllLossBackward>), tensor(0.9663, grad_fn=<NllLossBackward>), tensor(1.0874, grad_fn=<NllLossBackward>), tensor(1.1906, grad_fn=<NllLossBackward>), tensor(0.9894, grad_fn=<NllLossBackward>), tensor(1.2654, grad_fn=<NllLossBackward>), tensor(1.0301, grad_fn=<NllLossBackward>), tensor(1.2458, grad_fn=<NllLossBackward>), tensor(1.1458, grad_fn=<NllLossBackward>), tensor(1.0087, grad_fn=<NllLossBackward>), tensor(1.1371, grad_fn=<NllLossBackward>), tensor(0.9430, grad_fn=<NllLossBackward>), tensor(1.0547, grad_fn=<NllLossBackward>), tensor(1.1046, grad_fn=<NllLossBackward>), tensor(1.0231, grad_fn=<NllLossBackward>), tensor(1.1331, grad_fn=<NllLossBackward>), tensor(1.2070, grad_fn=<NllLossBackward>), tensor(1.0316, grad_fn=<NllLossBackward>), tensor(1.1107, grad_fn=<NllLossBackward>), tensor(1.0824, grad_fn=<NllLossBackward>), tensor(1.2308, grad_fn=<NllLossBackward>), tensor(1.0440, grad_fn=<NllLossBackward>), tensor(0.9359, grad_fn=<NllLossBackward>), tensor(1.2021, grad_fn=<NllLossBackward>), tensor(1.1250, grad_fn=<NllLossBackward>), tensor(1.0410, grad_fn=<NllLossBackward>), tensor(1.1715, grad_fn=<NllLossBackward>), tensor(0.9919, grad_fn=<NllLossBackward>), tensor(1.1848, grad_fn=<NllLossBackward>), tensor(0.9361, grad_fn=<NllLossBackward>), tensor(0.9078, grad_fn=<NllLossBackward>), tensor(1.2783, grad_fn=<NllLossBackward>), tensor(0.8947, grad_fn=<NllLossBackward>), tensor(1.0716, grad_fn=<NllLossBackward>), tensor(1.1724, grad_fn=<NllLossBackward>), tensor(1.1103, grad_fn=<NllLossBackward>), tensor(0.9979, grad_fn=<NllLossBackward>), tensor(1.1311, grad_fn=<NllLossBackward>), tensor(1.1862, grad_fn=<NllLossBackward>), tensor(0.9497, grad_fn=<NllLossBackward>), tensor(0.9041, grad_fn=<NllLossBackward>), tensor(1.3504, grad_fn=<NllLossBackward>), tensor(0.9594, grad_fn=<NllLossBackward>), tensor(1.2312, grad_fn=<NllLossBackward>), tensor(1.0396, grad_fn=<NllLossBackward>), tensor(1.0816, grad_fn=<NllLossBackward>), tensor(1.1492, grad_fn=<NllLossBackward>), tensor(1.1860, grad_fn=<NllLossBackward>), tensor(1.1546, grad_fn=<NllLossBackward>), tensor(0.9939, grad_fn=<NllLossBackward>), tensor(1.1814, grad_fn=<NllLossBackward>), tensor(0.9547, grad_fn=<NllLossBackward>), tensor(1.1230, grad_fn=<NllLossBackward>), tensor(1.0938, grad_fn=<NllLossBackward>), tensor(1.1585, grad_fn=<NllLossBackward>), tensor(0.9481, grad_fn=<NllLossBackward>), tensor(0.9824, grad_fn=<NllLossBackward>), tensor(1.1176, grad_fn=<NllLossBackward>), tensor(0.9170, grad_fn=<NllLossBackward>), tensor(1.1722, grad_fn=<NllLossBackward>), tensor(0.9508, grad_fn=<NllLossBackward>), tensor(1.0436, grad_fn=<NllLossBackward>), tensor(1.2672, grad_fn=<NllLossBackward>), tensor(1.1282, grad_fn=<NllLossBackward>), tensor(1.0728, grad_fn=<NllLossBackward>), tensor(1.0425, grad_fn=<NllLossBackward>), tensor(1.1615, grad_fn=<NllLossBackward>), tensor(0.9080, grad_fn=<NllLossBackward>), tensor(1.0093, grad_fn=<NllLossBackward>), tensor(1.1738, grad_fn=<NllLossBackward>), tensor(1.0988, grad_fn=<NllLossBackward>), tensor(0.9632, grad_fn=<NllLossBackward>), tensor(1.1270, grad_fn=<NllLossBackward>), tensor(1.0701, grad_fn=<NllLossBackward>), tensor(0.9064, grad_fn=<NllLossBackward>), tensor(1.1399, grad_fn=<NllLossBackward>), tensor(1.0649, grad_fn=<NllLossBackward>), tensor(0.9500, grad_fn=<NllLossBackward>), tensor(1.0413, grad_fn=<NllLossBackward>), tensor(1.1166, grad_fn=<NllLossBackward>), tensor(1.0599, grad_fn=<NllLossBackward>), tensor(1.1452, grad_fn=<NllLossBackward>), tensor(1.0923, grad_fn=<NllLossBackward>), tensor(1.0469, grad_fn=<NllLossBackward>), tensor(1.2082, grad_fn=<NllLossBackward>), tensor(1.0604, grad_fn=<NllLossBackward>), tensor(1.0205, grad_fn=<NllLossBackward>), tensor(0.8940, grad_fn=<NllLossBackward>), tensor(0.8681, grad_fn=<NllLossBackward>), tensor(1.1964, grad_fn=<NllLossBackward>), tensor(1.0426, grad_fn=<NllLossBackward>), tensor(1.0083, grad_fn=<NllLossBackward>), tensor(1.1993, grad_fn=<NllLossBackward>), tensor(1.0024, grad_fn=<NllLossBackward>), tensor(1.0325, grad_fn=<NllLossBackward>), tensor(1.0621, grad_fn=<NllLossBackward>), tensor(1.0641, grad_fn=<NllLossBackward>), tensor(1.1582, grad_fn=<NllLossBackward>), tensor(1.0322, grad_fn=<NllLossBackward>), tensor(1.0639, grad_fn=<NllLossBackward>), tensor(1.0700, grad_fn=<NllLossBackward>), tensor(0.9755, grad_fn=<NllLossBackward>), tensor(1.1296, grad_fn=<NllLossBackward>), tensor(1.0708, grad_fn=<NllLossBackward>), tensor(1.1201, grad_fn=<NllLossBackward>), tensor(1.1948, grad_fn=<NllLossBackward>), tensor(1.0559, grad_fn=<NllLossBackward>), tensor(1.2192, grad_fn=<NllLossBackward>), tensor(0.9875, grad_fn=<NllLossBackward>), tensor(1.0949, grad_fn=<NllLossBackward>), tensor(1.1600, grad_fn=<NllLossBackward>), tensor(1.0343, grad_fn=<NllLossBackward>), tensor(1.1117, grad_fn=<NllLossBackward>), tensor(0.9831, grad_fn=<NllLossBackward>), tensor(1.0861, grad_fn=<NllLossBackward>), tensor(0.9203, grad_fn=<NllLossBackward>), tensor(1.0464, grad_fn=<NllLossBackward>), tensor(0.9341, grad_fn=<NllLossBackward>), tensor(0.9943, grad_fn=<NllLossBackward>), tensor(0.9913, grad_fn=<NllLossBackward>), tensor(0.9281, grad_fn=<NllLossBackward>), tensor(1.1910, grad_fn=<NllLossBackward>), tensor(1.1085, grad_fn=<NllLossBackward>), tensor(1.3004, grad_fn=<NllLossBackward>), tensor(0.9219, grad_fn=<NllLossBackward>), tensor(1.1430, grad_fn=<NllLossBackward>), tensor(1.0324, grad_fn=<NllLossBackward>), tensor(1.1698, grad_fn=<NllLossBackward>), tensor(0.8839, grad_fn=<NllLossBackward>), tensor(0.8834, grad_fn=<NllLossBackward>), tensor(1.1199, grad_fn=<NllLossBackward>), tensor(1.0820, grad_fn=<NllLossBackward>), tensor(1.0007, grad_fn=<NllLossBackward>), tensor(1.1039, grad_fn=<NllLossBackward>), tensor(1.0618, grad_fn=<NllLossBackward>), tensor(0.9232, grad_fn=<NllLossBackward>), tensor(0.9768, grad_fn=<NllLossBackward>), tensor(1.0150, grad_fn=<NllLossBackward>), tensor(1.0060, grad_fn=<NllLossBackward>), tensor(1.1437, grad_fn=<NllLossBackward>), tensor(0.9178, grad_fn=<NllLossBackward>), tensor(1.1716, grad_fn=<NllLossBackward>), tensor(0.8848, grad_fn=<NllLossBackward>), tensor(1.0838, grad_fn=<NllLossBackward>), tensor(0.8755, grad_fn=<NllLossBackward>), tensor(1.1892, grad_fn=<NllLossBackward>), tensor(0.9910, grad_fn=<NllLossBackward>), tensor(1.0724, grad_fn=<NllLossBackward>), tensor(0.9755, grad_fn=<NllLossBackward>), tensor(1.0717, grad_fn=<NllLossBackward>), tensor(0.9369, grad_fn=<NllLossBackward>), tensor(1.1583, grad_fn=<NllLossBackward>), tensor(1.0792, grad_fn=<NllLossBackward>), tensor(1.0483, grad_fn=<NllLossBackward>), tensor(0.9944, grad_fn=<NllLossBackward>), tensor(1.1183, grad_fn=<NllLossBackward>), tensor(1.1547, grad_fn=<NllLossBackward>), tensor(1.0218, grad_fn=<NllLossBackward>), tensor(0.8870, grad_fn=<NllLossBackward>), tensor(1.1253, grad_fn=<NllLossBackward>), tensor(0.8413, grad_fn=<NllLossBackward>), tensor(1.0865, grad_fn=<NllLossBackward>), tensor(1.1421, grad_fn=<NllLossBackward>), tensor(1.1301, grad_fn=<NllLossBackward>), tensor(1.1455, grad_fn=<NllLossBackward>), tensor(0.9921, grad_fn=<NllLossBackward>), tensor(1.0495, grad_fn=<NllLossBackward>), tensor(1.1621, grad_fn=<NllLossBackward>), tensor(1.0663, grad_fn=<NllLossBackward>), tensor(1.1870, grad_fn=<NllLossBackward>), tensor(0.8749, grad_fn=<NllLossBackward>), tensor(1.2041, grad_fn=<NllLossBackward>), tensor(0.8944, grad_fn=<NllLossBackward>), tensor(0.9617, grad_fn=<NllLossBackward>), tensor(1.1304, grad_fn=<NllLossBackward>), tensor(1.1431, grad_fn=<NllLossBackward>), tensor(1.1791, grad_fn=<NllLossBackward>), tensor(1.0288, grad_fn=<NllLossBackward>), tensor(1.0624, grad_fn=<NllLossBackward>), tensor(1.2119, grad_fn=<NllLossBackward>), tensor(1.0178, grad_fn=<NllLossBackward>), tensor(1.0265, grad_fn=<NllLossBackward>), tensor(1.0571, grad_fn=<NllLossBackward>), tensor(1.1950, grad_fn=<NllLossBackward>), tensor(1.0464, grad_fn=<NllLossBackward>), tensor(0.9762, grad_fn=<NllLossBackward>), tensor(1.0020, grad_fn=<NllLossBackward>), tensor(0.9644, grad_fn=<NllLossBackward>), tensor(1.1475, grad_fn=<NllLossBackward>), tensor(0.9849, grad_fn=<NllLossBackward>), tensor(1.0417, grad_fn=<NllLossBackward>), tensor(1.1830, grad_fn=<NllLossBackward>), tensor(0.9758, grad_fn=<NllLossBackward>), tensor(1.0114, grad_fn=<NllLossBackward>), tensor(0.9938, grad_fn=<NllLossBackward>), tensor(1.1458, grad_fn=<NllLossBackward>), tensor(1.1587, grad_fn=<NllLossBackward>), tensor(1.0713, grad_fn=<NllLossBackward>), tensor(1.1667, grad_fn=<NllLossBackward>), tensor(0.8669, grad_fn=<NllLossBackward>), tensor(1.0542, grad_fn=<NllLossBackward>), tensor(0.8520, grad_fn=<NllLossBackward>), tensor(1.0289, grad_fn=<NllLossBackward>), tensor(1.0067, grad_fn=<NllLossBackward>), tensor(1.0733, grad_fn=<NllLossBackward>), tensor(1.0675, grad_fn=<NllLossBackward>), tensor(1.2175, grad_fn=<NllLossBackward>), tensor(1.1367, grad_fn=<NllLossBackward>), tensor(1.0153, grad_fn=<NllLossBackward>), tensor(1.2485, grad_fn=<NllLossBackward>), tensor(0.8883, grad_fn=<NllLossBackward>), tensor(1.1108, grad_fn=<NllLossBackward>), tensor(1.0018, grad_fn=<NllLossBackward>), tensor(0.9707, grad_fn=<NllLossBackward>), tensor(1.0772, grad_fn=<NllLossBackward>), tensor(1.1762, grad_fn=<NllLossBackward>), tensor(1.0581, grad_fn=<NllLossBackward>), tensor(0.9949, grad_fn=<NllLossBackward>), tensor(1.0184, grad_fn=<NllLossBackward>), tensor(1.0476, grad_fn=<NllLossBackward>), tensor(0.9988, grad_fn=<NllLossBackward>), tensor(1.0384, grad_fn=<NllLossBackward>), tensor(0.9520, grad_fn=<NllLossBackward>), tensor(1.0327, grad_fn=<NllLossBackward>), tensor(1.0354, grad_fn=<NllLossBackward>), tensor(1.0937, grad_fn=<NllLossBackward>), tensor(1.0659, grad_fn=<NllLossBackward>), tensor(0.9909, grad_fn=<NllLossBackward>), tensor(1.1167, grad_fn=<NllLossBackward>), tensor(1.0432, grad_fn=<NllLossBackward>), tensor(0.9493, grad_fn=<NllLossBackward>), tensor(1.0331, grad_fn=<NllLossBackward>), tensor(1.0260, grad_fn=<NllLossBackward>), tensor(1.0519, grad_fn=<NllLossBackward>), tensor(1.1651, grad_fn=<NllLossBackward>), tensor(1.1717, grad_fn=<NllLossBackward>), tensor(1.0464, grad_fn=<NllLossBackward>), tensor(1.0812, grad_fn=<NllLossBackward>), tensor(1.1145, grad_fn=<NllLossBackward>), tensor(1.0886, grad_fn=<NllLossBackward>), tensor(1.0513, grad_fn=<NllLossBackward>), tensor(1.1872, grad_fn=<NllLossBackward>), tensor(1.0002, grad_fn=<NllLossBackward>), tensor(0.9455, grad_fn=<NllLossBackward>), tensor(0.8424, grad_fn=<NllLossBackward>), tensor(1.0522, grad_fn=<NllLossBackward>), tensor(0.9537, grad_fn=<NllLossBackward>), tensor(1.0867, grad_fn=<NllLossBackward>), tensor(0.9565, grad_fn=<NllLossBackward>), tensor(0.8919, grad_fn=<NllLossBackward>), tensor(1.1051, grad_fn=<NllLossBackward>), tensor(1.0104, grad_fn=<NllLossBackward>), tensor(1.1674, grad_fn=<NllLossBackward>), tensor(1.1343, grad_fn=<NllLossBackward>), tensor(1.1380, grad_fn=<NllLossBackward>), tensor(0.9370, grad_fn=<NllLossBackward>), tensor(1.0452, grad_fn=<NllLossBackward>), tensor(1.0372, grad_fn=<NllLossBackward>), tensor(1.1607, grad_fn=<NllLossBackward>), tensor(0.9468, grad_fn=<NllLossBackward>), tensor(1.1307, grad_fn=<NllLossBackward>), tensor(1.0876, grad_fn=<NllLossBackward>), tensor(1.1671, grad_fn=<NllLossBackward>), tensor(1.0753, grad_fn=<NllLossBackward>), tensor(1.0480, grad_fn=<NllLossBackward>), tensor(0.9292, grad_fn=<NllLossBackward>), tensor(1.0817, grad_fn=<NllLossBackward>), tensor(0.8511, grad_fn=<NllLossBackward>), tensor(1.0249, grad_fn=<NllLossBackward>), tensor(0.8652, grad_fn=<NllLossBackward>), tensor(0.8994, grad_fn=<NllLossBackward>), tensor(1.1347, grad_fn=<NllLossBackward>), tensor(0.9410, grad_fn=<NllLossBackward>), tensor(0.9841, grad_fn=<NllLossBackward>), tensor(1.1299, grad_fn=<NllLossBackward>), tensor(1.0923, grad_fn=<NllLossBackward>), tensor(1.1613, grad_fn=<NllLossBackward>), tensor(1.0992, grad_fn=<NllLossBackward>), tensor(1.0967, grad_fn=<NllLossBackward>), tensor(1.3366, grad_fn=<NllLossBackward>), tensor(0.9950, grad_fn=<NllLossBackward>), tensor(1.0426, grad_fn=<NllLossBackward>), tensor(0.9523, grad_fn=<NllLossBackward>), tensor(0.8478, grad_fn=<NllLossBackward>), tensor(0.9490, grad_fn=<NllLossBackward>), tensor(1.1405, grad_fn=<NllLossBackward>), tensor(0.8435, grad_fn=<NllLossBackward>), tensor(1.0489, grad_fn=<NllLossBackward>), tensor(1.0400, grad_fn=<NllLossBackward>), tensor(1.0911, grad_fn=<NllLossBackward>), tensor(0.8944, grad_fn=<NllLossBackward>), tensor(0.9696, grad_fn=<NllLossBackward>), tensor(0.9294, grad_fn=<NllLossBackward>), tensor(0.9285, grad_fn=<NllLossBackward>), tensor(0.9148, grad_fn=<NllLossBackward>), tensor(0.8785, grad_fn=<NllLossBackward>), tensor(1.1131, grad_fn=<NllLossBackward>), tensor(1.1381, grad_fn=<NllLossBackward>), tensor(1.0580, grad_fn=<NllLossBackward>), tensor(1.0895, grad_fn=<NllLossBackward>), tensor(0.9684, grad_fn=<NllLossBackward>), tensor(0.9902, grad_fn=<NllLossBackward>), tensor(1.1359, grad_fn=<NllLossBackward>), tensor(1.1160, grad_fn=<NllLossBackward>), tensor(1.0327, grad_fn=<NllLossBackward>), tensor(0.9942, grad_fn=<NllLossBackward>), tensor(1.0287, grad_fn=<NllLossBackward>), tensor(1.0411, grad_fn=<NllLossBackward>), tensor(1.0488, grad_fn=<NllLossBackward>), tensor(0.8380, grad_fn=<NllLossBackward>), tensor(0.9741, grad_fn=<NllLossBackward>), tensor(0.9878, grad_fn=<NllLossBackward>), tensor(0.8495, grad_fn=<NllLossBackward>), tensor(1.0365, grad_fn=<NllLossBackward>), tensor(1.1952, grad_fn=<NllLossBackward>), tensor(0.9392, grad_fn=<NllLossBackward>), tensor(0.9939, grad_fn=<NllLossBackward>), tensor(0.8871, grad_fn=<NllLossBackward>), tensor(1.2564, grad_fn=<NllLossBackward>), tensor(0.9263, grad_fn=<NllLossBackward>), tensor(0.8836, grad_fn=<NllLossBackward>), tensor(1.0644, grad_fn=<NllLossBackward>), tensor(1.0009, grad_fn=<NllLossBackward>), tensor(1.2701, grad_fn=<NllLossBackward>), tensor(0.9427, grad_fn=<NllLossBackward>), tensor(0.9731, grad_fn=<NllLossBackward>), tensor(0.9783, grad_fn=<NllLossBackward>), tensor(0.8981, grad_fn=<NllLossBackward>), tensor(1.0784, grad_fn=<NllLossBackward>), tensor(0.9336, grad_fn=<NllLossBackward>), tensor(0.8344, grad_fn=<NllLossBackward>), tensor(1.1980, grad_fn=<NllLossBackward>), tensor(0.9079, grad_fn=<NllLossBackward>), tensor(1.1097, grad_fn=<NllLossBackward>), tensor(1.0694, grad_fn=<NllLossBackward>), tensor(0.9133, grad_fn=<NllLossBackward>), tensor(1.1218, grad_fn=<NllLossBackward>), tensor(1.1351, grad_fn=<NllLossBackward>), tensor(1.0583, grad_fn=<NllLossBackward>), tensor(1.2227, grad_fn=<NllLossBackward>), tensor(0.9934, grad_fn=<NllLossBackward>), tensor(1.1611, grad_fn=<NllLossBackward>), tensor(0.9818, grad_fn=<NllLossBackward>), tensor(1.1152, grad_fn=<NllLossBackward>), tensor(1.1297, grad_fn=<NllLossBackward>), tensor(0.9443, grad_fn=<NllLossBackward>), tensor(1.1694, grad_fn=<NllLossBackward>), tensor(1.1728, grad_fn=<NllLossBackward>), tensor(1.0397, grad_fn=<NllLossBackward>), tensor(1.0061, grad_fn=<NllLossBackward>), tensor(0.9687, grad_fn=<NllLossBackward>), tensor(1.0728, grad_fn=<NllLossBackward>), tensor(1.0503, grad_fn=<NllLossBackward>), tensor(0.8548, grad_fn=<NllLossBackward>), tensor(1.1091, grad_fn=<NllLossBackward>), tensor(0.9060, grad_fn=<NllLossBackward>), tensor(0.9837, grad_fn=<NllLossBackward>), tensor(0.9921, grad_fn=<NllLossBackward>), tensor(1.0574, grad_fn=<NllLossBackward>), tensor(1.0477, grad_fn=<NllLossBackward>), tensor(1.0706, grad_fn=<NllLossBackward>), tensor(1.0516, grad_fn=<NllLossBackward>), tensor(0.9373, grad_fn=<NllLossBackward>), tensor(0.9085, grad_fn=<NllLossBackward>), tensor(0.9557, grad_fn=<NllLossBackward>), tensor(1.1180, grad_fn=<NllLossBackward>), tensor(1.0112, grad_fn=<NllLossBackward>), tensor(1.0450, grad_fn=<NllLossBackward>), tensor(1.0862, grad_fn=<NllLossBackward>), tensor(1.0690, grad_fn=<NllLossBackward>), tensor(1.0234, grad_fn=<NllLossBackward>), tensor(0.9242, grad_fn=<NllLossBackward>), tensor(1.0318, grad_fn=<NllLossBackward>), tensor(0.9344, grad_fn=<NllLossBackward>), tensor(1.1871, grad_fn=<NllLossBackward>), tensor(1.0306, grad_fn=<NllLossBackward>), tensor(0.9483, grad_fn=<NllLossBackward>), tensor(0.9553, grad_fn=<NllLossBackward>), tensor(1.0032, grad_fn=<NllLossBackward>), tensor(1.0867, grad_fn=<NllLossBackward>), tensor(0.9711, grad_fn=<NllLossBackward>), tensor(0.9516, grad_fn=<NllLossBackward>), tensor(0.8076, grad_fn=<NllLossBackward>), tensor(1.1197, grad_fn=<NllLossBackward>), tensor(1.0672, grad_fn=<NllLossBackward>), tensor(1.0465, grad_fn=<NllLossBackward>), tensor(1.1248, grad_fn=<NllLossBackward>), tensor(1.0449, grad_fn=<NllLossBackward>), tensor(1.0555, grad_fn=<NllLossBackward>), tensor(0.9311, grad_fn=<NllLossBackward>), tensor(1.0298, grad_fn=<NllLossBackward>), tensor(1.1594, grad_fn=<NllLossBackward>), tensor(0.9999, grad_fn=<NllLossBackward>), tensor(1.0716, grad_fn=<NllLossBackward>), tensor(1.0616, grad_fn=<NllLossBackward>), tensor(1.1206, grad_fn=<NllLossBackward>), tensor(1.2470, grad_fn=<NllLossBackward>), tensor(1.0008, grad_fn=<NllLossBackward>), tensor(0.9993, grad_fn=<NllLossBackward>), tensor(1.0717, grad_fn=<NllLossBackward>), tensor(0.9493, grad_fn=<NllLossBackward>), tensor(0.9383, grad_fn=<NllLossBackward>), tensor(1.1849, grad_fn=<NllLossBackward>), tensor(1.0752, grad_fn=<NllLossBackward>), tensor(1.1760, grad_fn=<NllLossBackward>), tensor(1.1354, grad_fn=<NllLossBackward>), tensor(1.0883, grad_fn=<NllLossBackward>), tensor(1.0512, grad_fn=<NllLossBackward>), tensor(0.8065, grad_fn=<NllLossBackward>), tensor(1.3150, grad_fn=<NllLossBackward>), tensor(1.0509, grad_fn=<NllLossBackward>), tensor(1.1337, grad_fn=<NllLossBackward>), tensor(1.0441, grad_fn=<NllLossBackward>), tensor(0.9831, grad_fn=<NllLossBackward>), tensor(1.0843, grad_fn=<NllLossBackward>), tensor(0.8234, grad_fn=<NllLossBackward>), tensor(0.9119, grad_fn=<NllLossBackward>), tensor(1.0063, grad_fn=<NllLossBackward>), tensor(0.9425, grad_fn=<NllLossBackward>), tensor(0.9964, grad_fn=<NllLossBackward>), tensor(0.9201, grad_fn=<NllLossBackward>), tensor(1.0382, grad_fn=<NllLossBackward>), tensor(0.9913, grad_fn=<NllLossBackward>), tensor(1.0498, grad_fn=<NllLossBackward>), tensor(1.0155, grad_fn=<NllLossBackward>), tensor(1.1531, grad_fn=<NllLossBackward>), tensor(1.3119, grad_fn=<NllLossBackward>), tensor(0.9675, grad_fn=<NllLossBackward>), tensor(0.9919, grad_fn=<NllLossBackward>), tensor(1.1368, grad_fn=<NllLossBackward>), tensor(1.0060, grad_fn=<NllLossBackward>), tensor(1.0334, grad_fn=<NllLossBackward>), tensor(1.0391, grad_fn=<NllLossBackward>), tensor(1.0819, grad_fn=<NllLossBackward>), tensor(0.9488, grad_fn=<NllLossBackward>), tensor(0.9413, grad_fn=<NllLossBackward>), tensor(1.0279, grad_fn=<NllLossBackward>), tensor(1.0301, grad_fn=<NllLossBackward>), tensor(1.0286, grad_fn=<NllLossBackward>), tensor(0.8279, grad_fn=<NllLossBackward>), tensor(0.9894, grad_fn=<NllLossBackward>), tensor(1.1171, grad_fn=<NllLossBackward>), tensor(0.9503, grad_fn=<NllLossBackward>), tensor(1.0212, grad_fn=<NllLossBackward>), tensor(0.8983, grad_fn=<NllLossBackward>), tensor(0.9777, grad_fn=<NllLossBackward>), tensor(1.1901, grad_fn=<NllLossBackward>), tensor(0.9884, grad_fn=<NllLossBackward>), tensor(0.9783, grad_fn=<NllLossBackward>), tensor(1.1015, grad_fn=<NllLossBackward>), tensor(0.9111, grad_fn=<NllLossBackward>), tensor(0.8921, grad_fn=<NllLossBackward>), tensor(1.0546, grad_fn=<NllLossBackward>), tensor(0.9292, grad_fn=<NllLossBackward>), tensor(0.9633, grad_fn=<NllLossBackward>), tensor(0.9189, grad_fn=<NllLossBackward>), tensor(0.8727, grad_fn=<NllLossBackward>), tensor(1.2799, grad_fn=<NllLossBackward>), tensor(0.8933, grad_fn=<NllLossBackward>), tensor(1.2079, grad_fn=<NllLossBackward>), tensor(0.9879, grad_fn=<NllLossBackward>), tensor(0.9051, grad_fn=<NllLossBackward>), tensor(1.0378, grad_fn=<NllLossBackward>), tensor(1.0528, grad_fn=<NllLossBackward>), tensor(0.9989, grad_fn=<NllLossBackward>), tensor(1.1449, grad_fn=<NllLossBackward>), tensor(0.9930, grad_fn=<NllLossBackward>), tensor(1.0568, grad_fn=<NllLossBackward>), tensor(0.9631, grad_fn=<NllLossBackward>), tensor(1.0076, grad_fn=<NllLossBackward>), tensor(0.9216, grad_fn=<NllLossBackward>), tensor(1.0537, grad_fn=<NllLossBackward>), tensor(0.8759, grad_fn=<NllLossBackward>), tensor(1.1347, grad_fn=<NllLossBackward>), tensor(1.2133, grad_fn=<NllLossBackward>), tensor(1.0308, grad_fn=<NllLossBackward>), tensor(1.0366, grad_fn=<NllLossBackward>), tensor(0.9769, grad_fn=<NllLossBackward>), tensor(1.0762, grad_fn=<NllLossBackward>), tensor(1.1262, grad_fn=<NllLossBackward>), tensor(1.0289, grad_fn=<NllLossBackward>), tensor(0.9527, grad_fn=<NllLossBackward>), tensor(0.9641, grad_fn=<NllLossBackward>), tensor(0.8444, grad_fn=<NllLossBackward>), tensor(1.0979, grad_fn=<NllLossBackward>), tensor(1.0648, grad_fn=<NllLossBackward>), tensor(1.1734, grad_fn=<NllLossBackward>), tensor(1.0370, grad_fn=<NllLossBackward>), tensor(0.8469, grad_fn=<NllLossBackward>), tensor(1.0991, grad_fn=<NllLossBackward>), tensor(1.0101, grad_fn=<NllLossBackward>), tensor(0.9642, grad_fn=<NllLossBackward>), tensor(1.0237, grad_fn=<NllLossBackward>), tensor(1.1949, grad_fn=<NllLossBackward>), tensor(0.9331, grad_fn=<NllLossBackward>), tensor(0.9499, grad_fn=<NllLossBackward>), tensor(1.0635, grad_fn=<NllLossBackward>), tensor(1.0871, grad_fn=<NllLossBackward>), tensor(1.0617, grad_fn=<NllLossBackward>), tensor(1.0751, grad_fn=<NllLossBackward>), tensor(1.0281, grad_fn=<NllLossBackward>), tensor(1.0235, grad_fn=<NllLossBackward>), tensor(1.0576, grad_fn=<NllLossBackward>), tensor(1.1738, grad_fn=<NllLossBackward>), tensor(0.8774, grad_fn=<NllLossBackward>), tensor(0.9771, grad_fn=<NllLossBackward>), tensor(1.1023, grad_fn=<NllLossBackward>), tensor(1.1417, grad_fn=<NllLossBackward>), tensor(1.0873, grad_fn=<NllLossBackward>), tensor(1.0503, grad_fn=<NllLossBackward>), tensor(1.1253, grad_fn=<NllLossBackward>), tensor(0.8775, grad_fn=<NllLossBackward>), tensor(0.9615, grad_fn=<NllLossBackward>), tensor(1.2012, grad_fn=<NllLossBackward>), tensor(0.9895, grad_fn=<NllLossBackward>), tensor(1.0684, grad_fn=<NllLossBackward>), tensor(1.0715, grad_fn=<NllLossBackward>), tensor(0.7827, grad_fn=<NllLossBackward>), tensor(0.9294, grad_fn=<NllLossBackward>), tensor(0.9933, grad_fn=<NllLossBackward>), tensor(0.9919, grad_fn=<NllLossBackward>), tensor(0.9857, grad_fn=<NllLossBackward>), tensor(1.2275, grad_fn=<NllLossBackward>), tensor(1.1238, grad_fn=<NllLossBackward>), tensor(1.0343, grad_fn=<NllLossBackward>), tensor(1.0698, grad_fn=<NllLossBackward>), tensor(1.0253, grad_fn=<NllLossBackward>), tensor(1.1787, grad_fn=<NllLossBackward>), tensor(1.0274, grad_fn=<NllLossBackward>), tensor(0.9609, grad_fn=<NllLossBackward>), tensor(1.0180, grad_fn=<NllLossBackward>), tensor(0.8662, grad_fn=<NllLossBackward>), tensor(0.9932, grad_fn=<NllLossBackward>), tensor(0.9816, grad_fn=<NllLossBackward>), tensor(0.9369, grad_fn=<NllLossBackward>), tensor(1.0403, grad_fn=<NllLossBackward>), tensor(0.8922, grad_fn=<NllLossBackward>), tensor(1.1789, grad_fn=<NllLossBackward>), tensor(0.9322, grad_fn=<NllLossBackward>), tensor(0.9321, grad_fn=<NllLossBackward>), tensor(0.9814, grad_fn=<NllLossBackward>), tensor(1.0812, grad_fn=<NllLossBackward>), tensor(1.0247, grad_fn=<NllLossBackward>), tensor(0.8617, grad_fn=<NllLossBackward>), tensor(0.9918, grad_fn=<NllLossBackward>), tensor(1.1419, grad_fn=<NllLossBackward>), tensor(0.9828, grad_fn=<NllLossBackward>), tensor(1.0512, grad_fn=<NllLossBackward>), tensor(1.0362, grad_fn=<NllLossBackward>), tensor(0.9109, grad_fn=<NllLossBackward>), tensor(1.1961, grad_fn=<NllLossBackward>), tensor(0.8312, grad_fn=<NllLossBackward>), tensor(0.8708, grad_fn=<NllLossBackward>), tensor(1.0642, grad_fn=<NllLossBackward>), tensor(1.0287, grad_fn=<NllLossBackward>), tensor(0.9758, grad_fn=<NllLossBackward>), tensor(1.2738, grad_fn=<NllLossBackward>), tensor(0.9784, grad_fn=<NllLossBackward>), tensor(1.0237, grad_fn=<NllLossBackward>), tensor(0.9873, grad_fn=<NllLossBackward>), tensor(0.9435, grad_fn=<NllLossBackward>), tensor(0.9645, grad_fn=<NllLossBackward>), tensor(0.9819, grad_fn=<NllLossBackward>), tensor(0.8938, grad_fn=<NllLossBackward>), tensor(1.2146, grad_fn=<NllLossBackward>), tensor(0.9710, grad_fn=<NllLossBackward>), tensor(1.0146, grad_fn=<NllLossBackward>), tensor(1.0155, grad_fn=<NllLossBackward>), tensor(1.0069, grad_fn=<NllLossBackward>), tensor(1.3504, grad_fn=<NllLossBackward>), tensor(1.1757, grad_fn=<NllLossBackward>), tensor(1.0925, grad_fn=<NllLossBackward>), tensor(1.0177, grad_fn=<NllLossBackward>), tensor(0.9345, grad_fn=<NllLossBackward>), tensor(1.0220, grad_fn=<NllLossBackward>), tensor(0.9851, grad_fn=<NllLossBackward>), tensor(0.9319, grad_fn=<NllLossBackward>), tensor(1.0810, grad_fn=<NllLossBackward>), tensor(0.8863, grad_fn=<NllLossBackward>), tensor(0.9048, grad_fn=<NllLossBackward>), tensor(0.8830, grad_fn=<NllLossBackward>), tensor(1.2578, grad_fn=<NllLossBackward>), tensor(0.9796, grad_fn=<NllLossBackward>), tensor(0.9244, grad_fn=<NllLossBackward>), tensor(1.0014, grad_fn=<NllLossBackward>), tensor(1.0286, grad_fn=<NllLossBackward>), tensor(0.9939, grad_fn=<NllLossBackward>), tensor(1.0299, grad_fn=<NllLossBackward>), tensor(0.9008, grad_fn=<NllLossBackward>), tensor(1.1257, grad_fn=<NllLossBackward>), tensor(0.9424, grad_fn=<NllLossBackward>), tensor(1.0508, grad_fn=<NllLossBackward>), tensor(1.0335, grad_fn=<NllLossBackward>), tensor(1.0084, grad_fn=<NllLossBackward>), tensor(1.0517, grad_fn=<NllLossBackward>), tensor(1.1841, grad_fn=<NllLossBackward>), tensor(1.0703, grad_fn=<NllLossBackward>), tensor(0.9437, grad_fn=<NllLossBackward>), tensor(1.0820, grad_fn=<NllLossBackward>), tensor(0.8370, grad_fn=<NllLossBackward>), tensor(1.1311, grad_fn=<NllLossBackward>), tensor(1.0948, grad_fn=<NllLossBackward>), tensor(1.0107, grad_fn=<NllLossBackward>), tensor(0.8510, grad_fn=<NllLossBackward>), tensor(1.0433, grad_fn=<NllLossBackward>), tensor(1.0076, grad_fn=<NllLossBackward>), tensor(0.9969, grad_fn=<NllLossBackward>), tensor(0.9267, grad_fn=<NllLossBackward>), tensor(0.9980, grad_fn=<NllLossBackward>), tensor(1.1467, grad_fn=<NllLossBackward>), tensor(1.0851, grad_fn=<NllLossBackward>), tensor(0.8655, grad_fn=<NllLossBackward>), tensor(1.0114, grad_fn=<NllLossBackward>), tensor(0.9776, grad_fn=<NllLossBackward>), tensor(0.9686, grad_fn=<NllLossBackward>), tensor(0.8671, grad_fn=<NllLossBackward>), tensor(1.0109, grad_fn=<NllLossBackward>), tensor(1.0801, grad_fn=<NllLossBackward>), tensor(1.0427, grad_fn=<NllLossBackward>), tensor(0.9021, grad_fn=<NllLossBackward>), tensor(1.0991, grad_fn=<NllLossBackward>), tensor(1.0843, grad_fn=<NllLossBackward>), tensor(1.0176, grad_fn=<NllLossBackward>), tensor(1.0968, grad_fn=<NllLossBackward>), tensor(1.0524, grad_fn=<NllLossBackward>), tensor(0.9729, grad_fn=<NllLossBackward>), tensor(1.0980, grad_fn=<NllLossBackward>), tensor(1.1179, grad_fn=<NllLossBackward>), tensor(0.9590, grad_fn=<NllLossBackward>), tensor(1.1672, grad_fn=<NllLossBackward>), tensor(0.9906, grad_fn=<NllLossBackward>), tensor(0.7161, grad_fn=<NllLossBackward>), tensor(1.0842, grad_fn=<NllLossBackward>), tensor(1.1102, grad_fn=<NllLossBackward>), tensor(0.9393, grad_fn=<NllLossBackward>), tensor(1.0538, grad_fn=<NllLossBackward>), tensor(1.0412, grad_fn=<NllLossBackward>), tensor(0.9517, grad_fn=<NllLossBackward>), tensor(0.8928, grad_fn=<NllLossBackward>), tensor(0.9891, grad_fn=<NllLossBackward>), tensor(0.9386, grad_fn=<NllLossBackward>), tensor(1.0467, grad_fn=<NllLossBackward>), tensor(1.0469, grad_fn=<NllLossBackward>), tensor(1.0493, grad_fn=<NllLossBackward>), tensor(0.9987, grad_fn=<NllLossBackward>), tensor(0.9231, grad_fn=<NllLossBackward>), tensor(1.1419, grad_fn=<NllLossBackward>), tensor(1.0032, grad_fn=<NllLossBackward>), tensor(0.8829, grad_fn=<NllLossBackward>), tensor(0.7863, grad_fn=<NllLossBackward>), tensor(1.0518, grad_fn=<NllLossBackward>), tensor(0.9187, grad_fn=<NllLossBackward>), tensor(0.9034, grad_fn=<NllLossBackward>), tensor(1.1015, grad_fn=<NllLossBackward>), tensor(1.0213, grad_fn=<NllLossBackward>), tensor(0.9869, grad_fn=<NllLossBackward>), tensor(0.8948, grad_fn=<NllLossBackward>), tensor(0.8948, grad_fn=<NllLossBackward>), tensor(1.0528, grad_fn=<NllLossBackward>), tensor(0.9747, grad_fn=<NllLossBackward>), tensor(1.0270, grad_fn=<NllLossBackward>), tensor(0.9598, grad_fn=<NllLossBackward>), tensor(1.0300, grad_fn=<NllLossBackward>), tensor(1.0593, grad_fn=<NllLossBackward>), tensor(0.8998, grad_fn=<NllLossBackward>), tensor(0.9014, grad_fn=<NllLossBackward>), tensor(0.8463, grad_fn=<NllLossBackward>), tensor(0.9304, grad_fn=<NllLossBackward>), tensor(1.0558, grad_fn=<NllLossBackward>), tensor(1.0223, grad_fn=<NllLossBackward>), tensor(0.7732, grad_fn=<NllLossBackward>), tensor(1.1861, grad_fn=<NllLossBackward>), tensor(1.0609, grad_fn=<NllLossBackward>), tensor(1.1185, grad_fn=<NllLossBackward>), tensor(0.9131, grad_fn=<NllLossBackward>), tensor(1.0636, grad_fn=<NllLossBackward>), tensor(1.0855, grad_fn=<NllLossBackward>), tensor(1.0714, grad_fn=<NllLossBackward>), tensor(0.9525, grad_fn=<NllLossBackward>), tensor(1.0965, grad_fn=<NllLossBackward>), tensor(1.2043, grad_fn=<NllLossBackward>), tensor(0.9718, grad_fn=<NllLossBackward>), tensor(0.9721, grad_fn=<NllLossBackward>), tensor(1.0567, grad_fn=<NllLossBackward>), tensor(1.0900, grad_fn=<NllLossBackward>), tensor(1.0176, grad_fn=<NllLossBackward>), tensor(0.7927, grad_fn=<NllLossBackward>), tensor(0.9297, grad_fn=<NllLossBackward>), tensor(1.0487, grad_fn=<NllLossBackward>), tensor(1.1664, grad_fn=<NllLossBackward>), tensor(1.1111, grad_fn=<NllLossBackward>), tensor(1.1077, grad_fn=<NllLossBackward>), tensor(0.8759, grad_fn=<NllLossBackward>), tensor(0.9899, grad_fn=<NllLossBackward>), tensor(1.0393, grad_fn=<NllLossBackward>), tensor(1.0423, grad_fn=<NllLossBackward>), tensor(1.0238, grad_fn=<NllLossBackward>), tensor(1.0701, grad_fn=<NllLossBackward>), tensor(1.0432, grad_fn=<NllLossBackward>), tensor(0.9852, grad_fn=<NllLossBackward>), tensor(1.0714, grad_fn=<NllLossBackward>), tensor(1.0218, grad_fn=<NllLossBackward>), tensor(0.9885, grad_fn=<NllLossBackward>), tensor(1.1673, grad_fn=<NllLossBackward>), tensor(1.0464, grad_fn=<NllLossBackward>), tensor(0.9926, grad_fn=<NllLossBackward>), tensor(0.8895, grad_fn=<NllLossBackward>), tensor(0.9816, grad_fn=<NllLossBackward>), tensor(0.9747, grad_fn=<NllLossBackward>), tensor(1.0575, grad_fn=<NllLossBackward>), tensor(0.9611, grad_fn=<NllLossBackward>), tensor(1.0885, grad_fn=<NllLossBackward>), tensor(0.9562, grad_fn=<NllLossBackward>), tensor(1.0583, grad_fn=<NllLossBackward>), tensor(1.0075, grad_fn=<NllLossBackward>), tensor(1.1380, grad_fn=<NllLossBackward>), tensor(0.8464, grad_fn=<NllLossBackward>), tensor(1.0155, grad_fn=<NllLossBackward>), tensor(1.0888, grad_fn=<NllLossBackward>), tensor(0.8930, grad_fn=<NllLossBackward>), tensor(1.1109, grad_fn=<NllLossBackward>), tensor(1.0594, grad_fn=<NllLossBackward>), tensor(1.0131, grad_fn=<NllLossBackward>), tensor(1.0296, grad_fn=<NllLossBackward>), tensor(0.7947, grad_fn=<NllLossBackward>), tensor(1.1453, grad_fn=<NllLossBackward>), tensor(0.9561, grad_fn=<NllLossBackward>), tensor(1.0241, grad_fn=<NllLossBackward>), tensor(0.9673, grad_fn=<NllLossBackward>), tensor(0.8927, grad_fn=<NllLossBackward>), tensor(1.1652, grad_fn=<NllLossBackward>), tensor(0.8565, grad_fn=<NllLossBackward>), tensor(1.0585, grad_fn=<NllLossBackward>), tensor(0.9984, grad_fn=<NllLossBackward>), tensor(0.9352, grad_fn=<NllLossBackward>), tensor(0.9215, grad_fn=<NllLossBackward>), tensor(1.1472, grad_fn=<NllLossBackward>), tensor(0.8642, grad_fn=<NllLossBackward>), tensor(0.9493, grad_fn=<NllLossBackward>), tensor(1.0566, grad_fn=<NllLossBackward>), tensor(1.0153, grad_fn=<NllLossBackward>), tensor(0.9936, grad_fn=<NllLossBackward>), tensor(0.9506, grad_fn=<NllLossBackward>), tensor(0.9138, grad_fn=<NllLossBackward>), tensor(0.9810, grad_fn=<NllLossBackward>), tensor(1.1067, grad_fn=<NllLossBackward>), tensor(0.8941, grad_fn=<NllLossBackward>), tensor(1.0848, grad_fn=<NllLossBackward>), tensor(0.9698, grad_fn=<NllLossBackward>), tensor(1.0419, grad_fn=<NllLossBackward>), tensor(1.0097, grad_fn=<NllLossBackward>), tensor(0.9328, grad_fn=<NllLossBackward>), tensor(1.0015, grad_fn=<NllLossBackward>), tensor(0.9964, grad_fn=<NllLossBackward>), tensor(1.0557, grad_fn=<NllLossBackward>), tensor(0.9537, grad_fn=<NllLossBackward>), tensor(1.0484, grad_fn=<NllLossBackward>), tensor(1.1754, grad_fn=<NllLossBackward>), tensor(1.0096, grad_fn=<NllLossBackward>), tensor(1.0300, grad_fn=<NllLossBackward>), tensor(1.0834, grad_fn=<NllLossBackward>), tensor(1.0880, grad_fn=<NllLossBackward>), tensor(0.8829, grad_fn=<NllLossBackward>), tensor(1.0559, grad_fn=<NllLossBackward>), tensor(0.7914, grad_fn=<NllLossBackward>), tensor(1.0283, grad_fn=<NllLossBackward>), tensor(0.9796, grad_fn=<NllLossBackward>), tensor(0.8480, grad_fn=<NllLossBackward>), tensor(1.0123, grad_fn=<NllLossBackward>), tensor(0.8450, grad_fn=<NllLossBackward>), tensor(0.9867, grad_fn=<NllLossBackward>), tensor(0.8634, grad_fn=<NllLossBackward>), tensor(1.1106, grad_fn=<NllLossBackward>), tensor(1.2414, grad_fn=<NllLossBackward>), tensor(0.7777, grad_fn=<NllLossBackward>), tensor(0.9848, grad_fn=<NllLossBackward>), tensor(1.1371, grad_fn=<NllLossBackward>), tensor(1.1094, grad_fn=<NllLossBackward>), tensor(1.0395, grad_fn=<NllLossBackward>), tensor(1.0670, grad_fn=<NllLossBackward>), tensor(1.0803, grad_fn=<NllLossBackward>), tensor(0.9383, grad_fn=<NllLossBackward>), tensor(1.1071, grad_fn=<NllLossBackward>), tensor(1.1657, grad_fn=<NllLossBackward>), tensor(0.9381, grad_fn=<NllLossBackward>), tensor(1.0235, grad_fn=<NllLossBackward>), tensor(0.9063, grad_fn=<NllLossBackward>), tensor(0.8232, grad_fn=<NllLossBackward>), tensor(0.9781, grad_fn=<NllLossBackward>), tensor(1.0144, grad_fn=<NllLossBackward>), tensor(1.0565, grad_fn=<NllLossBackward>), tensor(0.9267, grad_fn=<NllLossBackward>), tensor(1.0346, grad_fn=<NllLossBackward>), tensor(0.8825, grad_fn=<NllLossBackward>), tensor(0.9867, grad_fn=<NllLossBackward>), tensor(1.0620, grad_fn=<NllLossBackward>), tensor(0.9702, grad_fn=<NllLossBackward>), tensor(0.8162, grad_fn=<NllLossBackward>), tensor(1.0631, grad_fn=<NllLossBackward>), tensor(0.9190, grad_fn=<NllLossBackward>), tensor(1.1010, grad_fn=<NllLossBackward>), tensor(0.9555, grad_fn=<NllLossBackward>), tensor(1.1268, grad_fn=<NllLossBackward>), tensor(1.0516, grad_fn=<NllLossBackward>), tensor(0.8625, grad_fn=<NllLossBackward>), tensor(0.9782, grad_fn=<NllLossBackward>), tensor(0.9043, grad_fn=<NllLossBackward>), tensor(1.0347, grad_fn=<NllLossBackward>), tensor(0.9659, grad_fn=<NllLossBackward>), tensor(0.9072, grad_fn=<NllLossBackward>), tensor(1.0893, grad_fn=<NllLossBackward>), tensor(1.0119, grad_fn=<NllLossBackward>), tensor(1.0918, grad_fn=<NllLossBackward>), tensor(0.8355, grad_fn=<NllLossBackward>), tensor(1.0950, grad_fn=<NllLossBackward>), tensor(1.2014, grad_fn=<NllLossBackward>), tensor(0.9863, grad_fn=<NllLossBackward>), tensor(1.0404, grad_fn=<NllLossBackward>), tensor(1.0904, grad_fn=<NllLossBackward>), tensor(1.0795, grad_fn=<NllLossBackward>), tensor(1.0150, grad_fn=<NllLossBackward>), tensor(1.1148, grad_fn=<NllLossBackward>), tensor(1.0796, grad_fn=<NllLossBackward>), tensor(0.8062, grad_fn=<NllLossBackward>), tensor(0.9036, grad_fn=<NllLossBackward>), tensor(1.0031, grad_fn=<NllLossBackward>), tensor(1.1056, grad_fn=<NllLossBackward>), tensor(0.9270, grad_fn=<NllLossBackward>), tensor(1.0219, grad_fn=<NllLossBackward>), tensor(0.9413, grad_fn=<NllLossBackward>), tensor(1.0546, grad_fn=<NllLossBackward>), tensor(0.8778, grad_fn=<NllLossBackward>), tensor(1.0487, grad_fn=<NllLossBackward>), tensor(0.9783, grad_fn=<NllLossBackward>), tensor(0.8493, grad_fn=<NllLossBackward>), tensor(0.9618, grad_fn=<NllLossBackward>), tensor(0.9611, grad_fn=<NllLossBackward>), tensor(0.9874, grad_fn=<NllLossBackward>), tensor(1.2967, grad_fn=<NllLossBackward>), tensor(1.1285, grad_fn=<NllLossBackward>), tensor(1.0645, grad_fn=<NllLossBackward>), tensor(1.1212, grad_fn=<NllLossBackward>), tensor(1.0968, grad_fn=<NllLossBackward>), tensor(0.8620, grad_fn=<NllLossBackward>), tensor(0.8720, grad_fn=<NllLossBackward>), tensor(0.9876, grad_fn=<NllLossBackward>), tensor(1.0436, grad_fn=<NllLossBackward>), tensor(0.9999, grad_fn=<NllLossBackward>), tensor(0.9779, grad_fn=<NllLossBackward>), tensor(1.1418, grad_fn=<NllLossBackward>), tensor(1.0155, grad_fn=<NllLossBackward>), tensor(0.9725, grad_fn=<NllLossBackward>), tensor(1.0989, grad_fn=<NllLossBackward>), tensor(1.1454, grad_fn=<NllLossBackward>), tensor(1.0805, grad_fn=<NllLossBackward>), tensor(0.9044, grad_fn=<NllLossBackward>), tensor(0.8294, grad_fn=<NllLossBackward>), tensor(0.8677, grad_fn=<NllLossBackward>), tensor(1.1445, grad_fn=<NllLossBackward>), tensor(0.9335, grad_fn=<NllLossBackward>), tensor(0.8645, grad_fn=<NllLossBackward>), tensor(0.9620, grad_fn=<NllLossBackward>), tensor(0.9464, grad_fn=<NllLossBackward>), tensor(1.1347, grad_fn=<NllLossBackward>), tensor(0.9303, grad_fn=<NllLossBackward>), tensor(1.1673, grad_fn=<NllLossBackward>), tensor(0.9093, grad_fn=<NllLossBackward>), tensor(0.9790, grad_fn=<NllLossBackward>), tensor(0.9664, grad_fn=<NllLossBackward>), tensor(1.0239, grad_fn=<NllLossBackward>), tensor(0.9317, grad_fn=<NllLossBackward>), tensor(0.9886, grad_fn=<NllLossBackward>), tensor(0.9518, grad_fn=<NllLossBackward>), tensor(1.0653, grad_fn=<NllLossBackward>), tensor(0.9167, grad_fn=<NllLossBackward>), tensor(1.0092, grad_fn=<NllLossBackward>), tensor(0.9709, grad_fn=<NllLossBackward>), tensor(0.8430, grad_fn=<NllLossBackward>), tensor(0.9372, grad_fn=<NllLossBackward>), tensor(0.9333, grad_fn=<NllLossBackward>), tensor(0.9024, grad_fn=<NllLossBackward>), tensor(0.9355, grad_fn=<NllLossBackward>), tensor(1.1396, grad_fn=<NllLossBackward>), tensor(0.9727, grad_fn=<NllLossBackward>), tensor(0.8369, grad_fn=<NllLossBackward>), tensor(0.8244, grad_fn=<NllLossBackward>), tensor(1.1314, grad_fn=<NllLossBackward>), tensor(1.0128, grad_fn=<NllLossBackward>), tensor(1.0563, grad_fn=<NllLossBackward>), tensor(0.9053, grad_fn=<NllLossBackward>), tensor(0.8613, grad_fn=<NllLossBackward>), tensor(0.9504, grad_fn=<NllLossBackward>), tensor(1.0023, grad_fn=<NllLossBackward>), tensor(1.0510, grad_fn=<NllLossBackward>), tensor(0.8288, grad_fn=<NllLossBackward>), tensor(0.9527, grad_fn=<NllLossBackward>), tensor(1.0446, grad_fn=<NllLossBackward>), tensor(1.0336, grad_fn=<NllLossBackward>), tensor(0.9539, grad_fn=<NllLossBackward>), tensor(0.9983, grad_fn=<NllLossBackward>), tensor(1.0303, grad_fn=<NllLossBackward>), tensor(1.1221, grad_fn=<NllLossBackward>), tensor(0.8469, grad_fn=<NllLossBackward>), tensor(0.9574, grad_fn=<NllLossBackward>), tensor(0.9556, grad_fn=<NllLossBackward>), tensor(0.9127, grad_fn=<NllLossBackward>), tensor(0.9683, grad_fn=<NllLossBackward>), tensor(1.0341, grad_fn=<NllLossBackward>), tensor(1.1484, grad_fn=<NllLossBackward>), tensor(0.8123, grad_fn=<NllLossBackward>), tensor(1.0845, grad_fn=<NllLossBackward>), tensor(0.9598, grad_fn=<NllLossBackward>), tensor(1.1317, grad_fn=<NllLossBackward>), tensor(0.9224, grad_fn=<NllLossBackward>), tensor(0.9414, grad_fn=<NllLossBackward>), tensor(0.9756, grad_fn=<NllLossBackward>), tensor(1.1145, grad_fn=<NllLossBackward>), tensor(0.9776, grad_fn=<NllLossBackward>), tensor(1.0556, grad_fn=<NllLossBackward>), tensor(0.8431, grad_fn=<NllLossBackward>), tensor(1.0002, grad_fn=<NllLossBackward>), tensor(1.0102, grad_fn=<NllLossBackward>), tensor(1.1039, grad_fn=<NllLossBackward>), tensor(1.0839, grad_fn=<NllLossBackward>), tensor(0.9401, grad_fn=<NllLossBackward>), tensor(1.0136, grad_fn=<NllLossBackward>), tensor(0.8378, grad_fn=<NllLossBackward>), tensor(0.9726, grad_fn=<NllLossBackward>), tensor(1.1254, grad_fn=<NllLossBackward>), tensor(0.9523, grad_fn=<NllLossBackward>), tensor(1.0572, grad_fn=<NllLossBackward>), tensor(1.1573, grad_fn=<NllLossBackward>), tensor(0.9128, grad_fn=<NllLossBackward>), tensor(0.9261, grad_fn=<NllLossBackward>), tensor(1.0496, grad_fn=<NllLossBackward>), tensor(1.0483, grad_fn=<NllLossBackward>), tensor(1.0177, grad_fn=<NllLossBackward>), tensor(0.9764, grad_fn=<NllLossBackward>), tensor(1.0146, grad_fn=<NllLossBackward>), tensor(1.0195, grad_fn=<NllLossBackward>), tensor(0.9382, grad_fn=<NllLossBackward>), tensor(0.9396, grad_fn=<NllLossBackward>), tensor(0.8112, grad_fn=<NllLossBackward>), tensor(1.0184, grad_fn=<NllLossBackward>), tensor(0.9853, grad_fn=<NllLossBackward>), tensor(1.2196, grad_fn=<NllLossBackward>), tensor(1.2641, grad_fn=<NllLossBackward>), tensor(0.8680, grad_fn=<NllLossBackward>), tensor(1.0297, grad_fn=<NllLossBackward>), tensor(1.2617, grad_fn=<NllLossBackward>), tensor(0.9084, grad_fn=<NllLossBackward>), tensor(1.0569, grad_fn=<NllLossBackward>), tensor(1.0218, grad_fn=<NllLossBackward>), tensor(0.9649, grad_fn=<NllLossBackward>), tensor(1.1255, grad_fn=<NllLossBackward>), tensor(0.9262, grad_fn=<NllLossBackward>), tensor(0.9736, grad_fn=<NllLossBackward>), tensor(1.1310, grad_fn=<NllLossBackward>), tensor(0.9772, grad_fn=<NllLossBackward>), tensor(1.0551, grad_fn=<NllLossBackward>), tensor(0.8772, grad_fn=<NllLossBackward>), tensor(0.9400, grad_fn=<NllLossBackward>), tensor(1.0397, grad_fn=<NllLossBackward>), tensor(0.8843, grad_fn=<NllLossBackward>), tensor(0.9981, grad_fn=<NllLossBackward>), tensor(0.9360, grad_fn=<NllLossBackward>), tensor(0.9091, grad_fn=<NllLossBackward>), tensor(0.9083, grad_fn=<NllLossBackward>), tensor(0.9652, grad_fn=<NllLossBackward>), tensor(1.0905, grad_fn=<NllLossBackward>), tensor(1.1844, grad_fn=<NllLossBackward>), tensor(0.9923, grad_fn=<NllLossBackward>), tensor(1.0691, grad_fn=<NllLossBackward>), tensor(1.1344, grad_fn=<NllLossBackward>), tensor(1.0970, grad_fn=<NllLossBackward>), tensor(0.9192, grad_fn=<NllLossBackward>), tensor(1.1658, grad_fn=<NllLossBackward>), tensor(0.9885, grad_fn=<NllLossBackward>), tensor(1.0280, grad_fn=<NllLossBackward>), tensor(1.0849, grad_fn=<NllLossBackward>), tensor(1.0810, grad_fn=<NllLossBackward>), tensor(0.9686, grad_fn=<NllLossBackward>), tensor(1.1329, grad_fn=<NllLossBackward>), tensor(1.0125, grad_fn=<NllLossBackward>), tensor(1.0887, grad_fn=<NllLossBackward>), tensor(0.8988, grad_fn=<NllLossBackward>), tensor(1.1350, grad_fn=<NllLossBackward>), tensor(1.1499, grad_fn=<NllLossBackward>), tensor(0.9318, grad_fn=<NllLossBackward>), tensor(0.9932, grad_fn=<NllLossBackward>), tensor(1.1118, grad_fn=<NllLossBackward>), tensor(0.9183, grad_fn=<NllLossBackward>), tensor(1.0724, grad_fn=<NllLossBackward>), tensor(0.9602, grad_fn=<NllLossBackward>), tensor(0.7740, grad_fn=<NllLossBackward>), tensor(1.1178, grad_fn=<NllLossBackward>), tensor(0.9087, grad_fn=<NllLossBackward>), tensor(1.1399, grad_fn=<NllLossBackward>), tensor(0.9461, grad_fn=<NllLossBackward>), tensor(0.8173, grad_fn=<NllLossBackward>), tensor(0.9937, grad_fn=<NllLossBackward>), tensor(0.9689, grad_fn=<NllLossBackward>), tensor(0.9129, grad_fn=<NllLossBackward>), tensor(0.8837, grad_fn=<NllLossBackward>), tensor(0.9744, grad_fn=<NllLossBackward>), tensor(0.8860, grad_fn=<NllLossBackward>), tensor(0.8859, grad_fn=<NllLossBackward>), tensor(0.7171, grad_fn=<NllLossBackward>), tensor(1.1026, grad_fn=<NllLossBackward>), tensor(0.9750, grad_fn=<NllLossBackward>), tensor(0.9502, grad_fn=<NllLossBackward>), tensor(1.0038, grad_fn=<NllLossBackward>), tensor(0.8515, grad_fn=<NllLossBackward>), tensor(1.0009, grad_fn=<NllLossBackward>), tensor(1.1234, grad_fn=<NllLossBackward>), tensor(0.9618, grad_fn=<NllLossBackward>), tensor(0.9131, grad_fn=<NllLossBackward>), tensor(0.9599, grad_fn=<NllLossBackward>), tensor(0.9902, grad_fn=<NllLossBackward>), tensor(0.9726, grad_fn=<NllLossBackward>), tensor(0.8202, grad_fn=<NllLossBackward>), tensor(0.9288, grad_fn=<NllLossBackward>), tensor(0.8593, grad_fn=<NllLossBackward>), tensor(0.9825, grad_fn=<NllLossBackward>), tensor(0.8474, grad_fn=<NllLossBackward>), tensor(1.0799, grad_fn=<NllLossBackward>), tensor(1.0278, grad_fn=<NllLossBackward>), tensor(0.8561, grad_fn=<NllLossBackward>), tensor(1.0646, grad_fn=<NllLossBackward>), tensor(0.9745, grad_fn=<NllLossBackward>), tensor(1.0379, grad_fn=<NllLossBackward>), tensor(1.1403, grad_fn=<NllLossBackward>), tensor(1.0550, grad_fn=<NllLossBackward>), tensor(0.8068, grad_fn=<NllLossBackward>), tensor(0.8027, grad_fn=<NllLossBackward>), tensor(0.8636, grad_fn=<NllLossBackward>), tensor(1.0031, grad_fn=<NllLossBackward>), tensor(1.0080, grad_fn=<NllLossBackward>), tensor(1.0491, grad_fn=<NllLossBackward>), tensor(0.9295, grad_fn=<NllLossBackward>), tensor(1.0615, grad_fn=<NllLossBackward>), tensor(0.8339, grad_fn=<NllLossBackward>), tensor(0.8558, grad_fn=<NllLossBackward>), tensor(1.1018, grad_fn=<NllLossBackward>), tensor(1.0379, grad_fn=<NllLossBackward>), tensor(1.0185, grad_fn=<NllLossBackward>), tensor(1.0571, grad_fn=<NllLossBackward>), tensor(1.1808, grad_fn=<NllLossBackward>), tensor(1.0652, grad_fn=<NllLossBackward>), tensor(1.0078, grad_fn=<NllLossBackward>), tensor(1.0184, grad_fn=<NllLossBackward>), tensor(1.0932, grad_fn=<NllLossBackward>), tensor(0.9338, grad_fn=<NllLossBackward>), tensor(0.9078, grad_fn=<NllLossBackward>), tensor(1.0281, grad_fn=<NllLossBackward>), tensor(0.8899, grad_fn=<NllLossBackward>), tensor(1.0959, grad_fn=<NllLossBackward>), tensor(1.0447, grad_fn=<NllLossBackward>), tensor(1.0848, grad_fn=<NllLossBackward>), tensor(0.8366, grad_fn=<NllLossBackward>), tensor(1.0392, grad_fn=<NllLossBackward>), tensor(1.1941, grad_fn=<NllLossBackward>), tensor(0.9919, grad_fn=<NllLossBackward>), tensor(1.0100, grad_fn=<NllLossBackward>), tensor(0.9406, grad_fn=<NllLossBackward>), tensor(1.1043, grad_fn=<NllLossBackward>), tensor(1.0805, grad_fn=<NllLossBackward>), tensor(0.9875, grad_fn=<NllLossBackward>), tensor(0.9838, grad_fn=<NllLossBackward>), tensor(0.9951, grad_fn=<NllLossBackward>), tensor(1.1924, grad_fn=<NllLossBackward>), tensor(1.0005, grad_fn=<NllLossBackward>), tensor(0.9727, grad_fn=<NllLossBackward>), tensor(0.9398, grad_fn=<NllLossBackward>), tensor(0.9697, grad_fn=<NllLossBackward>), tensor(0.8326, grad_fn=<NllLossBackward>), tensor(0.9272, grad_fn=<NllLossBackward>), tensor(1.0004, grad_fn=<NllLossBackward>), tensor(0.9786, grad_fn=<NllLossBackward>), tensor(0.9818, grad_fn=<NllLossBackward>), tensor(1.0020, grad_fn=<NllLossBackward>), tensor(0.9474, grad_fn=<NllLossBackward>), tensor(0.9212, grad_fn=<NllLossBackward>), tensor(0.9086, grad_fn=<NllLossBackward>), tensor(1.0442, grad_fn=<NllLossBackward>), tensor(0.8849, grad_fn=<NllLossBackward>), tensor(0.9999, grad_fn=<NllLossBackward>), tensor(0.9633, grad_fn=<NllLossBackward>), tensor(0.9069, grad_fn=<NllLossBackward>), tensor(1.0514, grad_fn=<NllLossBackward>), tensor(0.9164, grad_fn=<NllLossBackward>), tensor(0.9758, grad_fn=<NllLossBackward>), tensor(0.8333, grad_fn=<NllLossBackward>), tensor(0.8907, grad_fn=<NllLossBackward>), tensor(0.9321, grad_fn=<NllLossBackward>), tensor(0.9100, grad_fn=<NllLossBackward>), tensor(1.0405, grad_fn=<NllLossBackward>), tensor(0.8602, grad_fn=<NllLossBackward>), tensor(0.9931, grad_fn=<NllLossBackward>), tensor(1.0811, grad_fn=<NllLossBackward>), tensor(1.0259, grad_fn=<NllLossBackward>), tensor(1.0172, grad_fn=<NllLossBackward>), tensor(0.9304, grad_fn=<NllLossBackward>), tensor(1.0263, grad_fn=<NllLossBackward>), tensor(1.1454, grad_fn=<NllLossBackward>), tensor(1.1482, grad_fn=<NllLossBackward>), tensor(0.9455, grad_fn=<NllLossBackward>), tensor(0.9677, grad_fn=<NllLossBackward>), tensor(1.0395, grad_fn=<NllLossBackward>), tensor(0.8217, grad_fn=<NllLossBackward>), tensor(0.9580, grad_fn=<NllLossBackward>), tensor(1.1448, grad_fn=<NllLossBackward>), tensor(0.9484, grad_fn=<NllLossBackward>), tensor(0.9243, grad_fn=<NllLossBackward>), tensor(0.8823, grad_fn=<NllLossBackward>), tensor(1.1119, grad_fn=<NllLossBackward>), tensor(1.1351, grad_fn=<NllLossBackward>), tensor(1.0283, grad_fn=<NllLossBackward>), tensor(1.1104, grad_fn=<NllLossBackward>), tensor(0.9387, grad_fn=<NllLossBackward>), tensor(0.9463, grad_fn=<NllLossBackward>), tensor(1.0142, grad_fn=<NllLossBackward>), tensor(0.7465, grad_fn=<NllLossBackward>), tensor(0.9289, grad_fn=<NllLossBackward>), tensor(1.1732, grad_fn=<NllLossBackward>), tensor(1.2719, grad_fn=<NllLossBackward>), tensor(0.9395, grad_fn=<NllLossBackward>), tensor(1.1760, grad_fn=<NllLossBackward>), tensor(1.2266, grad_fn=<NllLossBackward>), tensor(0.9230, grad_fn=<NllLossBackward>), tensor(0.8991, grad_fn=<NllLossBackward>), tensor(1.0110, grad_fn=<NllLossBackward>), tensor(1.1355, grad_fn=<NllLossBackward>), tensor(1.0639, grad_fn=<NllLossBackward>), tensor(1.0280, grad_fn=<NllLossBackward>), tensor(1.0662, grad_fn=<NllLossBackward>), tensor(0.9755, grad_fn=<NllLossBackward>), tensor(0.9100, grad_fn=<NllLossBackward>), tensor(0.7057, grad_fn=<NllLossBackward>), tensor(0.9464, grad_fn=<NllLossBackward>), tensor(1.0588, grad_fn=<NllLossBackward>), tensor(0.9220, grad_fn=<NllLossBackward>), tensor(0.8198, grad_fn=<NllLossBackward>), tensor(1.1044, grad_fn=<NllLossBackward>), tensor(1.0288, grad_fn=<NllLossBackward>), tensor(0.9938, grad_fn=<NllLossBackward>), tensor(0.9553, grad_fn=<NllLossBackward>), tensor(0.9309, grad_fn=<NllLossBackward>), tensor(0.9034, grad_fn=<NllLossBackward>), tensor(0.9950, grad_fn=<NllLossBackward>), tensor(0.9699, grad_fn=<NllLossBackward>), tensor(1.0269, grad_fn=<NllLossBackward>), tensor(0.9500, grad_fn=<NllLossBackward>), tensor(1.0226, grad_fn=<NllLossBackward>), tensor(0.8469, grad_fn=<NllLossBackward>), tensor(0.9664, grad_fn=<NllLossBackward>), tensor(0.8396, grad_fn=<NllLossBackward>), tensor(1.0273, grad_fn=<NllLossBackward>), tensor(0.9130, grad_fn=<NllLossBackward>), tensor(0.9746, grad_fn=<NllLossBackward>), tensor(0.9675, grad_fn=<NllLossBackward>), tensor(0.9505, grad_fn=<NllLossBackward>), tensor(0.7947, grad_fn=<NllLossBackward>), tensor(0.9358, grad_fn=<NllLossBackward>), tensor(1.1714, grad_fn=<NllLossBackward>), tensor(1.0265, grad_fn=<NllLossBackward>), tensor(1.1189, grad_fn=<NllLossBackward>), tensor(1.0369, grad_fn=<NllLossBackward>), tensor(0.7549, grad_fn=<NllLossBackward>), tensor(0.9106, grad_fn=<NllLossBackward>), tensor(0.8692, grad_fn=<NllLossBackward>), tensor(0.9181, grad_fn=<NllLossBackward>), tensor(0.9215, grad_fn=<NllLossBackward>), tensor(0.7783, grad_fn=<NllLossBackward>), tensor(0.9815, grad_fn=<NllLossBackward>), tensor(1.1833, grad_fn=<NllLossBackward>), tensor(0.7992, grad_fn=<NllLossBackward>), tensor(1.0957, grad_fn=<NllLossBackward>), tensor(0.9765, grad_fn=<NllLossBackward>), tensor(1.0531, grad_fn=<NllLossBackward>), tensor(0.8708, grad_fn=<NllLossBackward>), tensor(1.0326, grad_fn=<NllLossBackward>), tensor(1.0542, grad_fn=<NllLossBackward>), tensor(1.0292, grad_fn=<NllLossBackward>), tensor(0.9703, grad_fn=<NllLossBackward>), tensor(0.8454, grad_fn=<NllLossBackward>), tensor(0.8356, grad_fn=<NllLossBackward>), tensor(1.1093, grad_fn=<NllLossBackward>), tensor(0.9990, grad_fn=<NllLossBackward>), tensor(0.9284, grad_fn=<NllLossBackward>), tensor(1.0865, grad_fn=<NllLossBackward>), tensor(0.8824, grad_fn=<NllLossBackward>), tensor(1.0874, grad_fn=<NllLossBackward>), tensor(1.2420, grad_fn=<NllLossBackward>), tensor(0.9793, grad_fn=<NllLossBackward>), tensor(1.0035, grad_fn=<NllLossBackward>), tensor(0.9891, grad_fn=<NllLossBackward>), tensor(1.0674, grad_fn=<NllLossBackward>), tensor(0.9361, grad_fn=<NllLossBackward>), tensor(1.1841, grad_fn=<NllLossBackward>), tensor(0.9607, grad_fn=<NllLossBackward>), tensor(0.9699, grad_fn=<NllLossBackward>), tensor(0.9064, grad_fn=<NllLossBackward>), tensor(1.0422, grad_fn=<NllLossBackward>), tensor(0.9726, grad_fn=<NllLossBackward>), tensor(0.9180, grad_fn=<NllLossBackward>), tensor(0.9065, grad_fn=<NllLossBackward>), tensor(0.8531, grad_fn=<NllLossBackward>), tensor(0.9143, grad_fn=<NllLossBackward>), tensor(0.9582, grad_fn=<NllLossBackward>), tensor(0.9375, grad_fn=<NllLossBackward>), tensor(0.9016, grad_fn=<NllLossBackward>), tensor(0.9940, grad_fn=<NllLossBackward>), tensor(0.9474, grad_fn=<NllLossBackward>), tensor(0.8988, grad_fn=<NllLossBackward>), tensor(0.8731, grad_fn=<NllLossBackward>), tensor(0.9785, grad_fn=<NllLossBackward>), tensor(0.7383, grad_fn=<NllLossBackward>), tensor(1.0245, grad_fn=<NllLossBackward>), tensor(0.9052, grad_fn=<NllLossBackward>), tensor(1.1434, grad_fn=<NllLossBackward>), tensor(1.0254, grad_fn=<NllLossBackward>), tensor(1.0968, grad_fn=<NllLossBackward>), tensor(0.9534, grad_fn=<NllLossBackward>), tensor(1.0960, grad_fn=<NllLossBackward>), tensor(1.0305, grad_fn=<NllLossBackward>), tensor(0.9182, grad_fn=<NllLossBackward>), tensor(0.9314, grad_fn=<NllLossBackward>), tensor(0.8854, grad_fn=<NllLossBackward>), tensor(1.0514, grad_fn=<NllLossBackward>), tensor(0.8083, grad_fn=<NllLossBackward>), tensor(0.9871, grad_fn=<NllLossBackward>), tensor(0.9961, grad_fn=<NllLossBackward>), tensor(1.1287, grad_fn=<NllLossBackward>), tensor(1.0369, grad_fn=<NllLossBackward>), tensor(0.8531, grad_fn=<NllLossBackward>), tensor(0.9287, grad_fn=<NllLossBackward>), tensor(1.0342, grad_fn=<NllLossBackward>), tensor(1.0617, grad_fn=<NllLossBackward>), tensor(1.0479, grad_fn=<NllLossBackward>), tensor(1.0108, grad_fn=<NllLossBackward>), tensor(0.9238, grad_fn=<NllLossBackward>), tensor(1.0120, grad_fn=<NllLossBackward>), tensor(0.8762, grad_fn=<NllLossBackward>), tensor(1.0154, grad_fn=<NllLossBackward>), tensor(1.0565, grad_fn=<NllLossBackward>), tensor(0.9840, grad_fn=<NllLossBackward>), tensor(0.9011, grad_fn=<NllLossBackward>), tensor(0.8686, grad_fn=<NllLossBackward>), tensor(0.9176, grad_fn=<NllLossBackward>), tensor(1.0650, grad_fn=<NllLossBackward>), tensor(0.8628, grad_fn=<NllLossBackward>), tensor(1.1844, grad_fn=<NllLossBackward>), tensor(0.9803, grad_fn=<NllLossBackward>), tensor(0.9434, grad_fn=<NllLossBackward>), tensor(0.8126, grad_fn=<NllLossBackward>), tensor(0.8702, grad_fn=<NllLossBackward>), tensor(1.0458, grad_fn=<NllLossBackward>), tensor(1.0430, grad_fn=<NllLossBackward>), tensor(0.7965, grad_fn=<NllLossBackward>), tensor(0.8398, grad_fn=<NllLossBackward>), tensor(0.8856, grad_fn=<NllLossBackward>), tensor(1.2201, grad_fn=<NllLossBackward>), tensor(1.0067, grad_fn=<NllLossBackward>), tensor(1.0507, grad_fn=<NllLossBackward>), tensor(1.1885, grad_fn=<NllLossBackward>), tensor(0.9735, grad_fn=<NllLossBackward>), tensor(1.0507, grad_fn=<NllLossBackward>), tensor(1.1678, grad_fn=<NllLossBackward>), tensor(0.9863, grad_fn=<NllLossBackward>), tensor(0.9857, grad_fn=<NllLossBackward>), tensor(1.0750, grad_fn=<NllLossBackward>), tensor(1.0354, grad_fn=<NllLossBackward>), tensor(0.9770, grad_fn=<NllLossBackward>), tensor(0.8185, grad_fn=<NllLossBackward>), tensor(0.8566, grad_fn=<NllLossBackward>), tensor(0.9068, grad_fn=<NllLossBackward>), tensor(1.0050, grad_fn=<NllLossBackward>), tensor(1.0114, grad_fn=<NllLossBackward>), tensor(1.0433, grad_fn=<NllLossBackward>), tensor(0.9389, grad_fn=<NllLossBackward>), tensor(0.8778, grad_fn=<NllLossBackward>), tensor(0.8709, grad_fn=<NllLossBackward>), tensor(1.0036, grad_fn=<NllLossBackward>), tensor(0.9840, grad_fn=<NllLossBackward>), tensor(0.9339, grad_fn=<NllLossBackward>), tensor(0.8672, grad_fn=<NllLossBackward>), tensor(0.9275, grad_fn=<NllLossBackward>), tensor(0.9617, grad_fn=<NllLossBackward>), tensor(0.8739, grad_fn=<NllLossBackward>), tensor(0.9512, grad_fn=<NllLossBackward>), tensor(0.9738, grad_fn=<NllLossBackward>), tensor(1.0540, grad_fn=<NllLossBackward>), tensor(1.0457, grad_fn=<NllLossBackward>), tensor(0.9470, grad_fn=<NllLossBackward>), tensor(0.9718, grad_fn=<NllLossBackward>), tensor(0.8566, grad_fn=<NllLossBackward>), tensor(0.8682, grad_fn=<NllLossBackward>), tensor(0.9636, grad_fn=<NllLossBackward>), tensor(0.8718, grad_fn=<NllLossBackward>), tensor(0.9320, grad_fn=<NllLossBackward>), tensor(0.8463, grad_fn=<NllLossBackward>), tensor(0.8431, grad_fn=<NllLossBackward>), tensor(0.8374, grad_fn=<NllLossBackward>), tensor(1.0288, grad_fn=<NllLossBackward>), tensor(1.0489, grad_fn=<NllLossBackward>), tensor(1.0448, grad_fn=<NllLossBackward>), tensor(0.9287, grad_fn=<NllLossBackward>), tensor(1.0801, grad_fn=<NllLossBackward>), tensor(1.0298, grad_fn=<NllLossBackward>), tensor(1.2012, grad_fn=<NllLossBackward>), tensor(1.0817, grad_fn=<NllLossBackward>), tensor(0.8567, grad_fn=<NllLossBackward>), tensor(1.1027, grad_fn=<NllLossBackward>), tensor(1.0513, grad_fn=<NllLossBackward>), tensor(0.8520, grad_fn=<NllLossBackward>), tensor(0.9935, grad_fn=<NllLossBackward>), tensor(0.8044, grad_fn=<NllLossBackward>), tensor(1.0345, grad_fn=<NllLossBackward>), tensor(0.9964, grad_fn=<NllLossBackward>), tensor(1.2026, grad_fn=<NllLossBackward>), tensor(1.1263, grad_fn=<NllLossBackward>), tensor(1.0894, grad_fn=<NllLossBackward>), tensor(0.9624, grad_fn=<NllLossBackward>), tensor(1.0386, grad_fn=<NllLossBackward>), tensor(0.9154, grad_fn=<NllLossBackward>), tensor(1.0235, grad_fn=<NllLossBackward>), tensor(0.8270, grad_fn=<NllLossBackward>), tensor(0.9051, grad_fn=<NllLossBackward>), tensor(1.0302, grad_fn=<NllLossBackward>), tensor(0.8590, grad_fn=<NllLossBackward>), tensor(0.9487, grad_fn=<NllLossBackward>), tensor(1.1077, grad_fn=<NllLossBackward>), tensor(1.0584, grad_fn=<NllLossBackward>), tensor(1.0267, grad_fn=<NllLossBackward>), tensor(1.0098, grad_fn=<NllLossBackward>), tensor(0.9588, grad_fn=<NllLossBackward>), tensor(0.9336, grad_fn=<NllLossBackward>), tensor(0.9864, grad_fn=<NllLossBackward>), tensor(1.1149, grad_fn=<NllLossBackward>), tensor(1.0165, grad_fn=<NllLossBackward>), tensor(1.0036, grad_fn=<NllLossBackward>), tensor(1.0321, grad_fn=<NllLossBackward>), tensor(0.9567, grad_fn=<NllLossBackward>), tensor(0.9626, grad_fn=<NllLossBackward>), tensor(1.0040, grad_fn=<NllLossBackward>), tensor(0.9532, grad_fn=<NllLossBackward>), tensor(0.9964, grad_fn=<NllLossBackward>), tensor(1.1741, grad_fn=<NllLossBackward>), tensor(1.0072, grad_fn=<NllLossBackward>), tensor(1.1509, grad_fn=<NllLossBackward>), tensor(0.8268, grad_fn=<NllLossBackward>), tensor(1.0075, grad_fn=<NllLossBackward>), tensor(1.0405, grad_fn=<NllLossBackward>), tensor(0.9593, grad_fn=<NllLossBackward>), tensor(0.8771, grad_fn=<NllLossBackward>), tensor(0.9539, grad_fn=<NllLossBackward>), tensor(0.8779, grad_fn=<NllLossBackward>), tensor(1.0352, grad_fn=<NllLossBackward>), tensor(0.8925, grad_fn=<NllLossBackward>), tensor(0.8249, grad_fn=<NllLossBackward>), tensor(1.2379, grad_fn=<NllLossBackward>), tensor(0.8511, grad_fn=<NllLossBackward>), tensor(0.8925, grad_fn=<NllLossBackward>), tensor(1.1151, grad_fn=<NllLossBackward>), tensor(1.0597, grad_fn=<NllLossBackward>), tensor(0.9160, grad_fn=<NllLossBackward>), tensor(0.8601, grad_fn=<NllLossBackward>), tensor(1.0647, grad_fn=<NllLossBackward>), tensor(1.0157, grad_fn=<NllLossBackward>), tensor(1.0755, grad_fn=<NllLossBackward>), tensor(0.9430, grad_fn=<NllLossBackward>), tensor(0.8773, grad_fn=<NllLossBackward>), tensor(0.9022, grad_fn=<NllLossBackward>), tensor(1.0374, grad_fn=<NllLossBackward>), tensor(1.0291, grad_fn=<NllLossBackward>), tensor(0.9979, grad_fn=<NllLossBackward>), tensor(0.8481, grad_fn=<NllLossBackward>), tensor(0.8997, grad_fn=<NllLossBackward>), tensor(1.0945, grad_fn=<NllLossBackward>), tensor(1.0660, grad_fn=<NllLossBackward>), tensor(0.9859, grad_fn=<NllLossBackward>), tensor(0.8956, grad_fn=<NllLossBackward>), tensor(0.9374, grad_fn=<NllLossBackward>), tensor(0.9775, grad_fn=<NllLossBackward>), tensor(0.9223, grad_fn=<NllLossBackward>), tensor(1.0192, grad_fn=<NllLossBackward>), tensor(0.9118, grad_fn=<NllLossBackward>), tensor(0.8589, grad_fn=<NllLossBackward>), tensor(1.0166, grad_fn=<NllLossBackward>), tensor(0.8895, grad_fn=<NllLossBackward>), tensor(1.1574, grad_fn=<NllLossBackward>), tensor(0.9093, grad_fn=<NllLossBackward>), tensor(0.9074, grad_fn=<NllLossBackward>), tensor(0.9668, grad_fn=<NllLossBackward>), tensor(1.0978, grad_fn=<NllLossBackward>), tensor(0.7436, grad_fn=<NllLossBackward>), tensor(1.0068, grad_fn=<NllLossBackward>), tensor(0.8955, grad_fn=<NllLossBackward>), tensor(0.9534, grad_fn=<NllLossBackward>), tensor(0.9267, grad_fn=<NllLossBackward>), tensor(1.0190, grad_fn=<NllLossBackward>), tensor(1.0218, grad_fn=<NllLossBackward>), tensor(1.0084, grad_fn=<NllLossBackward>), tensor(0.9969, grad_fn=<NllLossBackward>), tensor(0.9334, grad_fn=<NllLossBackward>), tensor(0.8072, grad_fn=<NllLossBackward>), tensor(0.9708, grad_fn=<NllLossBackward>), tensor(1.0830, grad_fn=<NllLossBackward>), tensor(0.9480, grad_fn=<NllLossBackward>), tensor(0.7306, grad_fn=<NllLossBackward>), tensor(0.8126, grad_fn=<NllLossBackward>), tensor(1.1311, grad_fn=<NllLossBackward>), tensor(0.9180, grad_fn=<NllLossBackward>), tensor(1.1612, grad_fn=<NllLossBackward>), tensor(0.9146, grad_fn=<NllLossBackward>), tensor(1.3403, grad_fn=<NllLossBackward>), tensor(0.9748, grad_fn=<NllLossBackward>), tensor(0.8897, grad_fn=<NllLossBackward>), tensor(1.1194, grad_fn=<NllLossBackward>), tensor(0.7999, grad_fn=<NllLossBackward>), tensor(1.0368, grad_fn=<NllLossBackward>), tensor(0.9920, grad_fn=<NllLossBackward>), tensor(1.0209, grad_fn=<NllLossBackward>), tensor(0.8361, grad_fn=<NllLossBackward>), tensor(1.0605, grad_fn=<NllLossBackward>), tensor(1.1239, grad_fn=<NllLossBackward>), tensor(0.8728, grad_fn=<NllLossBackward>), tensor(1.0206, grad_fn=<NllLossBackward>), tensor(0.9494, grad_fn=<NllLossBackward>), tensor(1.0400, grad_fn=<NllLossBackward>), tensor(0.9941, grad_fn=<NllLossBackward>), tensor(0.9543, grad_fn=<NllLossBackward>), tensor(0.8765, grad_fn=<NllLossBackward>), tensor(1.0186, grad_fn=<NllLossBackward>), tensor(1.0467, grad_fn=<NllLossBackward>), tensor(1.0225, grad_fn=<NllLossBackward>), tensor(0.8126, grad_fn=<NllLossBackward>), tensor(1.1043, grad_fn=<NllLossBackward>), tensor(1.0343, grad_fn=<NllLossBackward>), tensor(0.9757, grad_fn=<NllLossBackward>), tensor(0.9029, grad_fn=<NllLossBackward>), tensor(0.8757, grad_fn=<NllLossBackward>), tensor(1.0540, grad_fn=<NllLossBackward>), tensor(1.0513, grad_fn=<NllLossBackward>), tensor(0.8974, grad_fn=<NllLossBackward>), tensor(0.9800, grad_fn=<NllLossBackward>), tensor(1.0728, grad_fn=<NllLossBackward>), tensor(0.8828, grad_fn=<NllLossBackward>), tensor(1.0775, grad_fn=<NllLossBackward>), tensor(1.0280, grad_fn=<NllLossBackward>), tensor(0.8351, grad_fn=<NllLossBackward>), tensor(0.9231, grad_fn=<NllLossBackward>), tensor(0.9334, grad_fn=<NllLossBackward>), tensor(1.0372, grad_fn=<NllLossBackward>), tensor(0.9044, grad_fn=<NllLossBackward>), tensor(1.0718, grad_fn=<NllLossBackward>), tensor(1.0661, grad_fn=<NllLossBackward>), tensor(1.0929, grad_fn=<NllLossBackward>), tensor(0.7938, grad_fn=<NllLossBackward>), tensor(0.9304, grad_fn=<NllLossBackward>), tensor(1.0277, grad_fn=<NllLossBackward>), tensor(0.9875, grad_fn=<NllLossBackward>), tensor(1.0310, grad_fn=<NllLossBackward>), tensor(1.0333, grad_fn=<NllLossBackward>), tensor(1.1645, grad_fn=<NllLossBackward>), tensor(0.9123, grad_fn=<NllLossBackward>), tensor(0.9441, grad_fn=<NllLossBackward>), tensor(0.9745, grad_fn=<NllLossBackward>), tensor(1.0749, grad_fn=<NllLossBackward>), tensor(0.9138, grad_fn=<NllLossBackward>), tensor(0.8568, grad_fn=<NllLossBackward>), tensor(1.0385, grad_fn=<NllLossBackward>), tensor(0.9669, grad_fn=<NllLossBackward>), tensor(0.9877, grad_fn=<NllLossBackward>), tensor(0.8911, grad_fn=<NllLossBackward>), tensor(0.9384, grad_fn=<NllLossBackward>), tensor(0.8586, grad_fn=<NllLossBackward>), tensor(0.8818, grad_fn=<NllLossBackward>), tensor(0.9375, grad_fn=<NllLossBackward>), tensor(1.0937, grad_fn=<NllLossBackward>), tensor(0.8962, grad_fn=<NllLossBackward>), tensor(0.8895, grad_fn=<NllLossBackward>), tensor(1.1225, grad_fn=<NllLossBackward>), tensor(1.0578, grad_fn=<NllLossBackward>), tensor(1.0016, grad_fn=<NllLossBackward>), tensor(0.8028, grad_fn=<NllLossBackward>), tensor(1.1702, grad_fn=<NllLossBackward>), tensor(0.7707, grad_fn=<NllLossBackward>), tensor(0.9558, grad_fn=<NllLossBackward>), tensor(0.9863, grad_fn=<NllLossBackward>), tensor(0.9960, grad_fn=<NllLossBackward>), tensor(0.9056, grad_fn=<NllLossBackward>), tensor(1.0167, grad_fn=<NllLossBackward>), tensor(0.9342, grad_fn=<NllLossBackward>), tensor(1.0143, grad_fn=<NllLossBackward>), tensor(0.9243, grad_fn=<NllLossBackward>), tensor(0.8636, grad_fn=<NllLossBackward>), tensor(0.9074, grad_fn=<NllLossBackward>), tensor(0.7537, grad_fn=<NllLossBackward>), tensor(0.7615, grad_fn=<NllLossBackward>), tensor(0.8261, grad_fn=<NllLossBackward>), tensor(1.0569, grad_fn=<NllLossBackward>), tensor(1.0787, grad_fn=<NllLossBackward>), tensor(1.0225, grad_fn=<NllLossBackward>), tensor(1.0386, grad_fn=<NllLossBackward>), tensor(0.9664, grad_fn=<NllLossBackward>), tensor(0.8572, grad_fn=<NllLossBackward>), tensor(0.9123, grad_fn=<NllLossBackward>), tensor(1.0407, grad_fn=<NllLossBackward>), tensor(0.8998, grad_fn=<NllLossBackward>), tensor(1.1426, grad_fn=<NllLossBackward>), tensor(0.9536, grad_fn=<NllLossBackward>), tensor(1.0862, grad_fn=<NllLossBackward>), tensor(1.1397, grad_fn=<NllLossBackward>), tensor(0.9743, grad_fn=<NllLossBackward>), tensor(1.0750, grad_fn=<NllLossBackward>), tensor(0.8476, grad_fn=<NllLossBackward>), tensor(0.7939, grad_fn=<NllLossBackward>), tensor(1.1331, grad_fn=<NllLossBackward>), tensor(0.9806, grad_fn=<NllLossBackward>), tensor(0.9271, grad_fn=<NllLossBackward>), tensor(1.0211, grad_fn=<NllLossBackward>), tensor(0.9919, grad_fn=<NllLossBackward>), tensor(0.8806, grad_fn=<NllLossBackward>), tensor(1.0029, grad_fn=<NllLossBackward>), tensor(0.8691, grad_fn=<NllLossBackward>), tensor(1.0750, grad_fn=<NllLossBackward>), tensor(0.9377, grad_fn=<NllLossBackward>), tensor(1.1776, grad_fn=<NllLossBackward>), tensor(1.1100, grad_fn=<NllLossBackward>), tensor(1.0181, grad_fn=<NllLossBackward>), tensor(0.8074, grad_fn=<NllLossBackward>), tensor(0.7630, grad_fn=<NllLossBackward>), tensor(0.9764, grad_fn=<NllLossBackward>), tensor(0.8876, grad_fn=<NllLossBackward>), tensor(0.9127, grad_fn=<NllLossBackward>), tensor(0.9784, grad_fn=<NllLossBackward>), tensor(0.7768, grad_fn=<NllLossBackward>), tensor(0.9130, grad_fn=<NllLossBackward>), tensor(0.9978, grad_fn=<NllLossBackward>), tensor(1.0750, grad_fn=<NllLossBackward>), tensor(1.0056, grad_fn=<NllLossBackward>), tensor(0.8481, grad_fn=<NllLossBackward>), tensor(0.9987, grad_fn=<NllLossBackward>), tensor(0.9292, grad_fn=<NllLossBackward>), tensor(1.1295, grad_fn=<NllLossBackward>), tensor(1.0324, grad_fn=<NllLossBackward>), tensor(1.0566, grad_fn=<NllLossBackward>), tensor(0.8518, grad_fn=<NllLossBackward>), tensor(0.9092, grad_fn=<NllLossBackward>), tensor(0.9332, grad_fn=<NllLossBackward>), tensor(1.0142, grad_fn=<NllLossBackward>), tensor(0.7932, grad_fn=<NllLossBackward>), tensor(0.9983, grad_fn=<NllLossBackward>), tensor(0.9865, grad_fn=<NllLossBackward>), tensor(0.9695, grad_fn=<NllLossBackward>), tensor(1.1523, grad_fn=<NllLossBackward>), tensor(0.9729, grad_fn=<NllLossBackward>), tensor(0.9022, grad_fn=<NllLossBackward>), tensor(1.1106, grad_fn=<NllLossBackward>), tensor(0.9752, grad_fn=<NllLossBackward>), tensor(0.8526, grad_fn=<NllLossBackward>), tensor(0.8790, grad_fn=<NllLossBackward>), tensor(0.8173, grad_fn=<NllLossBackward>), tensor(0.8087, grad_fn=<NllLossBackward>), tensor(0.9993, grad_fn=<NllLossBackward>), tensor(0.9661, grad_fn=<NllLossBackward>), tensor(0.9393, grad_fn=<NllLossBackward>), tensor(0.9532, grad_fn=<NllLossBackward>), tensor(0.9114, grad_fn=<NllLossBackward>), tensor(1.1463, grad_fn=<NllLossBackward>), tensor(1.0566, grad_fn=<NllLossBackward>), tensor(0.9980, grad_fn=<NllLossBackward>), tensor(0.8979, grad_fn=<NllLossBackward>), tensor(1.0595, grad_fn=<NllLossBackward>), tensor(1.1084, grad_fn=<NllLossBackward>), tensor(1.0289, grad_fn=<NllLossBackward>), tensor(0.9590, grad_fn=<NllLossBackward>), tensor(0.8011, grad_fn=<NllLossBackward>), tensor(0.9992, grad_fn=<NllLossBackward>), tensor(0.9250, grad_fn=<NllLossBackward>), tensor(1.0452, grad_fn=<NllLossBackward>), tensor(0.8372, grad_fn=<NllLossBackward>), tensor(0.9658, grad_fn=<NllLossBackward>), tensor(1.0122, grad_fn=<NllLossBackward>), tensor(0.8221, grad_fn=<NllLossBackward>), tensor(0.8703, grad_fn=<NllLossBackward>), tensor(1.0566, grad_fn=<NllLossBackward>), tensor(0.9244, grad_fn=<NllLossBackward>), tensor(1.0730, grad_fn=<NllLossBackward>), tensor(0.9378, grad_fn=<NllLossBackward>), tensor(0.8009, grad_fn=<NllLossBackward>), tensor(0.8483, grad_fn=<NllLossBackward>), tensor(1.0366, grad_fn=<NllLossBackward>), tensor(0.9450, grad_fn=<NllLossBackward>), tensor(0.8850, grad_fn=<NllLossBackward>), tensor(0.9097, grad_fn=<NllLossBackward>), tensor(0.8993, grad_fn=<NllLossBackward>), tensor(1.0512, grad_fn=<NllLossBackward>), tensor(0.9909, grad_fn=<NllLossBackward>), tensor(1.1260, grad_fn=<NllLossBackward>), tensor(0.9467, grad_fn=<NllLossBackward>), tensor(0.9973, grad_fn=<NllLossBackward>), tensor(0.9594, grad_fn=<NllLossBackward>), tensor(0.8365, grad_fn=<NllLossBackward>), tensor(1.0861, grad_fn=<NllLossBackward>), tensor(1.0176, grad_fn=<NllLossBackward>), tensor(0.9069, grad_fn=<NllLossBackward>), tensor(0.9940, grad_fn=<NllLossBackward>), tensor(0.9124, grad_fn=<NllLossBackward>), tensor(0.8544, grad_fn=<NllLossBackward>), tensor(0.9254, grad_fn=<NllLossBackward>), tensor(0.9121, grad_fn=<NllLossBackward>), tensor(1.0675, grad_fn=<NllLossBackward>), tensor(1.1292, grad_fn=<NllLossBackward>), tensor(0.8482, grad_fn=<NllLossBackward>), tensor(1.0138, grad_fn=<NllLossBackward>), tensor(0.9984, grad_fn=<NllLossBackward>), tensor(1.1259, grad_fn=<NllLossBackward>), tensor(1.0344, grad_fn=<NllLossBackward>), tensor(0.9224, grad_fn=<NllLossBackward>), tensor(0.9303, grad_fn=<NllLossBackward>), tensor(1.1388, grad_fn=<NllLossBackward>), tensor(0.9442, grad_fn=<NllLossBackward>), tensor(0.9959, grad_fn=<NllLossBackward>), tensor(0.9970, grad_fn=<NllLossBackward>), tensor(0.8090, grad_fn=<NllLossBackward>), tensor(0.9588, grad_fn=<NllLossBackward>), tensor(0.9089, grad_fn=<NllLossBackward>), tensor(0.7665, grad_fn=<NllLossBackward>), tensor(0.7427, grad_fn=<NllLossBackward>), tensor(0.8598, grad_fn=<NllLossBackward>), tensor(1.0220, grad_fn=<NllLossBackward>), tensor(0.8276, grad_fn=<NllLossBackward>), tensor(0.9555, grad_fn=<NllLossBackward>), tensor(1.0205, grad_fn=<NllLossBackward>), tensor(0.9746, grad_fn=<NllLossBackward>), tensor(0.9647, grad_fn=<NllLossBackward>), tensor(0.9786, grad_fn=<NllLossBackward>), tensor(0.9884, grad_fn=<NllLossBackward>), tensor(0.8544, grad_fn=<NllLossBackward>), tensor(0.8455, grad_fn=<NllLossBackward>), tensor(0.8784, grad_fn=<NllLossBackward>), tensor(1.1483, grad_fn=<NllLossBackward>), tensor(0.9647, grad_fn=<NllLossBackward>), tensor(1.2243, grad_fn=<NllLossBackward>), tensor(0.9751, grad_fn=<NllLossBackward>), tensor(0.9127, grad_fn=<NllLossBackward>), tensor(1.0608, grad_fn=<NllLossBackward>), tensor(0.9136, grad_fn=<NllLossBackward>), tensor(0.9889, grad_fn=<NllLossBackward>), tensor(0.9419, grad_fn=<NllLossBackward>), tensor(0.9920, grad_fn=<NllLossBackward>), tensor(0.9878, grad_fn=<NllLossBackward>), tensor(0.9703, grad_fn=<NllLossBackward>), tensor(0.9315, grad_fn=<NllLossBackward>), tensor(0.8884, grad_fn=<NllLossBackward>), tensor(0.8631, grad_fn=<NllLossBackward>), tensor(1.0094, grad_fn=<NllLossBackward>), tensor(1.0686, grad_fn=<NllLossBackward>), tensor(0.8708, grad_fn=<NllLossBackward>), tensor(1.0523, grad_fn=<NllLossBackward>), tensor(1.0649, grad_fn=<NllLossBackward>), tensor(1.1032, grad_fn=<NllLossBackward>), tensor(0.7760, grad_fn=<NllLossBackward>), tensor(1.1379, grad_fn=<NllLossBackward>), tensor(0.8759, grad_fn=<NllLossBackward>), tensor(1.0377, grad_fn=<NllLossBackward>), tensor(0.7115, grad_fn=<NllLossBackward>), tensor(0.8967, grad_fn=<NllLossBackward>), tensor(0.9517, grad_fn=<NllLossBackward>), tensor(1.0628, grad_fn=<NllLossBackward>), tensor(0.9295, grad_fn=<NllLossBackward>), tensor(1.1005, grad_fn=<NllLossBackward>), tensor(0.8576, grad_fn=<NllLossBackward>), tensor(0.6287, grad_fn=<NllLossBackward>), tensor(1.0326, grad_fn=<NllLossBackward>), tensor(0.9878, grad_fn=<NllLossBackward>), tensor(1.0430, grad_fn=<NllLossBackward>), tensor(0.9150, grad_fn=<NllLossBackward>), tensor(1.0493, grad_fn=<NllLossBackward>), tensor(1.0639, grad_fn=<NllLossBackward>), tensor(0.7828, grad_fn=<NllLossBackward>), tensor(0.9043, grad_fn=<NllLossBackward>), tensor(0.9009, grad_fn=<NllLossBackward>), tensor(0.9891, grad_fn=<NllLossBackward>), tensor(1.0781, grad_fn=<NllLossBackward>), tensor(0.8132, grad_fn=<NllLossBackward>), tensor(1.0775, grad_fn=<NllLossBackward>), tensor(1.0175, grad_fn=<NllLossBackward>), tensor(0.7949, grad_fn=<NllLossBackward>), tensor(0.9916, grad_fn=<NllLossBackward>), tensor(1.0140, grad_fn=<NllLossBackward>), tensor(1.0710, grad_fn=<NllLossBackward>), tensor(0.8587, grad_fn=<NllLossBackward>), tensor(1.0595, grad_fn=<NllLossBackward>), tensor(0.9235, grad_fn=<NllLossBackward>), tensor(1.1938, grad_fn=<NllLossBackward>), tensor(0.9652, grad_fn=<NllLossBackward>), tensor(0.9433, grad_fn=<NllLossBackward>), tensor(0.9221, grad_fn=<NllLossBackward>), tensor(0.9634, grad_fn=<NllLossBackward>), tensor(0.8118, grad_fn=<NllLossBackward>), tensor(1.0002, grad_fn=<NllLossBackward>), tensor(0.8756, grad_fn=<NllLossBackward>), tensor(0.7850, grad_fn=<NllLossBackward>), tensor(0.7834, grad_fn=<NllLossBackward>), tensor(0.9707, grad_fn=<NllLossBackward>), tensor(0.9303, grad_fn=<NllLossBackward>), tensor(0.7739, grad_fn=<NllLossBackward>), tensor(0.7785, grad_fn=<NllLossBackward>), tensor(0.9056, grad_fn=<NllLossBackward>), tensor(0.8382, grad_fn=<NllLossBackward>), tensor(0.8979, grad_fn=<NllLossBackward>), tensor(1.1519, grad_fn=<NllLossBackward>), tensor(0.8811, grad_fn=<NllLossBackward>), tensor(0.9968, grad_fn=<NllLossBackward>), tensor(0.8181, grad_fn=<NllLossBackward>), tensor(1.0131, grad_fn=<NllLossBackward>), tensor(0.9572, grad_fn=<NllLossBackward>), tensor(0.8513, grad_fn=<NllLossBackward>), tensor(0.9841, grad_fn=<NllLossBackward>), tensor(1.0579, grad_fn=<NllLossBackward>), tensor(0.7862, grad_fn=<NllLossBackward>), tensor(1.1680, grad_fn=<NllLossBackward>), tensor(0.8637, grad_fn=<NllLossBackward>), tensor(1.0470, grad_fn=<NllLossBackward>), tensor(0.9967, grad_fn=<NllLossBackward>), tensor(1.0797, grad_fn=<NllLossBackward>), tensor(0.9599, grad_fn=<NllLossBackward>), tensor(0.9679, grad_fn=<NllLossBackward>), tensor(0.9688, grad_fn=<NllLossBackward>), tensor(0.8961, grad_fn=<NllLossBackward>), tensor(0.9934, grad_fn=<NllLossBackward>), tensor(1.1333, grad_fn=<NllLossBackward>), tensor(1.0897, grad_fn=<NllLossBackward>), tensor(1.1860, grad_fn=<NllLossBackward>), tensor(0.9360, grad_fn=<NllLossBackward>), tensor(0.8259, grad_fn=<NllLossBackward>), tensor(0.8881, grad_fn=<NllLossBackward>), tensor(0.8348, grad_fn=<NllLossBackward>), tensor(0.8926, grad_fn=<NllLossBackward>), tensor(0.8764, grad_fn=<NllLossBackward>), tensor(0.8899, grad_fn=<NllLossBackward>), tensor(0.8489, grad_fn=<NllLossBackward>), tensor(1.0416, grad_fn=<NllLossBackward>), tensor(1.0672, grad_fn=<NllLossBackward>), tensor(1.1002, grad_fn=<NllLossBackward>), tensor(0.8466, grad_fn=<NllLossBackward>), tensor(0.8775, grad_fn=<NllLossBackward>), tensor(0.7978, grad_fn=<NllLossBackward>), tensor(0.8317, grad_fn=<NllLossBackward>), tensor(0.9100, grad_fn=<NllLossBackward>), tensor(0.9086, grad_fn=<NllLossBackward>), tensor(0.9080, grad_fn=<NllLossBackward>), tensor(1.0921, grad_fn=<NllLossBackward>), tensor(0.6952, grad_fn=<NllLossBackward>), tensor(0.9935, grad_fn=<NllLossBackward>), tensor(1.0761, grad_fn=<NllLossBackward>), tensor(1.6471, grad_fn=<NllLossBackward>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1U_bchkmwUB"
      },
      "source": [
        "### Напишите цикл валидации\n",
        "Что он должен в себя включать:\n",
        "1. Получение предсказаний модели\n",
        "1. Расчет функции потерь\n",
        "1. Записывание значения лосса\n",
        "\n",
        "Также с помощью контекста ```with torch.no_grad():``` можно явно указать торчу не сохранять необходимые параметры для расчета градиентов. Обязательно для режима предсказания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wgva1lKmwUC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e58082d0-7cac-4c13-a8aa-a0a18da4dba1"
      },
      "source": [
        "losses = list()\n",
        "\n",
        "# это переводит модель в режим предсказания\n",
        "# то есть фиксируются статистики батч норма, дропаут не выкидывает фичи\n",
        "model.eval()\n",
        "\n",
        "# заметьте, что мы поменяли наш лоадер на валидационный\n",
        "for x, y in valid_loader:\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # получение предсказаний модели\n",
        "        # расчет лосса\n",
        "        prediction = model.forward(x)\n",
        "        loss = criterion(prediction, y)\n",
        "        losses.append(loss)\n",
        "print(f\"Validation loss: {loss}\")"
      ],
      "execution_count": 96,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 0.9907236099243164\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZJ7BOS8tPfw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc0449e7-a7b9-4b01-fca2-feeeba5d47c4"
      },
      "source": [
        "print(losses)"
      ],
      "execution_count": 97,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.0799), tensor(1.0703), tensor(0.9349), tensor(1.0394), tensor(1.0949), tensor(0.9599), tensor(0.9383), tensor(1.0513), tensor(0.9506), tensor(0.9359), tensor(0.9180), tensor(0.9161), tensor(0.8734), tensor(0.8830), tensor(0.8905), tensor(0.9049), tensor(1.0106), tensor(1.0366), tensor(0.9936), tensor(1.0242), tensor(1.0650), tensor(1.1092), tensor(0.8566), tensor(0.8838), tensor(0.9048), tensor(0.9269), tensor(1.1119), tensor(1.0157), tensor(1.0317), tensor(0.8431), tensor(0.8540), tensor(1.0820), tensor(0.8866), tensor(0.8910), tensor(0.9537), tensor(0.9437), tensor(0.9196), tensor(0.9435), tensor(1.0024), tensor(0.9045), tensor(1.0789), tensor(1.0695), tensor(0.8790), tensor(1.0785), tensor(0.9241), tensor(0.8743), tensor(0.8208), tensor(1.1565), tensor(0.8539), tensor(1.1250), tensor(1.0391), tensor(0.8069), tensor(0.9178), tensor(0.7759), tensor(0.8628), tensor(1.0841), tensor(0.8747), tensor(1.2374), tensor(0.8999), tensor(0.8385), tensor(0.8091), tensor(0.8818), tensor(1.1910), tensor(1.0533), tensor(1.0120), tensor(0.9713), tensor(0.9268), tensor(0.8955), tensor(1.0363), tensor(0.9256), tensor(0.9317), tensor(0.9945), tensor(0.9219), tensor(1.0634), tensor(0.9324), tensor(0.8686), tensor(1.2095), tensor(1.0350), tensor(1.0439), tensor(0.9733), tensor(0.9117), tensor(0.8420), tensor(0.8906), tensor(0.8879), tensor(0.8660), tensor(0.8398), tensor(0.9359), tensor(0.8746), tensor(0.9015), tensor(0.8790), tensor(0.8421), tensor(1.0618), tensor(0.9287), tensor(0.8378), tensor(0.8776), tensor(0.9295), tensor(0.7951), tensor(1.0005), tensor(0.8418), tensor(0.9490), tensor(1.0550), tensor(0.9316), tensor(0.9869), tensor(0.9440), tensor(1.0409), tensor(0.8586), tensor(1.0053), tensor(1.0556), tensor(0.9651), tensor(0.8782), tensor(0.7327), tensor(0.8312), tensor(1.0470), tensor(0.9664), tensor(1.0601), tensor(1.0653), tensor(0.9296), tensor(1.0059), tensor(0.7968), tensor(1.0598), tensor(1.1089), tensor(0.8550), tensor(1.0852), tensor(0.8118), tensor(0.9011), tensor(0.9464), tensor(0.9212), tensor(0.8953), tensor(0.9065), tensor(0.9825), tensor(0.8842), tensor(0.9265), tensor(1.0304), tensor(0.8186), tensor(0.8354), tensor(0.8075), tensor(0.9287), tensor(0.8881), tensor(0.8489), tensor(0.9149), tensor(0.9672), tensor(0.9986), tensor(0.7676), tensor(1.0169), tensor(0.8938), tensor(0.9618), tensor(0.9533), tensor(0.9460), tensor(1.0191), tensor(0.9620), tensor(0.9989), tensor(0.9621), tensor(0.9429), tensor(0.8929), tensor(0.8272), tensor(0.8905), tensor(0.8092), tensor(0.8445), tensor(1.0094), tensor(1.0265), tensor(0.9270), tensor(1.0129), tensor(0.9405), tensor(0.8360), tensor(0.9085), tensor(0.8125), tensor(0.9010), tensor(0.9506), tensor(0.9850), tensor(0.8765), tensor(0.8839), tensor(0.9819), tensor(0.9833), tensor(0.9848), tensor(0.9631), tensor(0.8709), tensor(0.8019), tensor(1.0260), tensor(1.1873), tensor(0.9944), tensor(0.8055), tensor(0.9642), tensor(0.8627), tensor(1.0060), tensor(0.7547), tensor(0.9247), tensor(0.9160), tensor(1.0072), tensor(0.7179), tensor(0.8824), tensor(1.0330), tensor(0.9572), tensor(0.8885), tensor(1.1886), tensor(0.9541), tensor(0.9124), tensor(0.9486), tensor(0.8645), tensor(0.9954), tensor(0.8824), tensor(0.8382), tensor(0.9362), tensor(0.9309), tensor(0.9696), tensor(0.9359), tensor(0.9668), tensor(0.9154), tensor(0.9521), tensor(1.0759), tensor(1.0822), tensor(1.0985), tensor(0.9494), tensor(0.8365), tensor(1.0110), tensor(0.8021), tensor(0.9695), tensor(0.8849), tensor(0.8174), tensor(0.9906), tensor(0.9881), tensor(0.9157), tensor(0.9321), tensor(0.9751), tensor(0.9340), tensor(0.7648), tensor(1.0580), tensor(1.2289), tensor(1.0997), tensor(0.9080), tensor(1.0708), tensor(1.1829), tensor(0.9070), tensor(0.9987), tensor(1.0791), tensor(0.8555), tensor(0.9472), tensor(1.1092), tensor(0.8538), tensor(0.9160), tensor(0.8419), tensor(0.9194), tensor(0.9623), tensor(0.7185), tensor(1.1620), tensor(0.8639), tensor(0.9914), tensor(0.9853), tensor(1.0042), tensor(1.1700), tensor(1.1055), tensor(0.9903), tensor(0.8827), tensor(1.0037), tensor(0.8563), tensor(0.8448), tensor(1.0098), tensor(1.2163), tensor(1.0765), tensor(0.9350), tensor(0.9309), tensor(1.0402), tensor(0.9335), tensor(1.0322), tensor(1.1064), tensor(1.0351), tensor(1.0914), tensor(1.0808), tensor(1.0419), tensor(1.0195), tensor(0.9050), tensor(1.0770), tensor(0.9153), tensor(0.8841), tensor(0.9759), tensor(0.9283), tensor(1.0247), tensor(1.0299), tensor(0.8303), tensor(0.9847), tensor(0.9704), tensor(0.9571), tensor(0.9168), tensor(1.0079), tensor(1.0508), tensor(0.8995), tensor(1.1629), tensor(1.0501), tensor(0.8550), tensor(0.8703), tensor(0.8264), tensor(0.8048), tensor(0.8321), tensor(0.8900), tensor(0.9197), tensor(0.9602), tensor(0.8537), tensor(0.9138), tensor(0.8820), tensor(1.0219), tensor(0.8301), tensor(1.0392), tensor(0.9376), tensor(0.9490), tensor(0.9902), tensor(0.9159), tensor(0.9880), tensor(0.8678), tensor(0.9439), tensor(1.2167), tensor(0.9787), tensor(0.8495), tensor(0.7353), tensor(0.8766), tensor(0.9719), tensor(0.9269), tensor(0.8320), tensor(0.9745), tensor(0.8234), tensor(1.0425), tensor(0.9354), tensor(0.9984), tensor(0.9330), tensor(0.9671), tensor(0.8860), tensor(0.9967), tensor(0.7692), tensor(0.7164), tensor(0.9449), tensor(0.7561), tensor(0.9858), tensor(0.8617), tensor(0.9934), tensor(0.9225), tensor(0.9437), tensor(0.8554), tensor(0.9161), tensor(0.9219), tensor(1.0043), tensor(1.0059), tensor(0.9363), tensor(0.8905), tensor(0.9338), tensor(0.9409), tensor(1.0189), tensor(1.0425), tensor(1.0618), tensor(0.9064), tensor(0.9218), tensor(0.8253), tensor(1.1126), tensor(0.9626), tensor(0.7803), tensor(0.7706), tensor(0.7322), tensor(1.0520), tensor(1.1021), tensor(0.9483), tensor(1.0437), tensor(1.0205), tensor(0.9868), tensor(0.9950), tensor(0.9078), tensor(1.0061), tensor(0.9182), tensor(1.0460), tensor(0.9138), tensor(0.9585), tensor(0.9601), tensor(0.9004), tensor(0.9118), tensor(1.0022), tensor(1.1064), tensor(0.9068), tensor(0.9041), tensor(0.8993), tensor(0.8781), tensor(1.0375), tensor(0.8892), tensor(0.8671), tensor(0.9170), tensor(1.0026), tensor(1.0908), tensor(0.9130), tensor(1.0039), tensor(0.9414), tensor(0.8325), tensor(0.9570), tensor(0.7708), tensor(0.7664), tensor(0.9534), tensor(0.9907)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol_kM9k1mwUM"
      },
      "source": [
        "### Проведите обучение несколько эпох\n",
        "Одна эпоха - это один проход по датасету.  \n",
        "Шаги:\n",
        "- Поменяйте что-нибудь в модели, добавить дропаут и тд\n",
        "- Остановите обучение с помощью early stopping\n",
        "- Добавьте расчет метрик во время обучения и предсказания (например, micro F1). Чтобы это сделать вы можете, например, сохранять предсказания модели\n",
        "- После обучения нарисуйте как по мере обучения меняется функция потерь на тренировочном и валидационном датасете, как меняется метрики\n",
        "- Опционально: постройте confusion matrix\n",
        "\n",
        "Подсказки:\n",
        "- Чтобы корректно сохранять предсказания нужно переменную отсоединить от графа, то есть сделать ```x.detach()```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BbyH5Ag1Oda"
      },
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes, loss):\n",
        "        super().__init__()\n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=embeddings.shape[-1])\n",
        "        self.linear_1 = nn.Linear(in_features=embeddings.shape[-1], out_features=linear_1_size)\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding_layer(x)\n",
        "        x = x.sum(dim=1)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.linear_1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.linear_3(x)\n",
        "        return x"
      ],
      "execution_count": 98,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB_6hGEhmwUO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "394c9211-f035-45ac-e425-5d8c06048b9c"
      },
      "source": [
        "from sklearn.metrics import f1_score\n",
        "for instance in list(tqdm._instances):\n",
        "  tqdm._decr_instances(instance)\n",
        "best_val_loss = 10\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.0001)\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1, gamma=0.9)\n",
        "losses = list()\n",
        "epochs = 6\n",
        "for epoch in range(epochs):\n",
        "  train_losses = []\n",
        "  valid_losses = []\n",
        "  valid_targets = list()\n",
        "  valid_predictions = list()\n",
        "  model.train()\n",
        "  for x, y in train_loader:\n",
        "    prediction = model.forward(x)\n",
        "    loss = criterion(prediction, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    train_losses.append(loss.item())\n",
        "    losses.append(loss.item())\n",
        "    for instance in list(tqdm._instances):\n",
        "      tqdm._decr_instances(instance)\n",
        "  scheduler.step()\n",
        "  model.eval()\n",
        "  for x, y in valid_loader:\n",
        "    with torch.no_grad():\n",
        "      prediction = model.forward(x)\n",
        "      y_pred = torch.softmax(prediction, dim=-1)\n",
        "      optimizer.zero_grad()\n",
        "      val_loss = criterion(y_pred, y)\n",
        "      optimizer.step()\n",
        "      optimizer.zero_grad()\n",
        "      optimizer.step()\n",
        "  valid_targets.append(y.numpy())\n",
        "  valid_predictions.append(prediction.numpy())\n",
        "  loss = criterion(prediction, y.squeeze())\n",
        "  valid_losses.append(loss.item())\n",
        "  for instance in list(tqdm._instances):\n",
        "    tqdm._decr_instances(instance)\n",
        "  mean_val_loss = np.mean(valid_losses)\n",
        "  #if mean_val_loss < best_val_loss:\n",
        "  #    best_val_loss = mean_val_loss\n",
        "  #else:\n",
        "  #    break\n",
        "  print(f\"epoch {epoch} validation loss {val_loss}, train loss {loss}\")"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0 validation loss 1.6621997356414795, train loss 0.9419354200363159\n",
            "epoch 1 validation loss 1.6574821472167969, train loss 0.935039222240448\n",
            "epoch 2 validation loss 1.6534706354141235, train loss 0.9328190684318542\n",
            "epoch 3 validation loss 1.6500110626220703, train loss 0.9318434596061707\n",
            "epoch 4 validation loss 1.6470098495483398, train loss 0.9285534024238586\n",
            "epoch 5 validation loss 1.6445133686065674, train loss 0.9274650812149048\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-YOzMPGtaRbA",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "7c0d086f-1fb7-4fca-e6af-b1acdf122d5d"
      },
      "source": [
        "import matplotlib.pyplot as plt\r\n",
        "plt.figure(figsize=(14, 12))\r\n",
        "plt.plot(losses)\r\n",
        "plt.grid()"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1008x864 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5renhj2mwUT"
      },
      "source": [
        "### Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmrM4ZJmmwUU"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orDn0foymwUV"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - длина последовательности (количество слов)\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAfL-HX5mwUW"
      },
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ],
      "execution_count": 101,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN5XNWgTmwUc"
      },
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ],
      "execution_count": 102,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36fzFo1KmwUh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09d17374-6b9b-42fc-a960-b47b40608a01"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 103
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDUskIK_mwUm"
      },
      "source": [
        "# второй способ\n",
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntjtdkMVmwUw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4253dc3-63f0-48c3-c95c-2ec83435572a"
      },
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([64, 128, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 105
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJu3uRemwU1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8b28f63a-8862-4332-8f39-f2743eb8cbb3"
      },
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ],
      "execution_count": 106,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mxfZg8PmwU6"
      },
      "source": [
        "### Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHNejHyvmwU7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9d28745e-6bbf-4856-b24d-3be70e38e408"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 64, 1024])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfCzYVHbmwVB"
      },
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ],
      "execution_count": 108,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vJAwFoTmwVG"
      },
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVHgByh2mwVV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b4602b04-64f9-4f00-cf25-a10f5af5a0a1"
      },
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 1024, 64])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 110
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MulbXtNemwVb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b675fda0-3977-4d20-e90d-a1391c811a49"
      },
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ],
      "execution_count": 111,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 512, 62])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 111
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLnUJz9tmwVn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9dcad3e0-b811-4fcf-b0d0-694d12c7a3b7"
      },
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ],
      "execution_count": 112,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 62, 512])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 112
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsrsvOlUmwVt"
      },
      "source": [
        "### Еще важный момент про LSTM\n",
        "\n",
        "The input can also be a packed variable length sequence. See [torch.nn.utils.rnn.pack_padded_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence) or [torch.nn.utils.rnn.pack_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence) for details.\n",
        "\n",
        "Это внутренняя конструкция торча, которая позволяет не читать токен ```PAD```, но все еще работать с батчами. То есть внутри батча мы можем передать лстмке, что у нас данные переменной длины. Не забудьте что на выход отдается [torch.nn.utils.rnn.PackedSequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.PackedSequence)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkL1r6VGmwVw"
      },
      "source": [
        "## Домашнее задание\n",
        "\n",
        "1. Сделать класс нейронки, вписать необходимые операции, архитектура ниже\n",
        "1. Написать обучалку (обобщить то, что было выше)\n",
        "1. Добавить логирование\n",
        "    1. Сохранять лосс на каждой итерции обучения __0.25 балла__\n",
        "    1. Каждую эпоху сохранять лосс трейна и тест __0.25 балла__\n",
        "    1. Каждую эпоху рассчитывать метрики __0.25 балла__\n",
        "    1. Добавить прогресс бар, в котором показывается усредненный лосс последних 500-та итераций __0.25 балла__\n",
        "1. Добавить early stopping __0.5 балла__\n",
        "1. Нарисовать графики лосса, метрик, конфьюжин матрицу __0.5 балла__\n",
        "\n",
        "\n",
        "### Архитектура (что можно попробовать)\n",
        "1. Предобученные эмбеддинги. Почитайте [здесь](https://pytorch.org/docs/stable/nn.html#embedding) (from_pretrained) как вставить свои эмбеддинги, выше мы читали матрицу эмбеддингов. __0 баллов__\n",
        "1. Дообучить эмбеддинги отдельно от сети. __2 балла__\n",
        "1. Дообучить эмбеддинги вместе с сетью и с другим learning rate (указывается в оптимизаторе). __2 балла__\n",
        "1. Bidirectional LSTM. __1 балл__\n",
        "1. Несколько параллельных CNN с разными размерами окна и mean/max over time пулингами к ним и дальнейшей конкатенацией. __2 балла__\n",
        "1. Несколько последовательных CNN. __1 балла__\n",
        "1. Разные окна и residual к предыдущему пункту. __2 балла__\n",
        "1. Предыдущий пункт сделан без ошибок (замаскированы свертки паддингов). __2 балла__\n",
        "1. Написать правильный правильный mean/max пулинг, который не учитывает паддинги, точнее их маскирует. __2 балла__\n",
        "1. Добавить [torch.nn.utils.rnn.pack_padded_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence) и [torch.nn.utils.rnn.pack_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence) для LSTM. Инфа [здесь](#Еще-важный-момент-про-LSTM) __2 балла__\n",
        "1. Добавить spatial дропаут для входа LSTM (не просто стандартный пункт при инициализации LSTM) __1 балл__\n",
        "1. Добавить BatchNorm/LayerNorm/Dropout/Residual/etc __1 балл__\n",
        "1. Добавить шедуллер __1 балл__\n",
        "1. Обучать на GPU __2 балла__\n",
        "1. Сделать transfer learning с собственно обученной языковой модели, обученной на любых данных, например, unlabeled. __7 баллов__\n",
        "1. your madness\n",
        "\n",
        "## 10 баллов максимум\n",
        "\n",
        "# По итогам напишите результаты экспериментов\n",
        "# Что получилось, а что нет\n",
        "# Почему, выводы"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c8s0PTVgd1iz"
      },
      "source": [
        "Параллельные CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICEx-xAomwVx"
      },
      "source": [
        "class Paral_CNN(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\r\n",
        "        \r\n",
        "        self.input_size = embeddings.shape[-1]\r\n",
        "        self.conv_size = int(self.input_size/2)\r\n",
        "        self.padding = nn.ConstantPad1d(padding=1, value=float('-inf'))\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv1d(in_channels=32, out_channels=64, kernel_size=2, stride=1, padding=1)\r\n",
        "        self.conv2 = nn.Conv1d(in_channels=32, out_channels=32, kernel_size=2, stride=1, padding=1)\r\n",
        "\r\n",
        "        self.dropout = nn.Dropout(p=0.5)\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "        self.linear_1 = nn.Linear(in_features=101, out_features=32)\r\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\r\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        x = self.embedding_layer(x)\r\n",
        "\r\n",
        "        x1 = self.conv1(x)\r\n",
        "        x1 = torch.max_pool1d(x1,padding=1, kernel_size=3)\r\n",
        "\r\n",
        "        x2 = self.conv2(x)\r\n",
        "        x2 = torch.avg_pool1d(x2, padding=1, kernel_size=3)\r\n",
        "\r\n",
        "        x = torch.cat([x1, x2], dim=1)\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.linear_1(x)\r\n",
        "        x = x.sum(dim=1)\r\n",
        "        x = torch.relu(x)\r\n",
        "        x = self.linear_2(x)\r\n",
        "        x = self.dropout(x)\r\n",
        "        x = torch.relu(x)\r\n",
        "        x = self.linear_3(x)\r\n",
        "        \r\n",
        "        \r\n",
        "        return x"
      ],
      "execution_count": 113,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-RmNcV5neYlQ"
      },
      "source": [
        "model = Paral_CNN(embeddings=embeddings, linear_1_size = 32, linear_2_size = 16, n_classes=len(category2index))"
      ],
      "execution_count": 114,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wL_S8LoOgV6y"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=0.005)\r\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1)"
      ],
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCheCdRCgccn"
      },
      "source": [
        "epochs = 6\r\n",
        "train_losses = []\r\n",
        "test_losses = []\r\n",
        "for epoch in range(epochs):\r\n",
        "  for x, y in train_loader:\r\n",
        "    #print(y)\r\n",
        "    y_pred = model.forward(x)\r\n",
        "    #print(y_pred)\r\n",
        "    train_loss = criterion(y_pred, y)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "  train_losses.append(train_loss)\r\n",
        "  scheduler.step()\r\n",
        "  for x, y in valid_loader:        \r\n",
        "      with torch.no_grad():\r\n",
        "          x_forw = model.forward(x)\r\n",
        "          y_pred = torch.softmax(x_forw, dim=-1)\r\n",
        "          optimizer.zero_grad()\r\n",
        "          test_loss = criterion(y_pred, y)\r\n",
        "          acc_list.append(test_acc)\r\n",
        "          optimizer.step()\r\n",
        "          optimizer.zero_grad()\r\n",
        "          optimizer.step()\r\n",
        "  test_losses.append(test_loss)\r\n",
        "  print(f\"epoch {epoch} train loss {train_loss}, test loss {test_loss}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i9I1xhXeS-HF"
      },
      "source": [
        "plt.figure(figsize=(14, 12))\r\n",
        "plt.plot(range(epochs), train_losses)\r\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "snWOgx2iT6Cy"
      },
      "source": [
        "Последовательные CNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLUu7o20TN3N"
      },
      "source": [
        "class Posl_CNN(nn.Module):\r\n",
        "    \r\n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes):\r\n",
        "        super().__init__()\r\n",
        "        \r\n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0, freeze=False)\r\n",
        "\r\n",
        "        self.input_size = embeddings.shape[-1]\r\n",
        "        self.conv_size_1 = int(self.input_size/2)\r\n",
        "        self.conv_size_2 = int(self.conv_size_1/2)\r\n",
        "\r\n",
        "        self.conv1 = nn.Conv1d(in_channels=self.input_size, out_channels=self.conv_size_1, kernel_size=3, stride=1, padding=0)\r\n",
        "        self.pool1 = nn.MaxPool1d(kernel_size=3, stride=1, padding=0)\r\n",
        "        self.conv2 = nn.Conv1d(in_channels=self.conv_size_1, out_channels=self.conv_size_2, kernel_size=3, stride=1, padding=0)\r\n",
        "        self.pool2 = nn.MaxPool1d(kernel_size=3, stride=1, padding=0)\r\n",
        "\r\n",
        "        self.batch_norm1 = nn.BatchNorm1d(num_features=self.conv_size_1)\r\n",
        "        self.batch_norm2 = nn.BatchNorm1d(num_features=self.conv_size_2)\r\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=self.conv_size_2)\r\n",
        "\r\n",
        "        self.relu = nn.ReLU()\r\n",
        "\r\n",
        "        self.linear_1 = nn.Linear(in_features=self.conv_size_2, out_features=linear_1_size)\r\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\r\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\r\n",
        "\r\n",
        "\r\n",
        "    def forward(self, x):\r\n",
        "\r\n",
        "        x = self.embedding_layer(x)\r\n",
        "\r\n",
        "        x = x.transpose(1, 2)\r\n",
        "\r\n",
        "        x = self.conv1(x)\r\n",
        "        x = self.batch_norm1(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.pool1(x)\r\n",
        "        x = self.conv2(x)\r\n",
        "        x = self.batch_norm2(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        x = self.pool2(x)\r\n",
        "\r\n",
        "        x = x.transpose(1, 2)\r\n",
        "\r\n",
        "        x = x.sum(dim=1)\r\n",
        "\r\n",
        "        x = self.batch_norm(x)\r\n",
        "\r\n",
        "        x = self.linear_1(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        # x = torch.relu(x)\r\n",
        "        x = self.linear_2(x)\r\n",
        "        x = self.relu(x)\r\n",
        "        # x = torch.relu(x)\r\n",
        "        x = self.linear_3(x)\r\n",
        "             \r\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qDwAuczTVA8r"
      },
      "source": [
        "model = Posl_CNN(embeddings=embeddings, linear_1_size=32, linear_2_size=16, n_classes=len(category2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GonHzi4Kfqc3"
      },
      "source": [
        "model_params = [x[1] for x in list(filter(lambda x: x[0] != 'embedding_layer.weight', model.named_parameters()))]\r\n",
        "embedding_params = model.embedding_layer.parameters()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DbtKXXhzVazX"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\r\n",
        "optimizer = torch.optim.Adam(params=[{'params': embedding_params, 'lr': 0.0001}, {'params': model_params, 'lr': 0.005}])\r\n",
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ApbrsA8dVqR0"
      },
      "source": [
        "from sklearn.metrics import f1_score\r\n",
        "epochs = 6\r\n",
        "train_losses = []\r\n",
        "train_iteration_losses = []\r\n",
        "test_losses = []\r\n",
        "mean_f_scores_train = list()\r\n",
        "mean_f_scores_test = list()\r\n",
        "best_test_loss = 10\r\n",
        "for epoch in range(epochs):\r\n",
        "  f_scores_train = list()\r\n",
        "  f_scores_test = list()\r\n",
        "  model.train()\r\n",
        "  train_progress_bar = tqdm(total=len(train_loader.dataset), desc=f'Epoch: {epoch + 1}, train')\r\n",
        "  for x, y in train_loader:\r\n",
        "    y_pred = model.forward(x)\r\n",
        "    f_scores_train.append(f1_score(y, y_pred.argmax(1), average='micro'))\r\n",
        "    train_loss = criterion(y_pred, y)\r\n",
        "    train_iteration_losses.append(train_loss)\r\n",
        "    optimizer.zero_grad()\r\n",
        "    train_loss.backward()\r\n",
        "    optimizer.step()\r\n",
        "  train_losses.append(train_loss)\r\n",
        "  train_progress_bar.set_postfix(train_loss = np.mean(train_losses[-500:]))\r\n",
        "  train_progress_bar.update(x.shape[0])\r\n",
        "  scheduler.step()\r\n",
        "  train_progress_bar.close()\r\n",
        "  model.eval()\r\n",
        "  train_progress_bar = tqdm(total=len(valid_loader.dataset), desc=f'Epoch: {epoch + 1}, test')\r\n",
        "  for x, y in valid_loader:      \r\n",
        "      with torch.no_grad():\r\n",
        "          x_forw = model.forward(x)\r\n",
        "          y_pred = torch.softmax(x_forw, dim=-1)\r\n",
        "          optimizer.zero_grad()\r\n",
        "          test_loss = criterion(y_pred, y)\r\n",
        "          optimizer.step()\r\n",
        "          optimizer.zero_grad()\r\n",
        "          optimizer.step()\r\n",
        "      f_scores_test.append(f1_score(y, pred.argmax(1), average='micro'))\r\n",
        "  test_losses.append(test_loss)\r\n",
        "  test_progress_bar.set_postfix(test_loss = np.mean(test_losses[-500:]))\r\n",
        "  test_progress_bar.update(x.shape[0])\r\n",
        "  test_progress_bar.close()\r\n",
        "  mean_test_loss = np.mean(valid_losses)\r\n",
        "  mean_f_scores_train.append(np.mean(f_scores_train))\r\n",
        "  mean_f_scores_test.append(np.mean(f_scores_test))\r\n",
        "  print(f\"epoch { i } test loss {test_loss}, train loss {train_loss}\")\r\n",
        "  if mean_test_loss < best_test_loss:\r\n",
        "        best_test_loss = mean_test_loss\r\n",
        "    else:\r\n",
        "        break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "687ql-nPune8"
      },
      "source": [
        "plt.figure(figsize=(5, 5))\r\n",
        "plt.plot(mean_f_scores_train)\r\n",
        "plt.grid()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NkCnKV_luo91"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}