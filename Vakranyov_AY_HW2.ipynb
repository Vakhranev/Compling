{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    },
    "colab": {
      "name": "Копия блокнота \"Homework 2.ipynb\"",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Compling/blob/master/Vakranyov_AY_HW2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PauhqetfmwFy",
        "outputId": "74e7219b-60fe-46a2-854c-6c4a3728987e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!wget https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py\n",
        "\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import torch\n",
        "\n",
        "import zipfile\n",
        "\n",
        "import seaborn as sns\n",
        "\n",
        "from data import Downloader, Parser"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 09:10:29--  https://raw.githubusercontent.com/BobaZooba/HSE-Deep-Learning-in-NLP-Course/master/Week%203/data.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 10563 (10K) [text/plain]\n",
            "Saving to: ‘data.py’\n",
            "\n",
            "data.py             100%[===================>]  10.32K  --.-KB/s    in 0s      \n",
            "\n",
            "2020-10-29 09:10:30 (79.7 MB/s) - ‘data.py’ saved [10563/10563]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lkj-KkyFmwGE"
      },
      "source": [
        "### Загружаем файл с эмбеддингами для английского языка\n",
        "Они нам понадобятся чуть позже.  \n",
        "Для других языков можете найти здесь: https://fasttext.cc/docs/en/crawl-vectors.html"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z_lth05VmwGG",
        "outputId": "cef302e8-df63-40ef-b1d1-0ac0f7526d70",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# раскомментируйте и скачайте\n",
        "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2020-10-29 09:11:24--  https://dl.fbaipublicfiles.com/fasttext/vectors-english/wiki-news-300d-1M.vec.zip\n",
            "Resolving dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)... 104.22.74.142, 104.22.75.142, 172.67.9.4, ...\n",
            "Connecting to dl.fbaipublicfiles.com (dl.fbaipublicfiles.com)|104.22.74.142|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 681808098 (650M) [application/zip]\n",
            "Saving to: ‘wiki-news-300d-1M.vec.zip’\n",
            "\n",
            "wiki-news-300d-1M.v 100%[===================>] 650.22M  24.1MB/s    in 28s     \n",
            "\n",
            "2020-10-29 09:11:52 (23.4 MB/s) - ‘wiki-news-300d-1M.vec.zip’ saved [681808098/681808098]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W1bwsmP5mwGV"
      },
      "source": [
        "# путь к данным\n",
        "data_path = './data/'"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_ThM59tmwGh"
      },
      "source": [
        "### Читалка данные\n",
        "Не стоит вдаваться в подробности, просто эта штука скачивает данные, затем парсит и делает из них три датасета:\n",
        "- тренировочный\n",
        "- валидационный\n",
        "- неразмеченный\n",
        "\n",
        "Неразмеченные данные необазятельны, но могут вам понадобиться, например, для языковой модели или улучшения эмбеддингов."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAp_0GoumwGj"
      },
      "source": [
        "downloader = Downloader(data_path=data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4PXrpMymwGw",
        "outputId": "055dabe5-591d-4429-eb75-b4784167c8a4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "downloader.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "single: 100%|██████████| 21/21 [00:15<00:00,  1.36it/s]\n",
            "multiple: 100%|██████████| 17/17 [00:18<00:00,  1.08s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hzGKfthjmwG8"
      },
      "source": [
        "parser = Parser(data_path=data_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5g7DkPr1mwHG",
        "outputId": "5d090fe3-3982-4ed9-b9bd-71cd396c5038",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "unlabeled, train, valid = parser.run()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Reading: 100%|██████████| 38/38 [02:44<00:00,  4.33s/it]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Z9fJ3trmwHW"
      },
      "source": [
        "### Посмотрим на датасеты"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOb7ee6emwHY",
        "outputId": "ac655adb-50cb-4003-8e66-8e6cbdd6c0bd",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "unlabeled"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>the seller replied that the knife was made in ...</td>\n",
              "      <td>england</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>can the ringer be totally turned off? this is ...</td>\n",
              "      <td>yes it can be turned off and not ring at all</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>will this phone work with consumer cellular' s...</td>\n",
              "      <td>i just switched to consumer cellular and all f...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>how quickly does this printer go through ink w...</td>\n",
              "      <td>i've never measured it, but you do get a good ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>will this device allow me to surfer the intern...</td>\n",
              "      <td>you can but you need to attach a compatible 3g...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137275</th>\n",
              "      <td>it says minimum weight 60lbs and maximum weigh...</td>\n",
              "      <td>the manual says up to 50 lbs.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137276</th>\n",
              "      <td>does this version have a limited number of use...</td>\n",
              "      <td>i was wondering the same thing &amp; couldn't find...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137277</th>\n",
              "      <td>supposedly this is the newer model accortding ...</td>\n",
              "      <td>just the colour and our cats don't seem to not...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137278</th>\n",
              "      <td>what is the height of the back rest only?</td>\n",
              "      <td>24 inches.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>137279</th>\n",
              "      <td>anybody else get gritty sediment at bottom? iv...</td>\n",
              "      <td>yes! i had the same experience. i thought abou...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>137280 rows × 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question                                           response\n",
              "0       the seller replied that the knife was made in ...                                            england\n",
              "1       can the ringer be totally turned off? this is ...       yes it can be turned off and not ring at all\n",
              "2       will this phone work with consumer cellular' s...  i just switched to consumer cellular and all f...\n",
              "3       how quickly does this printer go through ink w...  i've never measured it, but you do get a good ...\n",
              "4       will this device allow me to surfer the intern...  you can but you need to attach a compatible 3g...\n",
              "...                                                   ...                                                ...\n",
              "137275  it says minimum weight 60lbs and maximum weigh...                      the manual says up to 50 lbs.\n",
              "137276  does this version have a limited number of use...  i was wondering the same thing & couldn't find...\n",
              "137277  supposedly this is the newer model accortding ...  just the colour and our cats don't seem to not...\n",
              "137278          what is the height of the back rest only?                                         24 inches.\n",
              "137279  anybody else get gritty sediment at bottom? iv...  yes! i had the same experience. i thought abou...\n",
              "\n",
              "[137280 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7lEMssqmwHi",
        "outputId": "d8e99b0d-2d1e-4c4e-b5f2-4e10f181eb7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>does this fit my 99 grand caravan 3.3 engine</td>\n",
              "      <td>yes, i used this kit in my 99 dodge grand cara...</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>does the noot battery work on the alcatel onet...</td>\n",
              "      <td>i dont know the answer to your specific questi...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the seat back height?  thank you!</td>\n",
              "      <td>15 inches above the seat</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>would a heating pad work in this or would it b...</td>\n",
              "      <td>hinot so sure a heating pad would work as the ...</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>are these glass or plastic?</td>\n",
              "      <td>they are bpa free plastic.</td>\n",
              "      <td>beauty</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>what voltage is this? stationed in europe and ...</td>\n",
              "      <td>it's dc 120 v.</td>\n",
              "      <td>baby</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>is it possible to set up play with single goal...</td>\n",
              "      <td>no. the corners are flat so you need 3 people ...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>will this work for a sierria 25831035</td>\n",
              "      <td>real good fit. almost to good to be true</td>\n",
              "      <td>automotive</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>will the ear plugs fit with it in the case?</td>\n",
              "      <td>yes apple's earphones should fit perfectly. ha...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>does this take the cr2032 battery?</td>\n",
              "      <td>yes this does use the cr2032 battery, i haven'...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  ...                     category\n",
              "0            does this fit my 99 grand caravan 3.3 engine  ...                   automotive\n",
              "1       does the noot battery work on the alcatel onet...  ...  cell phones and accessories\n",
              "2               what is the seat back height?  thank you!  ...          sports and outdoors\n",
              "3       would a heating pad work in this or would it b...  ...                 pet supplies\n",
              "4                             are these glass or plastic?  ...                       beauty\n",
              "...                                                   ...  ...                          ...\n",
              "249995  what voltage is this? stationed in europe and ...  ...                         baby\n",
              "249996  is it possible to set up play with single goal...  ...          sports and outdoors\n",
              "249997              will this work for a sierria 25831035  ...                   automotive\n",
              "249998        will the ear plugs fit with it in the case?  ...  cell phones and accessories\n",
              "249999                 does this take the cr2032 battery?  ...          sports and outdoors\n",
              "\n",
              "[250000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3BVzMvo9mwHu",
        "outputId": "26b694a0-187e-4ff9-8939-ef52b9e55dac",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "valid"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>what guage steel?  galvanized inside and out? ...</td>\n",
              "      <td>hi howard, i have no idea of the answers to yo...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>will it fit on a 5'2' teen age girl?</td>\n",
              "      <td>absolutely, my son is 5'10\" and it works wonde...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>does this kit also contain a piece to cover th...</td>\n",
              "      <td>yes. there are three side pieces that meet at ...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>does anyone know the width between the legs?</td>\n",
              "      <td>about 14 inches</td>\n",
              "      <td>office products</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>is it fast</td>\n",
              "      <td>not sure i can answer that- i bought it for my...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49995</th>\n",
              "      <td>why are these being sold without a front calip...</td>\n",
              "      <td>my only guess is because everyone uses a diffe...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49996</th>\n",
              "      <td>how long before you began to notice a differen...</td>\n",
              "      <td>after 30 days my dog was hardly shedding at al...</td>\n",
              "      <td>pet supplies</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49997</th>\n",
              "      <td>what are the entire ingredients?</td>\n",
              "      <td>purified water, vegetable glycerine, polydextr...</td>\n",
              "      <td>grocery and gourmet food</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49998</th>\n",
              "      <td>does anyone know is this offer for just 1 grip...</td>\n",
              "      <td>a pair.</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>49999</th>\n",
              "      <td>legsl knife size  nyc</td>\n",
              "      <td>mulan, im afraid i can not answer your questio...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>50000 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                question  ...                     category\n",
              "0      what guage steel?  galvanized inside and out? ...  ...          sports and outdoors\n",
              "1                   will it fit on a 5'2' teen age girl?  ...          sports and outdoors\n",
              "2      does this kit also contain a piece to cover th...  ...  cell phones and accessories\n",
              "3           does anyone know the width between the legs?  ...              office products\n",
              "4                                             is it fast  ...          sports and outdoors\n",
              "...                                                  ...  ...                          ...\n",
              "49995  why are these being sold without a front calip...  ...          sports and outdoors\n",
              "49996  how long before you began to notice a differen...  ...                 pet supplies\n",
              "49997                   what are the entire ingredients?  ...     grocery and gourmet food\n",
              "49998  does anyone know is this offer for just 1 grip...  ...          sports and outdoors\n",
              "49999                              legsl knife size  nyc  ...          sports and outdoors\n",
              "\n",
              "[50000 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZIiK5k5ymwH3"
      },
      "source": [
        "## Задача\n",
        "Классифицировать поле question в одну из категорий в поле category.  \n",
        "Это данные с сервиса Amazon QA, то есть такой сервис, на котором можно задать вопрос и получить ответ от других пользователей.\n",
        "\n",
        "Идея задачи такая: давайте поможем клиенту определить в какую категорию выложить его вопрос, чтобы быстрее получить максимально релевантный ответ."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIAnIDrwmwH4"
      },
      "source": [
        "### Перевод класса в индекс\n",
        "Мы сделаем некоторый маппер, который текст класса переводит в конкретный уникальный индекс. Нам это понадобиться, потому что наша \n",
        "модель работает не напрямую с классом, а с его индексом."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MYpScz5mwH6",
        "outputId": "d45b9a88-bb83-4966-c68d-6d56fdc541a3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# проверим, что в трейне и валидации одинаковые категории\n",
        "set(train.category.unique().tolist()) == set(valid.category.unique().tolist())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DicC4JIhmwIE"
      },
      "source": [
        "unique_categories = set(train.category.unique().tolist() + valid.category.unique().tolist())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DhX3-l1rmwIP"
      },
      "source": [
        "category2index = {category: index for index, category in enumerate(unique_categories)}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8sPH75E9mwIc",
        "outputId": "4a8b9a83-14f3-46a6-affc-f1bdf9bfacd6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "category2index"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'automotive': 2,\n",
              " 'baby': 7,\n",
              " 'beauty': 3,\n",
              " 'cell phones and accessories': 5,\n",
              " 'grocery and gourmet food': 4,\n",
              " 'office products': 1,\n",
              " 'pet supplies': 0,\n",
              " 'sports and outdoors': 6}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1CfVU0CimwIo"
      },
      "source": [
        "train['target'] = train.category.map(category2index)\n",
        "valid['target'] = valid.category.map(category2index)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1xVDWJpjmwIy",
        "outputId": "1b273725-133c-4680-9dc6-c2a37d9f3779",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        }
      },
      "source": [
        "train"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>question</th>\n",
              "      <th>response</th>\n",
              "      <th>category</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>does this fit my 99 grand caravan 3.3 engine</td>\n",
              "      <td>yes, i used this kit in my 99 dodge grand cara...</td>\n",
              "      <td>automotive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>does the noot battery work on the alcatel onet...</td>\n",
              "      <td>i dont know the answer to your specific questi...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>what is the seat back height?  thank you!</td>\n",
              "      <td>15 inches above the seat</td>\n",
              "      <td>sports and outdoors</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>would a heating pad work in this or would it b...</td>\n",
              "      <td>hinot so sure a heating pad would work as the ...</td>\n",
              "      <td>pet supplies</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>are these glass or plastic?</td>\n",
              "      <td>they are bpa free plastic.</td>\n",
              "      <td>beauty</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249995</th>\n",
              "      <td>what voltage is this? stationed in europe and ...</td>\n",
              "      <td>it's dc 120 v.</td>\n",
              "      <td>baby</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249996</th>\n",
              "      <td>is it possible to set up play with single goal...</td>\n",
              "      <td>no. the corners are flat so you need 3 people ...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249997</th>\n",
              "      <td>will this work for a sierria 25831035</td>\n",
              "      <td>real good fit. almost to good to be true</td>\n",
              "      <td>automotive</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249998</th>\n",
              "      <td>will the ear plugs fit with it in the case?</td>\n",
              "      <td>yes apple's earphones should fit perfectly. ha...</td>\n",
              "      <td>cell phones and accessories</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>249999</th>\n",
              "      <td>does this take the cr2032 battery?</td>\n",
              "      <td>yes this does use the cr2032 battery, i haven'...</td>\n",
              "      <td>sports and outdoors</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>250000 rows × 4 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 question  ... target\n",
              "0            does this fit my 99 grand caravan 3.3 engine  ...      2\n",
              "1       does the noot battery work on the alcatel onet...  ...      5\n",
              "2               what is the seat back height?  thank you!  ...      6\n",
              "3       would a heating pad work in this or would it b...  ...      0\n",
              "4                             are these glass or plastic?  ...      3\n",
              "...                                                   ...  ...    ...\n",
              "249995  what voltage is this? stationed in europe and ...  ...      7\n",
              "249996  is it possible to set up play with single goal...  ...      6\n",
              "249997              will this work for a sierria 25831035  ...      2\n",
              "249998        will the ear plugs fit with it in the case?  ...      5\n",
              "249999                 does this take the cr2032 battery?  ...      6\n",
              "\n",
              "[250000 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQpyjh3DmwI6"
      },
      "source": [
        "### Torch Dataset, DataLoader\n",
        "\n",
        "Очень важная абстракция для торча.\n",
        "Мы всегда будем ее использовать, чтобы работать с данными.\n",
        "\n",
        "Dataset - класс, от которого нужно наследоваться, чтобы написать свой обработчик данных. Внутри него нужно реализовать два метода, \n",
        "о которых будет чуть ниже. То есть в данном классе вы описывает как нужно преобразовать ваши данные в торчовый формат. Перевести тексты \n",
        "в индексы слов и тд.\n",
        "\n",
        "DataLoader - класс, который будет за вас семплировать данные батчами. Это итератор, поэтому формат работы с ним примерно такой:\n",
        "```python\n",
        "for batch in data_loader:\n",
        "    ...\n",
        "```\n",
        "То есть на каждой итерации отдается по одному батчу данных. Итерирование заканчивается, когда вы пройдете все батчи.\n",
        "\n",
        "Зачем нужны эти абстракции? Чтобы упростить и унифицировать работу с данными.\n",
        "Вообще вы можете реализовать что-то свое, но это упрощение данной задачи."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXACcy5OmwI_"
      },
      "source": [
        "from torch.utils.data import Dataset, DataLoader"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5H_DSJzvmwJL"
      },
      "source": [
        "# игрушечный датасет\n",
        "# 121535 примера, 4 фичи, 3 класса\n",
        "some_data_x = np.random.rand(121535, 4)\n",
        "some_data_y = np.random.randint(3, size=(121535,))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pPQz5lwAmwJU",
        "outputId": "1966f455-5415-4609-a4c4-ff12f782b2f6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# просто рандомные цифры\n",
        "some_data_x[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.60628265, 0.81855215, 0.04032249, 0.06818204],\n",
              "       [0.08811917, 0.61536487, 0.62103204, 0.19494779],\n",
              "       [0.35195296, 0.70944777, 0.62643847, 0.63631257],\n",
              "       [0.71273118, 0.91936826, 0.47594969, 0.71466292],\n",
              "       [0.37432169, 0.05685763, 0.53775563, 0.94264564],\n",
              "       [0.58276578, 0.31788819, 0.0428031 , 0.5156363 ],\n",
              "       [0.84910007, 0.94583194, 0.68813621, 0.12869174],\n",
              "       [0.5818313 , 0.60409125, 0.67614055, 0.72607324],\n",
              "       [0.15731996, 0.1343803 , 0.65760561, 0.06068719],\n",
              "       [0.16076733, 0.19466998, 0.44337541, 0.85148639]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cO506pvFmwJd",
        "outputId": "8742e8f7-46b4-4b69-dc53-a76ee71e66eb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# и классы\n",
        "some_data_y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 1, ..., 2, 2, 0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ERMQy7AWmwJn"
      },
      "source": [
        "### Пример надобности\n",
        "Для обучения модели вам нужно подавать в нее батчи данных. Как бы могли это реализовать, если бы у нас не было Dataset и DataLoader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Otp2vKj0mwJp"
      },
      "source": [
        "batch_size = 16\n",
        "\n",
        "for i_batch in range(math.ceil(some_data_x.shape[0] / batch_size)):\n",
        "    \n",
        "    x_batch = some_data_x[i_batch * batch_size:(i_batch + 1) * batch_size]\n",
        "    y_batch = some_data_y[i_batch * batch_size:(i_batch + 1) * batch_size]\n",
        "    \n",
        "    x_batch = torch.tensor(x_batch)\n",
        "    y_batch = torch.tensor(y_batch)\n",
        "    \n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BCtwvxBZmwJy",
        "outputId": "891cb72f-bc65-4f8d-9661-7d4124c0d562",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_batch"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6063, 0.8186, 0.0403, 0.0682],\n",
              "        [0.0881, 0.6154, 0.6210, 0.1949],\n",
              "        [0.3520, 0.7094, 0.6264, 0.6363],\n",
              "        [0.7127, 0.9194, 0.4759, 0.7147],\n",
              "        [0.3743, 0.0569, 0.5378, 0.9426],\n",
              "        [0.5828, 0.3179, 0.0428, 0.5156],\n",
              "        [0.8491, 0.9458, 0.6881, 0.1287],\n",
              "        [0.5818, 0.6041, 0.6761, 0.7261],\n",
              "        [0.1573, 0.1344, 0.6576, 0.0607],\n",
              "        [0.1608, 0.1947, 0.4434, 0.8515],\n",
              "        [0.5681, 0.2333, 0.1362, 0.7040],\n",
              "        [0.8181, 0.9387, 0.6319, 0.1505],\n",
              "        [0.8450, 0.9160, 0.9972, 0.4855],\n",
              "        [0.0020, 0.4866, 0.5789, 0.9379],\n",
              "        [0.5956, 0.4314, 0.4756, 0.2258],\n",
              "        [0.6579, 0.9327, 0.2660, 0.9355]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2xydSIrmwJ5",
        "outputId": "7e5e2054-3ddc-4478-b039-f76c3be40886",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_batch.shape, y_batch.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([16, 4]), torch.Size([16]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5VfZ6XRgmwKA"
      },
      "source": [
        "Это достаточно простой пример. Мы смогли справиться сами, но почти всегда обработка данных для подачи ее в модель делается сложнее. \n",
        "И некоторые вещи часто нужны более одного раза, например, если мы хотим каждую эпоху шафлить наши данные, чтобы получать разные батчи.\n",
        "Мы сможем это сделать, но для этого нам придется тащить с собой некоторый код из проекта в проект. К тому же совместная разработка или \n",
        "просто чтение чужого кода сильно упрощается, когда вы используете унифицированные форматы."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qywWBKphmwKC"
      },
      "source": [
        "### Перейдем к Dataset\n",
        "И обернем наши данные в этот обработчик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHdvtHmfmwKF"
      },
      "source": [
        "class ToyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data_x, data_y):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.data_x = data_x\n",
        "        self.data_y = data_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        # нужно обязательно определить эту функцию\n",
        "        # должна возвращать размер датасета\n",
        "        # нужен для DataLoader, чтобы семплировать батчи\n",
        "        \n",
        "        return len(self.data_x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # еще нужно определить этот метод\n",
        "        # то есть как мы будем доставать наши данные по индексу\n",
        "        \n",
        "        return self.data_x[idx], self.data_y[idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq-9ETa8mwKS"
      },
      "source": [
        "some_dataset = ToyDataset(some_data_x, some_data_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wMgG_0kkmwKb",
        "outputId": "1496aa5b-5a90-4949-e112-80447ced0d8e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "some_dataset[5], some_dataset[467]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((array([0.58276578, 0.31788819, 0.0428031 , 0.5156363 ]), 0),\n",
              " (array([0.66264582, 0.69637466, 0.0421853 , 0.77843354]), 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mBLF-l4omwKm"
      },
      "source": [
        "### Кажется, что смысла в этом нет, но это самый простой пример"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-xiNy7gmwKn"
      },
      "source": [
        "### DataLoader\n",
        "В него мы можем задать некоторые параметры, например, батч сайз и нужно ли шафлить каждый новый проход по данным эти самые данные, \n",
        "чтобы получать разные батчи, то есть по разному компоновать эти батчи"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VZvHJwY1mwKo"
      },
      "source": [
        "some_loader = DataLoader(some_dataset, batch_size=16, shuffle=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ywM_MeFjmwKv",
        "outputId": "c592e676-c887-4396-87ed-7b81512a08fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x, y in some_loader:\n",
        "    break\n",
        "    \n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.5668, 0.3685, 0.1726, 0.8020],\n",
              "        [0.9270, 0.1466, 0.1942, 0.5973],\n",
              "        [0.2405, 0.9415, 0.9782, 0.3359],\n",
              "        [0.4112, 0.9300, 0.8427, 0.4346],\n",
              "        [0.3597, 0.9494, 0.7578, 0.4446],\n",
              "        [0.9389, 0.3165, 0.8136, 0.4728],\n",
              "        [0.0327, 0.3777, 0.7385, 0.8090],\n",
              "        [0.0780, 0.4229, 0.0839, 0.9872],\n",
              "        [0.8435, 0.2222, 0.6696, 0.2440],\n",
              "        [0.2121, 0.1300, 0.9089, 0.8651],\n",
              "        [0.3056, 0.6988, 0.2095, 0.7659],\n",
              "        [0.5560, 0.5866, 0.0156, 0.9345],\n",
              "        [0.3324, 0.3058, 0.5894, 0.6722],\n",
              "        [0.3296, 0.1339, 0.0687, 0.8513],\n",
              "        [0.6019, 0.6263, 0.6734, 0.8634],\n",
              "        [0.1362, 0.4631, 0.0716, 0.5375]], dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u7ugsw7VmwK7",
        "outputId": "0f7a9a17-4bc1-416f-d092-21c1fa8a0505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([16, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwRXGXMImwLE",
        "outputId": "9e5cfc0f-c7f7-4af4-d023-6f5ee43e37d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for x, y in some_loader:\n",
        "    pass\n",
        "\n",
        "len(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s7Imyx8umwLN",
        "outputId": "178251ae-b6b7-4c67-b170-a079a41bae2b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# почему 15?\n",
        "# потому что количество наших данных нацело не делится на 16\n",
        "# и поэтому последний батч меньше 16-ти\n",
        "len(some_dataset) % 16"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v9R8ZpRymwLV"
      },
      "source": [
        "### Усложним обработчик"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ignw8wuXmwLX"
      },
      "source": [
        "class ToyDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, data_x, data_y):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.data_x = data_x\n",
        "        self.data_y = data_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        \n",
        "        # нужно обязательно определить эту функцию\n",
        "        # должна возвращать размер датасета\n",
        "        # нужен для DataLoader, чтобы семплировать батчи\n",
        "        \n",
        "        return len(self.data_x)\n",
        "    \n",
        "    @staticmethod\n",
        "    def pow_features(x, n=2):\n",
        "        \n",
        "        return x ** n\n",
        "    \n",
        "    @staticmethod\n",
        "    def log_features(x):\n",
        "        \n",
        "        return np.log(x)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        # еще нужно определить этот метод\n",
        "        # то есть как мы будем доставать наши данные по индексу\n",
        "        \n",
        "        x = self.data_x[idx]\n",
        "        \n",
        "        # внутри датасета мы можем делать все что угодно с нашими данными\n",
        "        # например выше определим функции, которые добавляют степенные фичи\n",
        "        x_p_2 = self.pow_features(x, n=2)\n",
        "        x_p_3 = self.pow_features(x, n=3)\n",
        "        # и еще возьмем логарифмические фичи\n",
        "        x_log = self.log_features(x)\n",
        "        \n",
        "        # сконкатенируем наши фичи\n",
        "        x = np.concatenate([x, x_p_2, x_p_3, x_log])\n",
        "        \n",
        "        y = self.data_y[idx]\n",
        "        \n",
        "        return x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ynRZTBEDmwLg"
      },
      "source": [
        "toy_dataset = ToyDataset(some_data_x, some_data_y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wdWS1NNfmwLo"
      },
      "source": [
        "toy_loader = DataLoader(dataset=toy_dataset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nECo_cnNmwLz"
      },
      "source": [
        "for x, y in toy_loader:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECM6zR-3mwL9",
        "outputId": "d0e0366c-5975-4f64-a788-262bdc1fd275",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 16])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "11cPrRC-mwMF",
        "outputId": "c997bca6-74f2-422f-cb1b-ee47da75e797",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# заметим, что мы сразу получаем торчовый формат данных, который получился из автоматического преобразования из numpy\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[ 0.6063,  0.8186,  0.0403,  ..., -0.2002, -3.2108, -2.6856],\n",
              "        [ 0.0881,  0.6154,  0.6210,  ..., -0.4855, -0.4764, -1.6350],\n",
              "        [ 0.3520,  0.7094,  0.6264,  ..., -0.3433, -0.4677, -0.4521],\n",
              "        ...,\n",
              "        [ 0.7195,  0.6653,  0.8227,  ..., -0.4075, -0.1952, -0.0260],\n",
              "        [ 0.3877,  0.0949,  0.0380,  ..., -2.3554, -3.2692, -0.3970],\n",
              "        [ 0.1154,  0.5366,  0.0714,  ..., -0.6224, -2.6388, -1.1596]],\n",
              "       dtype=torch.float64)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A7RPNtDmwMO",
        "outputId": "76db0b67-0f92-4c7a-87e4-67fb9e9601b4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0, 0, 1, 2, 1, 0, 1, 0, 0, 2, 1, 1, 1, 2, 0, 1, 1, 1, 2, 1, 2, 1, 2, 1,\n",
              "        1, 1, 0, 0, 0, 2, 2, 2, 1, 1, 2, 0, 1, 1, 0, 2, 1, 0, 2, 2, 1, 2, 1, 0,\n",
              "        1, 0, 2, 2, 1, 2, 2, 1, 2, 2, 1, 0, 1, 0, 2, 2, 2, 2, 1, 0, 2, 2, 2, 0,\n",
              "        2, 0, 0, 1, 1, 0, 2, 0, 0, 0, 2, 0, 2, 0, 0, 2, 2, 0, 1, 1, 0, 1, 1, 2,\n",
              "        0, 2, 0, 2, 0, 2, 0, 2, 1, 0, 0, 1, 2, 2, 0, 1, 1, 1, 0, 1, 0, 1, 0, 2,\n",
              "        0, 1, 0, 1, 0, 2, 1, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQ4OzH3mmwMY",
        "outputId": "f71b632d-7d47-4981-8126-e42cc6105b14",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# сделаем небольшую модель и посчитаем лосс\n",
        "\n",
        "model = torch.nn.Sequential(torch.nn.Linear(16, 8),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(8, 4),\n",
        "                            torch.nn.ReLU(),\n",
        "                            torch.nn.Linear(4, 3))\n",
        "\n",
        "criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "with torch.no_grad():\n",
        "\n",
        "    prediction = model(x.float())\n",
        "\n",
        "    loss = criterion(prediction, y)\n",
        "    \n",
        "loss.item()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1.1356678009033203"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kkDBO1cfmwMp"
      },
      "source": [
        "### Сделаем датасет для наших текстовых данных\n",
        "Будем отдавать строку и таргет по индексу"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b4lOJj4FmwMr"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]\n",
        "        target = self.targets[index]\n",
        "        \n",
        "        return text, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yhkuK2x1mwMy"
      },
      "source": [
        "# подготовим данные\n",
        "train_x = list(train.question)\n",
        "train_y = list(train.target)\n",
        "\n",
        "valid_x = list(valid.question)\n",
        "valid_y = list(valid.target)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE07XIwkmwND"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=list(train.question), targets=list(train.target))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iw4MJ7W8mwNL"
      },
      "source": [
        "# семплируем данные\n",
        "text, target = train_dataset[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsgIoI4NmwNW",
        "outputId": "84968b0f-2d76-4701-f1ee-0ccea45e7540",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "text"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'does this fit my 99 grand caravan 3.3 engine'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lkSczglhmwNf",
        "outputId": "a61acee2-f6b8-4861-d7a2-0e2f25bd56d2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "target"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DusOSVpOmwNn"
      },
      "source": [
        "### Смысл обработчика\n",
        "Состоит в том, что нам нужно преобразовать наши данные в формат, который мы уже сможем передать в модель.\n",
        "Сейчас у нас строки, а торч ничего не знает про строки, ему нужны тензоры."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nBgeGoermwNo"
      },
      "source": [
        "### Загружаем эмбеддинги\n",
        "Чтобы работать с текстовыми данными мы можем разбить наши строки на слова, а слова перевести в вектора. Откуда нам взять эти вектора?\n",
        "Мы говорили про такой метод как word2vec и в начале этой тетрадки загружали файл с этими самыми векторами."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "umc0ZdammwNq"
      },
      "source": [
        "import zipfile\n",
        "import numpy as np\n",
        "\n",
        "from tqdm import tqdm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qbv94NMzmwNz"
      },
      "source": [
        "def load_embeddings(zip_path, filename, pad_token='PAD', max_words=100_000, verbose=True):\n",
        "    \n",
        "    vocab = dict()\n",
        "    embeddings = list()\n",
        "\n",
        "    with zipfile.ZipFile(zip_path) as zipped_file:\n",
        "        with zipped_file.open(filename) as file_object:\n",
        "\n",
        "            vocab_size, embedding_dim = file_object.readline().decode('utf-8').strip().split()\n",
        "\n",
        "            vocab_size = int(vocab_size)\n",
        "            embedding_dim = int(embedding_dim)\n",
        "            \n",
        "            # в файле 1 000 000 слов с векторами, давайте ограничим для простоты этот словарь\n",
        "            max_words = vocab_size if max_words <= 0 else max_words\n",
        "            \n",
        "            # добавим пад токен и эмбеддинг в нашу матрицу эмбеддингов и словарь\n",
        "            vocab[pad_token] = len(vocab)\n",
        "            embeddings.append(np.zeros(embedding_dim))\n",
        "\n",
        "            progress_bar = tqdm(total=max_words, disable=not verbose)\n",
        "\n",
        "            for line in file_object:\n",
        "                parts = line.decode('utf-8').strip().split()\n",
        "\n",
        "                token = ' '.join(parts[:-embedding_dim]).lower()\n",
        "                \n",
        "                if token in vocab:\n",
        "                    continue\n",
        "                \n",
        "                word_vector = np.array(list(map(float, parts[-embedding_dim:])))\n",
        "\n",
        "                vocab[token] = len(vocab)\n",
        "                embeddings.append(word_vector)\n",
        "\n",
        "                progress_bar.update()\n",
        "                \n",
        "                if len(vocab) == max_words:\n",
        "                    break\n",
        "\n",
        "            progress_bar.close()\n",
        "\n",
        "    embeddings = np.stack(embeddings)\n",
        "    \n",
        "    return vocab, embeddings"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "ggeKh1GvmwN9",
        "outputId": "871b2b86-2758-4ffb-a225-500cef69a197",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "vocab, embeddings = load_embeddings('./wiki-news-300d-1M.vec.zip', 'wiki-news-300d-1M.vec', max_words=100_000)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|█████████▉| 99999/100000 [00:12<00:00, 7873.71it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u2A4szMHmwOG"
      },
      "source": [
        "### Посмотрим на ближайших соседей слова по эмбеддингам"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1RKRQyWmwOH"
      },
      "source": [
        "index2token = {index: token for token, index in vocab.items()}"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DP7IP1RvmwOY"
      },
      "source": [
        "emb_norms = np.linalg.norm(embeddings, axis=1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FZ9XwMj_mwOk"
      },
      "source": [
        "def get_k_nearest_neighbors(word, embeddings, emb_norms, vocab, index2token, k=5):\n",
        "    \n",
        "    if word not in vocab:\n",
        "        print('Not in vocab')\n",
        "        return\n",
        "    \n",
        "    word_index = vocab[word]\n",
        "\n",
        "    word_vector = embeddings[word_index]\n",
        "    word_vector = np.expand_dims(word_vector, 0)\n",
        "\n",
        "    scores = (word_vector @ embeddings.T)[0]\n",
        "    \n",
        "    # переводим в косинусы, поделив на нормы векторов\n",
        "    # эпсилон 1e-6 для того, чтобы не делить на 0\n",
        "    scores = scores / (emb_norms + 1e-6) / emb_norms[word_index]\n",
        "    \n",
        "    # 1:k+1 потому что первый вариант это само слово\n",
        "    for idx in scores.argsort()[::-1][1:k+1]:\n",
        "        print(f'Слово {index2token[idx]} близко на {scores[idx]:.2f} к слову {word}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V1DGLYDgmwOu",
        "outputId": "2cae1d43-823e-4016-8fb8-21ecf23f3fa6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_k_nearest_neighbors('anna', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово maria близко на 0.73 к слову anna\n",
            "Слово emma близко на 0.66 к слову anna\n",
            "Слово kristina близко на 0.65 к слову anna\n",
            "Слово laura близко на 0.65 к слову anna\n",
            "Слово emily близко на 0.65 к слову anna\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ExhJDpg_mwO3",
        "outputId": "ed55d022-f577-4e3a-eb09-cf3eee425a89",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_k_nearest_neighbors('mom', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово dad близко на 0.85 к слову mom\n",
            "Слово mum близко на 0.78 к слову mom\n",
            "Слово mother близко на 0.76 к слову mom\n",
            "Слово moms близко на 0.75 к слову mom\n",
            "Слово kid близко на 0.68 к слову mom\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wHfEe1-DmwO-",
        "outputId": "79251d4f-55e5-4f54-8cec-630ed34b8c3a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_k_nearest_neighbors('have', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово has близко на 0.78 к слову have\n",
            "Слово been близко на 0.75 к слову have\n",
            "Слово 've близко на 0.75 к слову have\n",
            "Слово had близко на 0.74 к слову have\n",
            "Слово ahve близко на 0.74 к слову have\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0emkbwsXmwPQ",
        "outputId": "5149a108-edb2-4af7-e0bf-f4ffb4f81505",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_k_nearest_neighbors('money', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово cash близко на 0.72 к слову money\n",
            "Слово funds близко на 0.72 к слову money\n",
            "Слово monies близко на 0.72 к слову money\n",
            "Слово moneys близко на 0.67 к слову money\n",
            "Слово dosh близко на 0.63 к слову money\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hyx9Gl2RmwPX",
        "outputId": "5b453516-e495-40ea-caeb-2bd0a936eae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "get_k_nearest_neighbors('music', embeddings, emb_norms, vocab, index2token)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Слово musical близко на 0.71 к слову music\n",
            "Слово songs близко на 0.69 к слову music\n",
            "Слово tunes близко на 0.69 к слову music\n",
            "Слово musics близко на 0.68 к слову music\n",
            "Слово composer близко на 0.68 к слову music\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1x26_qumwPg"
      },
      "source": [
        "### Выбор метода токенизации\n",
        "У нас сейчас есть маппинг, что некоторому слову соответствует некоторый эмбеддинг этого слова.\n",
        "Токенизация - процесс разбиения текста на токены, то есть части этого текста.   \n",
        "Чем \"слово\" отличается от \"токена\": токен это более обобщенное понятие, то есть, например, цифра это токен"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68Nk0fCumwPi"
      },
      "source": [
        "# про различия подробнее можно найти, например, здесь\n",
        "# https://stackoverflow.com/questions/50240029/nltk-wordpunct-tokenize-vs-word-tokenize\n",
        "from nltk.tokenize import word_tokenize, wordpunct_tokenize"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FDMfHEltmwPq",
        "outputId": "84a8fd17-3163-4fbf-891b-75ea27bea3ba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация по пробелу\n",
        "    tokens = sample.split()\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:01<00:00, 154712.11it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 512414 слов из 3602778 слов в датасете\n",
            "Что составляет 14.22% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 119127\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VkEc8tqsmwPw",
        "outputId": "3500c645-238b-4ec0-c6b6-722b3dad236c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация\n",
        "    tokens = wordpunct_tokenize(sample)\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:02<00:00, 95496.56it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 111444 слов из 4198407 слов в датасете\n",
            "Что составляет 2.65% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 36080\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CRZs41zgmwP4",
        "outputId": "fd20a5f1-24ac-4f1e-925f-50a601fd522a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')\n",
        "\n",
        "total_n_words = 0\n",
        "unknown_words = list()\n",
        "\n",
        "for sample in tqdm(train_x):\n",
        "    # токенизация\n",
        "    tokens = word_tokenize(sample)\n",
        "    \n",
        "    for tok in tokens:\n",
        "        # проверяем есть ли токен в нашем словаре\n",
        "        if tok not in vocab:\n",
        "            unknown_words.append(tok)\n",
        "            \n",
        "        total_n_words += 1\n",
        "        \n",
        "print(f'Мы не знаем {len(unknown_words)} слов из {total_n_words} слов в датасете')\n",
        "print(f'Что составляет {len(unknown_words) * 100 / total_n_words:.2f}% датасета')\n",
        "print()\n",
        "print(f'Уникальных неизвестных слов: {len(set(unknown_words))}')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:46<00:00, 5386.51it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Мы не знаем 151761 слов из 4100141 слов в датасете\n",
            "Что составляет 3.70% датасета\n",
            "\n",
            "Уникальных неизвестных слов: 53830\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Z2E1Ct9wmwP-"
      },
      "source": [
        "### Результаты\n",
        "- Скорость у word_tokenize сильно ниже, чем у wordpunct_tokenize\n",
        "- Используя word_tokenize, мы теряем примерно 1% информации из датасета по сравнению с wordpunct_tokenize\n",
        "\n",
        "### Выбор очевиден в сторону wordpunct_tokenize"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FGDViu55mwQA"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        \n",
        "        # переведем наши индексы токенов в торчовый тензор\n",
        "        # таргет переведется самостоятельно\n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HcS-teH4mwQI"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s3NxkEocmwQO"
      },
      "source": [
        "x, y = train_dataset[5]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clziyBYImwQW",
        "outputId": "ba88c679-7d53-42ec-d06e-9e2ee5ffdc59",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([ 129,  291,   20,  197, 5748,  252,  149,    3,   55,   20,   98,   15,\n",
              "           2, 5748,  214,   37])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfthifOKmwQb",
        "outputId": "0ad16697-9866-4ad4-911e-805b4dc4978e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "y"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "5"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 66
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i5UeEkzgmwQg",
        "outputId": "92ccd77c-5a5a-45bd-b405-c1d075ca54d5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# мы можем восстановить текст обратно по индексам слов\n",
        "[index2token[idx.item()] for idx in x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['even',\n",
              " 'though',\n",
              " 'it',\n",
              " 'says',\n",
              " 'iphone',\n",
              " '5',\n",
              " 'case',\n",
              " '.',\n",
              " 'will',\n",
              " 'it',\n",
              " 'work',\n",
              " 'for',\n",
              " 'the',\n",
              " 'iphone',\n",
              " '4',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DXOgBrp_mwQn"
      },
      "source": [
        "### У нас остается проблема разных длин текстов\n",
        "Чтобы поместить батч текстов в один тензор нам нужны одинаковые длины"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpOqkvW3mwQo"
      },
      "source": [
        "## это не отработает, можете раскомментировать и проверить\n",
        "\n",
        "# x = [\n",
        "#     [1, 2, 3],\n",
        "#     [1, 2, 3, 4, 5],\n",
        "#     [1, 2, 3, 4, 5, 6, 7]\n",
        "# ]\n",
        "\n",
        "# torch.tensor(x), torch.tensor(x).shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ov2z96hQmwQ2",
        "outputId": "f674d350-7284-4356-d120-27a2d3e8feee",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# это сработает\n",
        "\n",
        "x = [\n",
        "    [1, 2, 3, 0, 0, 0, 0],\n",
        "    [1, 2, 3, 4, 5, 0, 0],\n",
        "    [1, 2, 3, 4, 5, 6, 7]\n",
        "]\n",
        "\n",
        "torch.tensor(x), torch.tensor(x).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor([[1, 2, 3, 0, 0, 0, 0],\n",
              "         [1, 2, 3, 4, 5, 0, 0],\n",
              "         [1, 2, 3, 4, 5, 6, 7]]), torch.Size([3, 7]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DOWRDQ8tmwQ9"
      },
      "source": [
        "### Длина текста\n",
        "Нам нужно понять до какой длины нам падить каждый наш пример. \n",
        "Мы можем найти в наших данных максимальную длину примера в токенах и падить до этой длины, но у этого подхода есть минус:\n",
        "у нас могут быть несколько текстов с аномально большой длиной, то есть некоторые выбросы.  \n",
        "\n",
        "В таком случае нам легче ограничить длину этих текстов до определенной статистики по нашему датасет, то есть, например, 95% наших текстов\n",
        "длиной в 25 слов и нам этого достаточно. То есть мы ограничимся этой длиной, потому что почти весь датасет влезает в эту длину\n",
        "и нам не нужно будет падить до большой длины.\n",
        "\n",
        "Паддинг нужен нам для того, чтобы мы могли поместить разные примеры в один батч, но мы не хотим учитывать эти токены, то есть \n",
        "по сути это будут холостые прогоны и за счет этого компромисса, что бОльшая часть датасета не больше n слов мы можем оптимизировать \n",
        "наше обучение.\n",
        "\n",
        "<br>\n",
        "\n",
        "\n",
        "> Почему бы нам просто не выкинуть эти длинные тексты?\n",
        "\n",
        "Дело в том, что мы хотим прийти к некоторому компромиссу между максимальной длиной и потерей информации. Если мы возьмем 95-й перцинтиль наших длин (то есть 95% наших текстов не больше n), то, выкинув остальные 5%, мы потеряем существенную часть примеров.\n",
        "С другой стороны может показаться неправильным ограничение длины и это действительно может сломать смысл примеры, но зачастую этим \n",
        "принебрегают."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WRLb6YzPmwQ-",
        "outputId": "ab1a3b68-abbd-40bd-cea0-da6eccdc8269",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "train_lengths = [len(wordpunct_tokenize(sample)) for sample in tqdm(train_x)]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100%|██████████| 250000/250000 [00:01<00:00, 189769.86it/s]\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRd_EMC-mwRG",
        "outputId": "7760e18e-27c1-4c32-be23-f3e23a2c9274",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 336
        }
      },
      "source": [
        "sns.distplot(train_lengths)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/seaborn/distributions.py:2551: FutureWarning: `distplot` is a deprecated function and will be removed in a future version. Please adapt your code to use either `displot` (a figure-level function with similar flexibility) or `histplot` (an axes-level function for histograms).\n",
            "  warnings.warn(msg, FutureWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7ff6cde92898>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tScNTdhkmwRO",
        "outputId": "4467e228-6163-464a-b727-8d09597fb272",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# видим большие выбросы в данных\n",
        "# 97% наших текстов не больше вот стольки токенов\n",
        "np.percentile(train_lengths, 95)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "34.0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OzVn2M-umwRY"
      },
      "source": [
        "class TextClassificationDataset(Dataset):\n",
        "    \n",
        "    def __init__(self, texts, targets, vocab, pad_index=0, max_length=32):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.texts = texts\n",
        "        self.targets = targets\n",
        "        self.vocab = vocab\n",
        "        \n",
        "        self.pad_index = pad_index\n",
        "        self.max_length = max_length\n",
        "        \n",
        "    def __len__(self):\n",
        "        return len(self.texts)\n",
        "    \n",
        "    def tokenization(self, text):\n",
        "        \n",
        "        tokens = wordpunct_tokenize(text)\n",
        "        \n",
        "        token_indices = [self.vocab[tok] for tok in tokens if tok in self.vocab]\n",
        "        \n",
        "        return token_indices\n",
        "    \n",
        "    def padding(self, tokenized_text):\n",
        "        \n",
        "        tokenized_text = tokenized_text[:self.max_length]\n",
        "        \n",
        "        tokenized_text += [self.pad_index] * (self.max_length - len(tokenized_text))\n",
        "        \n",
        "        return tokenized_text\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        \n",
        "        text = self.texts[index]        \n",
        "        target = self.targets[index]\n",
        "        \n",
        "        tokenized_text = self.tokenization(text)\n",
        "        tokenized_text = self.padding(tokenized_text)\n",
        "        \n",
        "        tokenized_text = torch.tensor(tokenized_text)\n",
        "        \n",
        "        return tokenized_text, target"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kq11AJqgmwRg"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7Uv6F_F9mwRo",
        "outputId": "46c3dac2-570a-42f5-88c9-41d98bc5ae4b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x, y = train_dataset[0]\n",
        "x"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([  218,    29,  1663,    92,  5101,  3294, 20749,   161,     3,   161,\n",
              "         1861,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bI4OO3aGmwRu",
        "outputId": "317d56c0-238e-45b7-f23c-31c07b542db6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "[index2token[idx.item()] for idx in x]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['does',\n",
              " 'this',\n",
              " 'fit',\n",
              " 'my',\n",
              " '99',\n",
              " 'grand',\n",
              " 'caravan',\n",
              " '3',\n",
              " '.',\n",
              " '3',\n",
              " 'engine',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD',\n",
              " 'PAD']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EXXrt51ymwR1"
      },
      "source": [
        "train_dataset = TextClassificationDataset(texts=train_x, targets=train_y, vocab=vocab)\n",
        "valid_dataset = TextClassificationDataset(texts=valid_x, targets=valid_y, vocab=vocab)\n",
        "\n",
        "train_loader = DataLoader(train_dataset, batch_size=128)\n",
        "valid_loader = DataLoader(valid_dataset, batch_size=128)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iU9b64Y2mwR8"
      },
      "source": [
        "for x, y in train_loader:\n",
        "    break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mJsKAFfUmwSC",
        "outputId": "f15d407c-7222-42ff-963e-61b0910f2733",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x.shape, y.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([128, 32]), torch.Size([128]))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FGZS8dhYmwSI"
      },
      "source": [
        "### Как мы можем задавать слои"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "az1oWNcomwSL"
      },
      "source": [
        "from torch import nn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eOIWrRV8mwSX"
      },
      "source": [
        "embedding_layer = nn.Embedding(num_embeddings=len(vocab), \n",
        "                               embedding_dim=embeddings.shape[-1],\n",
        "                               padding_idx=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU6lvUBYmwSc"
      },
      "source": [
        "x_embed = embedding_layer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aFhmcEaTmwSi",
        "outputId": "a3093283-79b6-42f5-cc91-8ce67b1e3d55",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[-3.7906, -1.5192,  0.0497,  ..., -1.2339,  0.6187,  1.5402],\n",
              "         [ 1.3650,  1.6287,  0.0192,  ...,  1.0747,  1.3890,  1.0202],\n",
              "         [-0.0459,  0.1610,  0.7346,  ..., -1.2025,  0.1559,  1.2280],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[-3.7906, -1.5192,  0.0497,  ..., -1.2339,  0.6187,  1.5402],\n",
              "         [-0.1489,  1.3007,  0.0977,  ...,  0.2390, -0.5938, -1.2195],\n",
              "         [-0.6607, -1.7661,  1.8397,  ..., -0.6314,  0.4997,  1.3668],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[ 1.0658, -0.9167,  0.4288,  ..., -0.5357,  0.6898, -0.8597],\n",
              "         [ 0.8172,  0.6538,  0.1417,  ...,  0.7553,  0.3723, -0.8889],\n",
              "         [-0.1489,  1.3007,  0.0977,  ...,  0.2390, -0.5938, -1.2195],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        ...,\n",
              "\n",
              "        [[-3.7906, -1.5192,  0.0497,  ..., -1.2339,  0.6187,  1.5402],\n",
              "         [-0.8822, -1.5257,  0.2453,  ...,  0.2288,  0.6341, -1.7908],\n",
              "         [-0.0459,  0.1610,  0.7346,  ..., -1.2025,  0.1559,  1.2280],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]],\n",
              "\n",
              "        [[-3.7906, -1.5192,  0.0497,  ..., -1.2339,  0.6187,  1.5402],\n",
              "         [ 0.0091,  0.0987,  0.5392,  ..., -1.0970, -1.0840,  1.9063],\n",
              "         [-0.3537, -0.3154, -0.4329,  ..., -0.8934, -0.9594, -2.3114],\n",
              "         ...,\n",
              "         [ 1.4582, -0.7430, -1.2258,  ..., -0.8890,  1.0577, -0.5078],\n",
              "         [-0.2907,  1.8909,  0.4097,  ...,  0.7966,  1.8451, -0.0589],\n",
              "         [ 0.6689,  0.9761, -0.5549,  ..., -0.1921, -0.0442, -0.7978]],\n",
              "\n",
              "        [[ 0.6524,  0.4884,  0.9545,  ..., -1.1892,  0.6366,  2.0434],\n",
              "         [-0.1489,  1.3007,  0.0977,  ...,  0.2390, -0.5938, -1.2195],\n",
              "         [-0.0839, -0.0987,  2.1617,  ..., -0.4659, -0.1234,  1.8476],\n",
              "         ...,\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n",
              "         [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]]],\n",
              "       grad_fn=<EmbeddingBackward>)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SsiFyyNnmwSo",
        "outputId": "ca619967-df85-4b08-d6b9-4198ac937cd7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "x_embed.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 300])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dRcyJ9hEmwSw"
      },
      "source": [
        "### Но мы ведь прочитали нашу матрицу эмбеддингов\n",
        "Таким образом она инициализируется предобученными весами.  \n",
        "При такой инициализации по умолчанию она замораживается, внутри ```.from_pretrained(embeddings, padding_idx=0)``` есть флаг ```freeze```, который отвечает за необходимость заморозки весов. То есть эти веса в процессе обучения не будут обновляться."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-sZguS0amwSy"
      },
      "source": [
        "embeddings = torch.tensor(embeddings).float()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9wxstMqmwS3"
      },
      "source": [
        "embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UhBjsss2mwS_"
      },
      "source": [
        "x_embed = embedding_layer(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zWtZEG4RmwTF"
      },
      "source": [
        "### Немного LSTM\n",
        "Ниже будет про ```batch_first=True```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WFAor2_NmwTG"
      },
      "source": [
        "lstm = nn.LSTM(input_size=300, hidden_size=128, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WMMNlB1DmwTM"
      },
      "source": [
        "x_lstm, _ = lstm(x_embed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q7XGmnUxmwTU",
        "outputId": "46210f8a-5f4f-422f-e6df-effe16d5daa9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# 256 потому что это конкатенация лстмки, которая прочитала текст слева направо\n",
        "# и лстмки, которая прочитала текст справа налево\n",
        "x_lstm.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 32, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 89
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ou7cPfgemwTb",
        "outputId": "7bb42ed6-c375-4848-fa88-8abbe0c7c737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "# избавились от временной размерности\n",
        "x_lstm.mean(dim=1).shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([128, 256])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_W753-EMmwTg"
      },
      "source": [
        "### Сделаем свою сеть\n",
        "В первой домашке в конце есть более подробная информация почему мы используем классы."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFl-JIVfmwTh"
      },
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes):\n",
        "        super().__init__()\n",
        "        \n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n",
        "        \n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=embeddings.shape[-1])\n",
        "        \n",
        "        self.linear_1 = nn.Linear(in_features=embeddings.shape[-1], out_features=linear_1_size)\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        # переводим индексы слов в эмбеддинги этих слов\n",
        "        # (batch_size, sequence_length) -> (batch_size, sequence_length, embedding_dim)\n",
        "        x = self.embedding_layer(x)\n",
        "        \n",
        "        # агрегируем наши эмбеддинги по размерности время\n",
        "        # (batch_size, sequence_length, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        x = x.sum(dim=1)\n",
        "        \n",
        "        # делаем нормирование\n",
        "        # (batch_size, embedding_dim) -> (batch_size, embedding_dim)\n",
        "        x = self.batch_norm(x)\n",
        "        \n",
        "        # прогоняем через первый линейный слой\n",
        "        # (batch_size, embedding_dim) -> (batch_size, linear_1_size)\n",
        "        x = self.linear_1(x)\n",
        "        \n",
        "        # применяем нелинейность\n",
        "        # (batch_size, linear_1_size) -> (batch_size, linear_1_size)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        # прогоняем через второй линейный слой\n",
        "        # (batch_size, linear_1_size) -> (batch_size, linear_2_size)\n",
        "        x = self.linear_2(x)\n",
        "        \n",
        "        # применяем нелинейность\n",
        "        # (batch_size, linear_2_size) -> (batch_size, linear_2_size)\n",
        "        x = torch.relu(x)\n",
        "        \n",
        "        # переводим с помощью линейного преобразования в количество классов\n",
        "        # (batch_size, linear_2_size) -> (batch_size, n_classes)\n",
        "        x = self.linear_3(x)\n",
        "        \n",
        "        ## по идеи здесь должен был быть софтмакс\n",
        "        ## но мы будем использовать лосс nn.CrossEntropyLoss()\n",
        "        ## в его документации написано\n",
        "        ## This criterion combines :func:`nn.LogSoftmax` and :func:`nn.NLLLoss` in one single class.\n",
        "        ## это некоторая оптимизация, которая включает в себя сразу и софтмакс и сам negative log likelihood лосс\n",
        "        ## так как у нас в лоссе есть софтмакс, то мы не будем применять его в сетке\n",
        "        ## на этапе предсказания (а не обучения) мы будем отдельно делать софтмакс для получения распределения классов\n",
        "        ## \n",
        "        ## (batch_size, n_classes) -> (batch_size, n_classes)\n",
        "        # x = torch.softmax(x, dim=-1)\n",
        "        \n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Xuo1BYevmwTl"
      },
      "source": [
        "model = DeepAverageNetwork(embeddings=embeddings,\n",
        "                           linear_1_size=256, \n",
        "                           linear_2_size=128, \n",
        "                           n_classes=len(category2index))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vTH8HEiLmwTq"
      },
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# задайте оптимизатор\n",
        "optimizer = torch.optim.Adam(lr=0.001, params=model.parameters())\n",
        "#изменили learning rate"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tcS-44xXxsJA"
      },
      "source": [
        "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=2, gamma=0.1, last_epoch=-1)\n",
        "#Создаём шедуллер, который уменьшает скорость обучения каждой группы параметров на гамму каждые step_size эпохи"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T44SyjAMmwT2"
      },
      "source": [
        "### Напишите цикл обучения\n",
        "Что он должен в себя включать:\n",
        "1. Получение предсказаний модели\n",
        "1. Расчет функции потерь\n",
        "1. Расчет градиентов\n",
        "1. Шаг градиентного спуска\n",
        "1. Обнуление градиентов\n",
        "1. Записывание значения лосса"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0VYqV_5GmwT3",
        "outputId": "c3603b4c-4379-47ad-bea6-1186cd0845ed",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses = list()\n",
        "\n",
        "# в обучении моделей у нас есть такая ситуация, что некоторые слои ведут себя по разному на этапе тренировки и предсказания\n",
        "# например, батч норм (а так же все остальные нормировки) и дропаут\n",
        "# это переводит модель в режим тренировки\n",
        "model.train()\n",
        "for x, y in train_loader:\n",
        "  prediction = model.forward(x)\n",
        "  loss = criterion(prediction, y)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  optimizer.zero_grad()\n",
        "  losses.append(loss)\n",
        "print(f\"Train loss: {loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Train loss: 0.44254109263420105\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AFb7SVOZidA2",
        "outputId": "f63d67d3-5cc6-4a6e-e2a5-1a1c94500af6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(0.7959, grad_fn=<NllLossBackward>), tensor(1.0093, grad_fn=<NllLossBackward>), tensor(1.0415, grad_fn=<NllLossBackward>), tensor(0.9629, grad_fn=<NllLossBackward>), tensor(0.8426, grad_fn=<NllLossBackward>), tensor(0.9622, grad_fn=<NllLossBackward>), tensor(1.0099, grad_fn=<NllLossBackward>), tensor(1.0994, grad_fn=<NllLossBackward>), tensor(0.9274, grad_fn=<NllLossBackward>), tensor(0.8886, grad_fn=<NllLossBackward>), tensor(0.8682, grad_fn=<NllLossBackward>), tensor(1.0486, grad_fn=<NllLossBackward>), tensor(1.0450, grad_fn=<NllLossBackward>), tensor(0.9308, grad_fn=<NllLossBackward>), tensor(1.0532, grad_fn=<NllLossBackward>), tensor(0.8844, grad_fn=<NllLossBackward>), tensor(1.0519, grad_fn=<NllLossBackward>), tensor(1.0359, grad_fn=<NllLossBackward>), tensor(0.9406, grad_fn=<NllLossBackward>), tensor(1.0331, grad_fn=<NllLossBackward>), tensor(0.9551, grad_fn=<NllLossBackward>), tensor(0.9681, grad_fn=<NllLossBackward>), tensor(0.9040, grad_fn=<NllLossBackward>), tensor(0.8653, grad_fn=<NllLossBackward>), tensor(1.0058, grad_fn=<NllLossBackward>), tensor(0.9056, grad_fn=<NllLossBackward>), tensor(0.8656, grad_fn=<NllLossBackward>), tensor(0.9550, grad_fn=<NllLossBackward>), tensor(0.8865, grad_fn=<NllLossBackward>), tensor(0.9464, grad_fn=<NllLossBackward>), tensor(0.9724, grad_fn=<NllLossBackward>), tensor(0.9672, grad_fn=<NllLossBackward>), tensor(0.8248, grad_fn=<NllLossBackward>), tensor(0.8827, grad_fn=<NllLossBackward>), tensor(0.9421, grad_fn=<NllLossBackward>), tensor(1.0034, grad_fn=<NllLossBackward>), tensor(0.8636, grad_fn=<NllLossBackward>), tensor(0.8241, grad_fn=<NllLossBackward>), tensor(0.8967, grad_fn=<NllLossBackward>), tensor(0.9216, grad_fn=<NllLossBackward>), tensor(0.8737, grad_fn=<NllLossBackward>), tensor(0.9586, grad_fn=<NllLossBackward>), tensor(1.0583, grad_fn=<NllLossBackward>), tensor(0.9132, grad_fn=<NllLossBackward>), tensor(0.9029, grad_fn=<NllLossBackward>), tensor(0.8914, grad_fn=<NllLossBackward>), tensor(0.8092, grad_fn=<NllLossBackward>), tensor(1.0157, grad_fn=<NllLossBackward>), tensor(0.9055, grad_fn=<NllLossBackward>), tensor(1.0773, grad_fn=<NllLossBackward>), tensor(1.1098, grad_fn=<NllLossBackward>), tensor(1.0006, grad_fn=<NllLossBackward>), tensor(0.9753, grad_fn=<NllLossBackward>), tensor(1.0966, grad_fn=<NllLossBackward>), tensor(1.0704, grad_fn=<NllLossBackward>), tensor(0.9216, grad_fn=<NllLossBackward>), tensor(1.0629, grad_fn=<NllLossBackward>), tensor(1.0278, grad_fn=<NllLossBackward>), tensor(0.8550, grad_fn=<NllLossBackward>), tensor(0.8208, grad_fn=<NllLossBackward>), tensor(1.1030, grad_fn=<NllLossBackward>), tensor(0.8880, grad_fn=<NllLossBackward>), tensor(0.7724, grad_fn=<NllLossBackward>), tensor(1.0371, grad_fn=<NllLossBackward>), tensor(1.0196, grad_fn=<NllLossBackward>), tensor(0.9408, grad_fn=<NllLossBackward>), tensor(0.9303, grad_fn=<NllLossBackward>), tensor(0.8666, grad_fn=<NllLossBackward>), tensor(0.8896, grad_fn=<NllLossBackward>), tensor(1.0005, grad_fn=<NllLossBackward>), tensor(1.0675, grad_fn=<NllLossBackward>), tensor(0.9742, grad_fn=<NllLossBackward>), tensor(0.9892, grad_fn=<NllLossBackward>), tensor(0.9329, grad_fn=<NllLossBackward>), tensor(0.8567, grad_fn=<NllLossBackward>), tensor(0.8696, grad_fn=<NllLossBackward>), tensor(0.9335, grad_fn=<NllLossBackward>), tensor(1.0708, grad_fn=<NllLossBackward>), tensor(0.9026, grad_fn=<NllLossBackward>), tensor(0.8449, grad_fn=<NllLossBackward>), tensor(1.0748, grad_fn=<NllLossBackward>), tensor(0.8398, grad_fn=<NllLossBackward>), tensor(0.9951, grad_fn=<NllLossBackward>), tensor(0.8241, grad_fn=<NllLossBackward>), tensor(0.9820, grad_fn=<NllLossBackward>), tensor(0.9086, grad_fn=<NllLossBackward>), tensor(1.0869, grad_fn=<NllLossBackward>), tensor(0.8668, grad_fn=<NllLossBackward>), tensor(0.8091, grad_fn=<NllLossBackward>), tensor(0.9017, grad_fn=<NllLossBackward>), tensor(0.8412, grad_fn=<NllLossBackward>), tensor(1.0639, grad_fn=<NllLossBackward>), tensor(1.0935, grad_fn=<NllLossBackward>), tensor(0.7452, grad_fn=<NllLossBackward>), tensor(0.8698, grad_fn=<NllLossBackward>), tensor(0.9146, grad_fn=<NllLossBackward>), tensor(0.8534, grad_fn=<NllLossBackward>), tensor(1.0392, grad_fn=<NllLossBackward>), tensor(0.9951, grad_fn=<NllLossBackward>), tensor(1.0151, grad_fn=<NllLossBackward>), tensor(0.9043, grad_fn=<NllLossBackward>), tensor(1.0483, grad_fn=<NllLossBackward>), tensor(0.9414, grad_fn=<NllLossBackward>), tensor(0.9313, grad_fn=<NllLossBackward>), tensor(0.8670, grad_fn=<NllLossBackward>), tensor(0.8129, grad_fn=<NllLossBackward>), tensor(0.8124, grad_fn=<NllLossBackward>), tensor(1.0459, grad_fn=<NllLossBackward>), tensor(1.0188, grad_fn=<NllLossBackward>), tensor(0.9645, grad_fn=<NllLossBackward>), tensor(0.9033, grad_fn=<NllLossBackward>), tensor(0.9214, grad_fn=<NllLossBackward>), tensor(1.0679, grad_fn=<NllLossBackward>), tensor(0.9207, grad_fn=<NllLossBackward>), tensor(0.8555, grad_fn=<NllLossBackward>), tensor(0.9732, grad_fn=<NllLossBackward>), tensor(1.0182, grad_fn=<NllLossBackward>), tensor(0.8976, grad_fn=<NllLossBackward>), tensor(0.8567, grad_fn=<NllLossBackward>), tensor(0.9015, grad_fn=<NllLossBackward>), tensor(0.7821, grad_fn=<NllLossBackward>), tensor(1.0026, grad_fn=<NllLossBackward>), tensor(0.8205, grad_fn=<NllLossBackward>), tensor(0.9490, grad_fn=<NllLossBackward>), tensor(1.0251, grad_fn=<NllLossBackward>), tensor(0.9562, grad_fn=<NllLossBackward>), tensor(0.7753, grad_fn=<NllLossBackward>), tensor(0.9086, grad_fn=<NllLossBackward>), tensor(0.8597, grad_fn=<NllLossBackward>), tensor(0.7749, grad_fn=<NllLossBackward>), tensor(0.9779, grad_fn=<NllLossBackward>), tensor(1.0480, grad_fn=<NllLossBackward>), tensor(0.9398, grad_fn=<NllLossBackward>), tensor(0.9628, grad_fn=<NllLossBackward>), tensor(0.9976, grad_fn=<NllLossBackward>), tensor(0.9509, grad_fn=<NllLossBackward>), tensor(0.9616, grad_fn=<NllLossBackward>), tensor(0.7709, grad_fn=<NllLossBackward>), tensor(0.9947, grad_fn=<NllLossBackward>), tensor(0.8719, grad_fn=<NllLossBackward>), tensor(0.8920, grad_fn=<NllLossBackward>), tensor(0.8759, grad_fn=<NllLossBackward>), tensor(0.9224, grad_fn=<NllLossBackward>), tensor(0.7388, grad_fn=<NllLossBackward>), tensor(0.8777, grad_fn=<NllLossBackward>), tensor(0.9272, grad_fn=<NllLossBackward>), tensor(1.0512, grad_fn=<NllLossBackward>), tensor(0.9269, grad_fn=<NllLossBackward>), tensor(0.9091, grad_fn=<NllLossBackward>), tensor(0.8382, grad_fn=<NllLossBackward>), tensor(0.8850, grad_fn=<NllLossBackward>), tensor(0.9570, grad_fn=<NllLossBackward>), tensor(0.9194, grad_fn=<NllLossBackward>), tensor(0.7371, grad_fn=<NllLossBackward>), tensor(0.8759, grad_fn=<NllLossBackward>), tensor(0.9221, grad_fn=<NllLossBackward>), tensor(0.9518, grad_fn=<NllLossBackward>), tensor(0.8800, grad_fn=<NllLossBackward>), tensor(0.9079, grad_fn=<NllLossBackward>), tensor(0.8682, grad_fn=<NllLossBackward>), tensor(0.8515, grad_fn=<NllLossBackward>), tensor(1.1332, grad_fn=<NllLossBackward>), tensor(1.0208, grad_fn=<NllLossBackward>), tensor(0.9781, grad_fn=<NllLossBackward>), tensor(1.0065, grad_fn=<NllLossBackward>), tensor(0.8288, grad_fn=<NllLossBackward>), tensor(1.0068, grad_fn=<NllLossBackward>), tensor(0.7711, grad_fn=<NllLossBackward>), tensor(0.8919, grad_fn=<NllLossBackward>), tensor(1.0034, grad_fn=<NllLossBackward>), tensor(0.9918, grad_fn=<NllLossBackward>), tensor(0.9902, grad_fn=<NllLossBackward>), tensor(1.0231, grad_fn=<NllLossBackward>), tensor(0.8469, grad_fn=<NllLossBackward>), tensor(1.0442, grad_fn=<NllLossBackward>), tensor(0.9759, grad_fn=<NllLossBackward>), tensor(0.7593, grad_fn=<NllLossBackward>), tensor(0.9952, grad_fn=<NllLossBackward>), tensor(0.7871, grad_fn=<NllLossBackward>), tensor(0.8559, grad_fn=<NllLossBackward>), tensor(0.9353, grad_fn=<NllLossBackward>), tensor(1.0113, grad_fn=<NllLossBackward>), tensor(1.0283, grad_fn=<NllLossBackward>), tensor(1.0801, grad_fn=<NllLossBackward>), tensor(0.8830, grad_fn=<NllLossBackward>), tensor(0.9638, grad_fn=<NllLossBackward>), tensor(0.8945, grad_fn=<NllLossBackward>), tensor(0.9286, grad_fn=<NllLossBackward>), tensor(0.8987, grad_fn=<NllLossBackward>), tensor(0.7473, grad_fn=<NllLossBackward>), tensor(0.8495, grad_fn=<NllLossBackward>), tensor(0.9791, grad_fn=<NllLossBackward>), tensor(0.9256, grad_fn=<NllLossBackward>), tensor(1.0728, grad_fn=<NllLossBackward>), tensor(0.8883, grad_fn=<NllLossBackward>), tensor(0.9515, grad_fn=<NllLossBackward>), tensor(1.0011, grad_fn=<NllLossBackward>), tensor(0.9719, grad_fn=<NllLossBackward>), tensor(0.9404, grad_fn=<NllLossBackward>), tensor(1.0532, grad_fn=<NllLossBackward>), tensor(0.7677, grad_fn=<NllLossBackward>), tensor(0.9149, grad_fn=<NllLossBackward>), tensor(0.8361, grad_fn=<NllLossBackward>), tensor(0.8964, grad_fn=<NllLossBackward>), tensor(0.9107, grad_fn=<NllLossBackward>), tensor(0.7284, grad_fn=<NllLossBackward>), tensor(1.0089, grad_fn=<NllLossBackward>), tensor(0.8706, grad_fn=<NllLossBackward>), tensor(0.7880, grad_fn=<NllLossBackward>), tensor(0.9358, grad_fn=<NllLossBackward>), tensor(1.0145, grad_fn=<NllLossBackward>), tensor(0.9206, grad_fn=<NllLossBackward>), tensor(0.7987, grad_fn=<NllLossBackward>), tensor(1.0759, grad_fn=<NllLossBackward>), tensor(0.8928, grad_fn=<NllLossBackward>), tensor(0.8594, grad_fn=<NllLossBackward>), tensor(0.9909, grad_fn=<NllLossBackward>), tensor(0.8829, grad_fn=<NllLossBackward>), tensor(0.9823, grad_fn=<NllLossBackward>), tensor(0.9112, grad_fn=<NllLossBackward>), tensor(0.9939, grad_fn=<NllLossBackward>), tensor(0.9688, grad_fn=<NllLossBackward>), tensor(0.9002, grad_fn=<NllLossBackward>), tensor(1.1355, grad_fn=<NllLossBackward>), tensor(0.8593, grad_fn=<NllLossBackward>), tensor(0.9638, grad_fn=<NllLossBackward>), tensor(0.9231, grad_fn=<NllLossBackward>), tensor(0.7642, grad_fn=<NllLossBackward>), tensor(1.0180, grad_fn=<NllLossBackward>), tensor(1.0628, grad_fn=<NllLossBackward>), tensor(0.8787, grad_fn=<NllLossBackward>), tensor(0.8534, grad_fn=<NllLossBackward>), tensor(0.8582, grad_fn=<NllLossBackward>), tensor(0.9012, grad_fn=<NllLossBackward>), tensor(0.8797, grad_fn=<NllLossBackward>), tensor(0.9661, grad_fn=<NllLossBackward>), tensor(0.8472, grad_fn=<NllLossBackward>), tensor(1.1739, grad_fn=<NllLossBackward>), tensor(0.8772, grad_fn=<NllLossBackward>), tensor(0.8924, grad_fn=<NllLossBackward>), tensor(0.9088, grad_fn=<NllLossBackward>), tensor(1.0215, grad_fn=<NllLossBackward>), tensor(1.1272, grad_fn=<NllLossBackward>), tensor(0.8207, grad_fn=<NllLossBackward>), tensor(0.9824, grad_fn=<NllLossBackward>), tensor(0.8008, grad_fn=<NllLossBackward>), tensor(1.1033, grad_fn=<NllLossBackward>), tensor(0.8837, grad_fn=<NllLossBackward>), tensor(0.8335, grad_fn=<NllLossBackward>), tensor(0.9844, grad_fn=<NllLossBackward>), tensor(1.0731, grad_fn=<NllLossBackward>), tensor(0.9763, grad_fn=<NllLossBackward>), tensor(1.1061, grad_fn=<NllLossBackward>), tensor(0.8457, grad_fn=<NllLossBackward>), tensor(0.8969, grad_fn=<NllLossBackward>), tensor(0.8499, grad_fn=<NllLossBackward>), tensor(0.7626, grad_fn=<NllLossBackward>), tensor(0.7235, grad_fn=<NllLossBackward>), tensor(0.9220, grad_fn=<NllLossBackward>), tensor(1.0209, grad_fn=<NllLossBackward>), tensor(0.9132, grad_fn=<NllLossBackward>), tensor(0.9305, grad_fn=<NllLossBackward>), tensor(0.8585, grad_fn=<NllLossBackward>), tensor(0.9529, grad_fn=<NllLossBackward>), tensor(1.0283, grad_fn=<NllLossBackward>), tensor(0.7719, grad_fn=<NllLossBackward>), tensor(0.9328, grad_fn=<NllLossBackward>), tensor(0.9556, grad_fn=<NllLossBackward>), tensor(0.7924, grad_fn=<NllLossBackward>), tensor(0.9694, grad_fn=<NllLossBackward>), tensor(1.0930, grad_fn=<NllLossBackward>), tensor(0.9586, grad_fn=<NllLossBackward>), tensor(0.9622, grad_fn=<NllLossBackward>), tensor(0.9293, grad_fn=<NllLossBackward>), tensor(0.9044, grad_fn=<NllLossBackward>), tensor(1.0421, grad_fn=<NllLossBackward>), tensor(0.9310, grad_fn=<NllLossBackward>), tensor(0.9295, grad_fn=<NllLossBackward>), tensor(0.8838, grad_fn=<NllLossBackward>), tensor(0.9730, grad_fn=<NllLossBackward>), tensor(0.9309, grad_fn=<NllLossBackward>), tensor(0.7348, grad_fn=<NllLossBackward>), tensor(0.7819, grad_fn=<NllLossBackward>), tensor(1.0683, grad_fn=<NllLossBackward>), tensor(0.7714, grad_fn=<NllLossBackward>), tensor(0.7619, grad_fn=<NllLossBackward>), tensor(1.0145, grad_fn=<NllLossBackward>), tensor(0.9700, grad_fn=<NllLossBackward>), tensor(1.1617, grad_fn=<NllLossBackward>), tensor(1.0149, grad_fn=<NllLossBackward>), tensor(1.0404, grad_fn=<NllLossBackward>), tensor(0.9971, grad_fn=<NllLossBackward>), tensor(1.0427, grad_fn=<NllLossBackward>), tensor(0.8787, grad_fn=<NllLossBackward>), tensor(0.8789, grad_fn=<NllLossBackward>), tensor(1.1166, grad_fn=<NllLossBackward>), tensor(0.7632, grad_fn=<NllLossBackward>), tensor(0.9368, grad_fn=<NllLossBackward>), tensor(1.1425, grad_fn=<NllLossBackward>), tensor(0.7586, grad_fn=<NllLossBackward>), tensor(0.9190, grad_fn=<NllLossBackward>), tensor(1.0084, grad_fn=<NllLossBackward>), tensor(0.8871, grad_fn=<NllLossBackward>), tensor(0.8492, grad_fn=<NllLossBackward>), tensor(0.9505, grad_fn=<NllLossBackward>), tensor(1.0510, grad_fn=<NllLossBackward>), tensor(0.9306, grad_fn=<NllLossBackward>), tensor(1.2054, grad_fn=<NllLossBackward>), tensor(0.9382, grad_fn=<NllLossBackward>), tensor(0.8504, grad_fn=<NllLossBackward>), tensor(0.7983, grad_fn=<NllLossBackward>), tensor(0.8428, grad_fn=<NllLossBackward>), tensor(0.9191, grad_fn=<NllLossBackward>), tensor(0.7858, grad_fn=<NllLossBackward>), tensor(1.0349, grad_fn=<NllLossBackward>), tensor(0.9276, grad_fn=<NllLossBackward>), tensor(1.0508, grad_fn=<NllLossBackward>), tensor(0.9616, grad_fn=<NllLossBackward>), tensor(0.8647, grad_fn=<NllLossBackward>), tensor(1.0198, grad_fn=<NllLossBackward>), tensor(0.9252, grad_fn=<NllLossBackward>), tensor(0.8749, grad_fn=<NllLossBackward>), tensor(1.0382, grad_fn=<NllLossBackward>), tensor(0.9875, grad_fn=<NllLossBackward>), tensor(0.9257, grad_fn=<NllLossBackward>), tensor(1.1626, grad_fn=<NllLossBackward>), tensor(0.7264, grad_fn=<NllLossBackward>), tensor(0.8408, grad_fn=<NllLossBackward>), tensor(0.9367, grad_fn=<NllLossBackward>), tensor(1.1286, grad_fn=<NllLossBackward>), tensor(0.9132, grad_fn=<NllLossBackward>), tensor(0.9613, grad_fn=<NllLossBackward>), tensor(0.9173, grad_fn=<NllLossBackward>), tensor(0.7551, grad_fn=<NllLossBackward>), tensor(0.9349, grad_fn=<NllLossBackward>), tensor(0.7967, grad_fn=<NllLossBackward>), tensor(0.9760, grad_fn=<NllLossBackward>), tensor(0.9608, grad_fn=<NllLossBackward>), tensor(1.0853, grad_fn=<NllLossBackward>), tensor(0.8942, grad_fn=<NllLossBackward>), tensor(0.9982, grad_fn=<NllLossBackward>), tensor(1.0279, grad_fn=<NllLossBackward>), tensor(1.1230, grad_fn=<NllLossBackward>), tensor(0.9616, grad_fn=<NllLossBackward>), tensor(0.6762, grad_fn=<NllLossBackward>), tensor(0.8218, grad_fn=<NllLossBackward>), tensor(1.0354, grad_fn=<NllLossBackward>), tensor(1.0027, grad_fn=<NllLossBackward>), tensor(0.8962, grad_fn=<NllLossBackward>), tensor(0.9595, grad_fn=<NllLossBackward>), tensor(0.8985, grad_fn=<NllLossBackward>), tensor(1.0352, grad_fn=<NllLossBackward>), tensor(0.8709, grad_fn=<NllLossBackward>), tensor(0.9017, grad_fn=<NllLossBackward>), tensor(0.8437, grad_fn=<NllLossBackward>), tensor(0.9017, grad_fn=<NllLossBackward>), tensor(0.9629, grad_fn=<NllLossBackward>), tensor(1.0823, grad_fn=<NllLossBackward>), tensor(1.1082, grad_fn=<NllLossBackward>), tensor(0.9053, grad_fn=<NllLossBackward>), tensor(0.9012, grad_fn=<NllLossBackward>), tensor(0.8563, grad_fn=<NllLossBackward>), tensor(0.9023, grad_fn=<NllLossBackward>), tensor(0.9335, grad_fn=<NllLossBackward>), tensor(0.8851, grad_fn=<NllLossBackward>), tensor(0.9513, grad_fn=<NllLossBackward>), tensor(0.9564, grad_fn=<NllLossBackward>), tensor(0.7049, grad_fn=<NllLossBackward>), tensor(0.7798, grad_fn=<NllLossBackward>), tensor(1.0049, grad_fn=<NllLossBackward>), tensor(1.0749, grad_fn=<NllLossBackward>), tensor(0.7855, grad_fn=<NllLossBackward>), tensor(0.8606, grad_fn=<NllLossBackward>), tensor(0.8883, grad_fn=<NllLossBackward>), tensor(0.8148, grad_fn=<NllLossBackward>), tensor(0.9201, grad_fn=<NllLossBackward>), tensor(0.9710, grad_fn=<NllLossBackward>), tensor(0.7110, grad_fn=<NllLossBackward>), tensor(0.8777, grad_fn=<NllLossBackward>), tensor(0.8227, grad_fn=<NllLossBackward>), tensor(0.9515, grad_fn=<NllLossBackward>), tensor(1.0326, grad_fn=<NllLossBackward>), tensor(0.9723, grad_fn=<NllLossBackward>), tensor(0.8890, grad_fn=<NllLossBackward>), tensor(0.8648, grad_fn=<NllLossBackward>), tensor(0.8452, grad_fn=<NllLossBackward>), tensor(0.9194, grad_fn=<NllLossBackward>), tensor(1.0753, grad_fn=<NllLossBackward>), tensor(1.0158, grad_fn=<NllLossBackward>), tensor(0.9607, grad_fn=<NllLossBackward>), tensor(1.0311, grad_fn=<NllLossBackward>), tensor(0.6290, grad_fn=<NllLossBackward>), tensor(0.9872, grad_fn=<NllLossBackward>), tensor(0.8603, grad_fn=<NllLossBackward>), tensor(0.9357, grad_fn=<NllLossBackward>), tensor(0.8594, grad_fn=<NllLossBackward>), tensor(0.8371, grad_fn=<NllLossBackward>), tensor(0.7928, grad_fn=<NllLossBackward>), tensor(0.8739, grad_fn=<NllLossBackward>), tensor(0.9039, grad_fn=<NllLossBackward>), tensor(1.0513, grad_fn=<NllLossBackward>), tensor(0.8020, grad_fn=<NllLossBackward>), tensor(0.9190, grad_fn=<NllLossBackward>), tensor(0.8683, grad_fn=<NllLossBackward>), tensor(0.9651, grad_fn=<NllLossBackward>), tensor(0.9647, grad_fn=<NllLossBackward>), tensor(0.9728, grad_fn=<NllLossBackward>), tensor(0.8993, grad_fn=<NllLossBackward>), tensor(1.0357, grad_fn=<NllLossBackward>), tensor(0.8925, grad_fn=<NllLossBackward>), tensor(0.7897, grad_fn=<NllLossBackward>), tensor(0.7720, grad_fn=<NllLossBackward>), tensor(0.8119, grad_fn=<NllLossBackward>), tensor(1.1554, grad_fn=<NllLossBackward>), tensor(1.0197, grad_fn=<NllLossBackward>), tensor(1.0476, grad_fn=<NllLossBackward>), tensor(0.8016, grad_fn=<NllLossBackward>), tensor(0.9771, grad_fn=<NllLossBackward>), tensor(0.9555, grad_fn=<NllLossBackward>), tensor(1.1722, grad_fn=<NllLossBackward>), tensor(1.0670, grad_fn=<NllLossBackward>), tensor(0.7548, grad_fn=<NllLossBackward>), tensor(1.0021, grad_fn=<NllLossBackward>), tensor(1.1026, grad_fn=<NllLossBackward>), tensor(0.9858, grad_fn=<NllLossBackward>), tensor(0.9353, grad_fn=<NllLossBackward>), tensor(0.7496, grad_fn=<NllLossBackward>), tensor(1.0117, grad_fn=<NllLossBackward>), tensor(0.7959, grad_fn=<NllLossBackward>), tensor(0.9047, grad_fn=<NllLossBackward>), tensor(1.0928, grad_fn=<NllLossBackward>), tensor(0.9087, grad_fn=<NllLossBackward>), tensor(1.0769, grad_fn=<NllLossBackward>), tensor(0.8978, grad_fn=<NllLossBackward>), tensor(1.0868, grad_fn=<NllLossBackward>), tensor(0.6983, grad_fn=<NllLossBackward>), tensor(0.8836, grad_fn=<NllLossBackward>), tensor(1.1249, grad_fn=<NllLossBackward>), tensor(0.8943, grad_fn=<NllLossBackward>), tensor(0.8641, grad_fn=<NllLossBackward>), tensor(0.8749, grad_fn=<NllLossBackward>), tensor(1.1339, grad_fn=<NllLossBackward>), tensor(0.9981, grad_fn=<NllLossBackward>), tensor(0.9786, grad_fn=<NllLossBackward>), tensor(0.9150, grad_fn=<NllLossBackward>), tensor(0.9037, grad_fn=<NllLossBackward>), tensor(0.9559, grad_fn=<NllLossBackward>), tensor(1.1387, grad_fn=<NllLossBackward>), tensor(1.0267, grad_fn=<NllLossBackward>), tensor(0.7640, grad_fn=<NllLossBackward>), tensor(0.9019, grad_fn=<NllLossBackward>), tensor(0.8587, grad_fn=<NllLossBackward>), tensor(0.9271, grad_fn=<NllLossBackward>), tensor(0.9310, grad_fn=<NllLossBackward>), tensor(0.9297, grad_fn=<NllLossBackward>), tensor(0.8496, grad_fn=<NllLossBackward>), tensor(0.9428, grad_fn=<NllLossBackward>), tensor(0.9031, grad_fn=<NllLossBackward>), tensor(1.0797, grad_fn=<NllLossBackward>), tensor(0.9799, grad_fn=<NllLossBackward>), tensor(1.0090, grad_fn=<NllLossBackward>), tensor(0.9777, grad_fn=<NllLossBackward>), tensor(0.9679, grad_fn=<NllLossBackward>), tensor(0.9519, grad_fn=<NllLossBackward>), tensor(0.7242, grad_fn=<NllLossBackward>), tensor(1.1362, grad_fn=<NllLossBackward>), tensor(0.9905, grad_fn=<NllLossBackward>), tensor(0.8621, grad_fn=<NllLossBackward>), tensor(0.9301, grad_fn=<NllLossBackward>), tensor(0.8833, grad_fn=<NllLossBackward>), tensor(0.9677, grad_fn=<NllLossBackward>), tensor(1.0227, grad_fn=<NllLossBackward>), tensor(0.9382, grad_fn=<NllLossBackward>), tensor(0.8702, grad_fn=<NllLossBackward>), tensor(1.0613, grad_fn=<NllLossBackward>), tensor(1.0704, grad_fn=<NllLossBackward>), tensor(1.0788, grad_fn=<NllLossBackward>), tensor(1.0584, grad_fn=<NllLossBackward>), tensor(0.9086, grad_fn=<NllLossBackward>), tensor(0.9649, grad_fn=<NllLossBackward>), tensor(0.8898, grad_fn=<NllLossBackward>), tensor(1.0226, grad_fn=<NllLossBackward>), tensor(1.0325, grad_fn=<NllLossBackward>), tensor(0.9233, grad_fn=<NllLossBackward>), tensor(0.8073, grad_fn=<NllLossBackward>), tensor(1.1321, grad_fn=<NllLossBackward>), tensor(1.0411, grad_fn=<NllLossBackward>), tensor(0.8058, grad_fn=<NllLossBackward>), tensor(1.0543, grad_fn=<NllLossBackward>), tensor(0.8789, grad_fn=<NllLossBackward>), tensor(0.8669, grad_fn=<NllLossBackward>), tensor(0.8914, grad_fn=<NllLossBackward>), tensor(0.9711, grad_fn=<NllLossBackward>), tensor(0.8863, grad_fn=<NllLossBackward>), tensor(0.9297, grad_fn=<NllLossBackward>), tensor(0.7905, grad_fn=<NllLossBackward>), tensor(1.0150, grad_fn=<NllLossBackward>), tensor(0.8395, grad_fn=<NllLossBackward>), tensor(0.8676, grad_fn=<NllLossBackward>), tensor(1.0323, grad_fn=<NllLossBackward>), tensor(1.0041, grad_fn=<NllLossBackward>), tensor(1.0587, grad_fn=<NllLossBackward>), tensor(0.8636, grad_fn=<NllLossBackward>), tensor(0.8733, grad_fn=<NllLossBackward>), tensor(0.9489, grad_fn=<NllLossBackward>), tensor(0.8422, grad_fn=<NllLossBackward>), tensor(0.9967, grad_fn=<NllLossBackward>), tensor(1.0298, grad_fn=<NllLossBackward>), tensor(1.0360, grad_fn=<NllLossBackward>), tensor(0.9582, grad_fn=<NllLossBackward>), tensor(0.8797, grad_fn=<NllLossBackward>), tensor(0.7915, grad_fn=<NllLossBackward>), tensor(0.9209, grad_fn=<NllLossBackward>), tensor(0.8169, grad_fn=<NllLossBackward>), tensor(0.8735, grad_fn=<NllLossBackward>), tensor(0.7400, grad_fn=<NllLossBackward>), tensor(0.9553, grad_fn=<NllLossBackward>), tensor(0.8306, grad_fn=<NllLossBackward>), tensor(0.8322, grad_fn=<NllLossBackward>), tensor(0.8977, grad_fn=<NllLossBackward>), tensor(0.9209, grad_fn=<NllLossBackward>), tensor(1.0086, grad_fn=<NllLossBackward>), tensor(1.1100, grad_fn=<NllLossBackward>), tensor(0.8963, grad_fn=<NllLossBackward>), tensor(0.7466, grad_fn=<NllLossBackward>), tensor(1.0879, grad_fn=<NllLossBackward>), tensor(0.7933, grad_fn=<NllLossBackward>), tensor(0.9747, grad_fn=<NllLossBackward>), tensor(0.8857, grad_fn=<NllLossBackward>), tensor(0.8784, grad_fn=<NllLossBackward>), tensor(0.9163, grad_fn=<NllLossBackward>), tensor(0.9222, grad_fn=<NllLossBackward>), tensor(0.9187, grad_fn=<NllLossBackward>), tensor(1.0516, grad_fn=<NllLossBackward>), tensor(1.0373, grad_fn=<NllLossBackward>), tensor(0.9067, grad_fn=<NllLossBackward>), tensor(0.9977, grad_fn=<NllLossBackward>), tensor(1.0471, grad_fn=<NllLossBackward>), tensor(0.9864, grad_fn=<NllLossBackward>), tensor(0.9463, grad_fn=<NllLossBackward>), tensor(0.8488, grad_fn=<NllLossBackward>), tensor(0.9827, grad_fn=<NllLossBackward>), tensor(0.8940, grad_fn=<NllLossBackward>), tensor(0.7869, grad_fn=<NllLossBackward>), tensor(0.8699, grad_fn=<NllLossBackward>), tensor(0.9442, grad_fn=<NllLossBackward>), tensor(0.9156, grad_fn=<NllLossBackward>), tensor(0.9862, grad_fn=<NllLossBackward>), tensor(0.8126, grad_fn=<NllLossBackward>), tensor(0.9019, grad_fn=<NllLossBackward>), tensor(0.8419, grad_fn=<NllLossBackward>), tensor(0.8216, grad_fn=<NllLossBackward>), tensor(0.7643, grad_fn=<NllLossBackward>), tensor(0.9502, grad_fn=<NllLossBackward>), tensor(0.8798, grad_fn=<NllLossBackward>), tensor(0.9468, grad_fn=<NllLossBackward>), tensor(1.0434, grad_fn=<NllLossBackward>), tensor(0.9933, grad_fn=<NllLossBackward>), tensor(0.8264, grad_fn=<NllLossBackward>), tensor(0.6931, grad_fn=<NllLossBackward>), tensor(1.1301, grad_fn=<NllLossBackward>), tensor(0.9913, grad_fn=<NllLossBackward>), tensor(0.8872, grad_fn=<NllLossBackward>), tensor(1.0062, grad_fn=<NllLossBackward>), tensor(0.9415, grad_fn=<NllLossBackward>), tensor(0.8359, grad_fn=<NllLossBackward>), tensor(1.1280, grad_fn=<NllLossBackward>), tensor(0.8846, grad_fn=<NllLossBackward>), tensor(0.9682, grad_fn=<NllLossBackward>), tensor(0.8799, grad_fn=<NllLossBackward>), tensor(0.9376, grad_fn=<NllLossBackward>), tensor(0.8354, grad_fn=<NllLossBackward>), tensor(0.9971, grad_fn=<NllLossBackward>), tensor(0.8473, grad_fn=<NllLossBackward>), tensor(0.8871, grad_fn=<NllLossBackward>), tensor(0.8647, grad_fn=<NllLossBackward>), tensor(0.8759, grad_fn=<NllLossBackward>), tensor(1.0040, grad_fn=<NllLossBackward>), tensor(0.9025, grad_fn=<NllLossBackward>), tensor(0.9383, grad_fn=<NllLossBackward>), tensor(0.9863, grad_fn=<NllLossBackward>), tensor(0.8352, grad_fn=<NllLossBackward>), tensor(0.8342, grad_fn=<NllLossBackward>), tensor(0.8380, grad_fn=<NllLossBackward>), tensor(1.1943, grad_fn=<NllLossBackward>), tensor(0.9293, grad_fn=<NllLossBackward>), tensor(1.0941, grad_fn=<NllLossBackward>), tensor(0.8784, grad_fn=<NllLossBackward>), tensor(0.8185, grad_fn=<NllLossBackward>), tensor(0.8631, grad_fn=<NllLossBackward>), tensor(1.1521, grad_fn=<NllLossBackward>), tensor(0.9165, grad_fn=<NllLossBackward>), tensor(0.9188, grad_fn=<NllLossBackward>), tensor(0.8053, grad_fn=<NllLossBackward>), tensor(0.9164, grad_fn=<NllLossBackward>), tensor(1.1865, grad_fn=<NllLossBackward>), tensor(0.9996, grad_fn=<NllLossBackward>), tensor(0.8662, grad_fn=<NllLossBackward>), tensor(1.1389, grad_fn=<NllLossBackward>), tensor(0.9194, grad_fn=<NllLossBackward>), tensor(0.8803, grad_fn=<NllLossBackward>), tensor(0.7959, grad_fn=<NllLossBackward>), tensor(0.8496, grad_fn=<NllLossBackward>), tensor(0.9060, grad_fn=<NllLossBackward>), tensor(1.0317, grad_fn=<NllLossBackward>), tensor(0.7897, grad_fn=<NllLossBackward>), tensor(0.8265, grad_fn=<NllLossBackward>), tensor(0.9231, grad_fn=<NllLossBackward>), tensor(0.9465, grad_fn=<NllLossBackward>), tensor(0.8648, grad_fn=<NllLossBackward>), tensor(1.1362, grad_fn=<NllLossBackward>), tensor(0.7559, grad_fn=<NllLossBackward>), tensor(0.7539, grad_fn=<NllLossBackward>), tensor(0.8706, grad_fn=<NllLossBackward>), tensor(1.0590, grad_fn=<NllLossBackward>), tensor(0.7426, grad_fn=<NllLossBackward>), tensor(0.9009, grad_fn=<NllLossBackward>), tensor(1.1907, grad_fn=<NllLossBackward>), tensor(0.8211, grad_fn=<NllLossBackward>), tensor(0.8852, grad_fn=<NllLossBackward>), tensor(0.9498, grad_fn=<NllLossBackward>), tensor(0.7608, grad_fn=<NllLossBackward>), tensor(0.8712, grad_fn=<NllLossBackward>), tensor(1.2198, grad_fn=<NllLossBackward>), tensor(0.9272, grad_fn=<NllLossBackward>), tensor(0.9809, grad_fn=<NllLossBackward>), tensor(0.8419, grad_fn=<NllLossBackward>), tensor(0.9811, grad_fn=<NllLossBackward>), tensor(0.9731, grad_fn=<NllLossBackward>), tensor(0.9014, grad_fn=<NllLossBackward>), tensor(0.8197, grad_fn=<NllLossBackward>), tensor(0.9205, grad_fn=<NllLossBackward>), tensor(0.9348, grad_fn=<NllLossBackward>), tensor(0.7612, grad_fn=<NllLossBackward>), tensor(0.7497, grad_fn=<NllLossBackward>), tensor(1.1170, grad_fn=<NllLossBackward>), tensor(1.0044, grad_fn=<NllLossBackward>), tensor(1.0730, grad_fn=<NllLossBackward>), tensor(0.8383, grad_fn=<NllLossBackward>), tensor(0.7715, grad_fn=<NllLossBackward>), tensor(0.8868, grad_fn=<NllLossBackward>), tensor(1.0744, grad_fn=<NllLossBackward>), tensor(1.1090, grad_fn=<NllLossBackward>), tensor(0.8857, grad_fn=<NllLossBackward>), tensor(0.7719, grad_fn=<NllLossBackward>), tensor(0.9422, grad_fn=<NllLossBackward>), tensor(1.0824, grad_fn=<NllLossBackward>), tensor(0.9051, grad_fn=<NllLossBackward>), tensor(1.0420, grad_fn=<NllLossBackward>), tensor(0.9916, grad_fn=<NllLossBackward>), tensor(0.8684, grad_fn=<NllLossBackward>), tensor(0.9054, grad_fn=<NllLossBackward>), tensor(0.9340, grad_fn=<NllLossBackward>), tensor(0.8770, grad_fn=<NllLossBackward>), tensor(0.8360, grad_fn=<NllLossBackward>), tensor(0.9909, grad_fn=<NllLossBackward>), tensor(0.9256, grad_fn=<NllLossBackward>), tensor(1.0061, grad_fn=<NllLossBackward>), tensor(0.9198, grad_fn=<NllLossBackward>), tensor(0.9843, grad_fn=<NllLossBackward>), tensor(1.0070, grad_fn=<NllLossBackward>), tensor(0.8069, grad_fn=<NllLossBackward>), tensor(1.1426, grad_fn=<NllLossBackward>), tensor(1.0061, grad_fn=<NllLossBackward>), tensor(1.0046, grad_fn=<NllLossBackward>), tensor(0.7948, grad_fn=<NllLossBackward>), tensor(0.9867, grad_fn=<NllLossBackward>), tensor(1.0458, grad_fn=<NllLossBackward>), tensor(0.7490, grad_fn=<NllLossBackward>), tensor(0.8554, grad_fn=<NllLossBackward>), tensor(0.7204, grad_fn=<NllLossBackward>), tensor(0.9803, grad_fn=<NllLossBackward>), tensor(0.9294, grad_fn=<NllLossBackward>), tensor(1.0194, grad_fn=<NllLossBackward>), tensor(0.8776, grad_fn=<NllLossBackward>), tensor(0.9638, grad_fn=<NllLossBackward>), tensor(0.8324, grad_fn=<NllLossBackward>), tensor(0.9441, grad_fn=<NllLossBackward>), tensor(0.8990, grad_fn=<NllLossBackward>), tensor(1.0234, grad_fn=<NllLossBackward>), tensor(1.0118, grad_fn=<NllLossBackward>), tensor(0.9744, grad_fn=<NllLossBackward>), tensor(0.9523, grad_fn=<NllLossBackward>), tensor(0.8557, grad_fn=<NllLossBackward>), tensor(0.8885, grad_fn=<NllLossBackward>), tensor(0.8804, grad_fn=<NllLossBackward>), tensor(0.8463, grad_fn=<NllLossBackward>), tensor(0.9991, grad_fn=<NllLossBackward>), tensor(1.0166, grad_fn=<NllLossBackward>), tensor(0.8037, grad_fn=<NllLossBackward>), tensor(1.0201, grad_fn=<NllLossBackward>), tensor(0.9751, grad_fn=<NllLossBackward>), tensor(0.9238, grad_fn=<NllLossBackward>), tensor(0.8718, grad_fn=<NllLossBackward>), tensor(0.8122, grad_fn=<NllLossBackward>), tensor(0.8940, grad_fn=<NllLossBackward>), tensor(0.8472, grad_fn=<NllLossBackward>), tensor(0.8389, grad_fn=<NllLossBackward>), tensor(0.9342, grad_fn=<NllLossBackward>), tensor(1.1081, grad_fn=<NllLossBackward>), tensor(0.8830, grad_fn=<NllLossBackward>), tensor(0.9101, grad_fn=<NllLossBackward>), tensor(0.9368, grad_fn=<NllLossBackward>), tensor(0.9559, grad_fn=<NllLossBackward>), tensor(0.9720, grad_fn=<NllLossBackward>), tensor(1.0430, grad_fn=<NllLossBackward>), tensor(0.9300, grad_fn=<NllLossBackward>), tensor(0.9478, grad_fn=<NllLossBackward>), tensor(0.7461, grad_fn=<NllLossBackward>), tensor(0.8390, grad_fn=<NllLossBackward>), tensor(0.8285, grad_fn=<NllLossBackward>), tensor(0.7957, grad_fn=<NllLossBackward>), tensor(0.9381, grad_fn=<NllLossBackward>), tensor(0.7081, grad_fn=<NllLossBackward>), tensor(0.9091, grad_fn=<NllLossBackward>), tensor(0.9913, grad_fn=<NllLossBackward>), tensor(0.9137, grad_fn=<NllLossBackward>), tensor(0.8193, grad_fn=<NllLossBackward>), tensor(0.8142, grad_fn=<NllLossBackward>), tensor(1.0192, grad_fn=<NllLossBackward>), tensor(1.0105, grad_fn=<NllLossBackward>), tensor(0.7676, grad_fn=<NllLossBackward>), tensor(0.9205, grad_fn=<NllLossBackward>), tensor(0.9298, grad_fn=<NllLossBackward>), tensor(0.8760, grad_fn=<NllLossBackward>), tensor(0.8385, grad_fn=<NllLossBackward>), tensor(0.9486, grad_fn=<NllLossBackward>), tensor(1.0284, grad_fn=<NllLossBackward>), tensor(1.0478, grad_fn=<NllLossBackward>), tensor(0.9373, grad_fn=<NllLossBackward>), tensor(0.9864, grad_fn=<NllLossBackward>), tensor(0.7583, grad_fn=<NllLossBackward>), tensor(0.9152, grad_fn=<NllLossBackward>), tensor(0.9240, grad_fn=<NllLossBackward>), tensor(0.9847, grad_fn=<NllLossBackward>), tensor(1.0131, grad_fn=<NllLossBackward>), tensor(0.8183, grad_fn=<NllLossBackward>), tensor(0.8373, grad_fn=<NllLossBackward>), tensor(0.9320, grad_fn=<NllLossBackward>), tensor(0.8583, grad_fn=<NllLossBackward>), tensor(0.8983, grad_fn=<NllLossBackward>), tensor(1.0207, grad_fn=<NllLossBackward>), tensor(0.9802, grad_fn=<NllLossBackward>), tensor(0.9747, grad_fn=<NllLossBackward>), tensor(1.0858, grad_fn=<NllLossBackward>), tensor(0.8821, grad_fn=<NllLossBackward>), tensor(1.0685, grad_fn=<NllLossBackward>), tensor(0.9740, grad_fn=<NllLossBackward>), tensor(0.9821, grad_fn=<NllLossBackward>), tensor(0.9225, grad_fn=<NllLossBackward>), tensor(1.0667, grad_fn=<NllLossBackward>), tensor(0.9894, grad_fn=<NllLossBackward>), tensor(0.9909, grad_fn=<NllLossBackward>), tensor(0.9021, grad_fn=<NllLossBackward>), tensor(0.8303, grad_fn=<NllLossBackward>), tensor(0.8802, grad_fn=<NllLossBackward>), tensor(0.9668, grad_fn=<NllLossBackward>), tensor(0.8413, grad_fn=<NllLossBackward>), tensor(0.9422, grad_fn=<NllLossBackward>), tensor(0.8806, grad_fn=<NllLossBackward>), tensor(0.8830, grad_fn=<NllLossBackward>), tensor(0.9765, grad_fn=<NllLossBackward>), tensor(1.1100, grad_fn=<NllLossBackward>), tensor(0.8341, grad_fn=<NllLossBackward>), tensor(0.9858, grad_fn=<NllLossBackward>), tensor(0.7208, grad_fn=<NllLossBackward>), tensor(0.8151, grad_fn=<NllLossBackward>), tensor(0.6972, grad_fn=<NllLossBackward>), tensor(0.7939, grad_fn=<NllLossBackward>), tensor(1.0979, grad_fn=<NllLossBackward>), tensor(0.8245, grad_fn=<NllLossBackward>), tensor(0.9070, grad_fn=<NllLossBackward>), tensor(1.1039, grad_fn=<NllLossBackward>), tensor(0.9418, grad_fn=<NllLossBackward>), tensor(0.7558, grad_fn=<NllLossBackward>), tensor(0.7645, grad_fn=<NllLossBackward>), tensor(0.7754, grad_fn=<NllLossBackward>), tensor(0.9228, grad_fn=<NllLossBackward>), tensor(0.7710, grad_fn=<NllLossBackward>), tensor(0.7487, grad_fn=<NllLossBackward>), tensor(0.8466, grad_fn=<NllLossBackward>), tensor(0.8860, grad_fn=<NllLossBackward>), tensor(0.8599, grad_fn=<NllLossBackward>), tensor(0.9063, grad_fn=<NllLossBackward>), tensor(0.9148, grad_fn=<NllLossBackward>), tensor(0.7328, grad_fn=<NllLossBackward>), tensor(1.0025, grad_fn=<NllLossBackward>), tensor(1.0179, grad_fn=<NllLossBackward>), tensor(0.9787, grad_fn=<NllLossBackward>), tensor(0.7558, grad_fn=<NllLossBackward>), tensor(0.9890, grad_fn=<NllLossBackward>), tensor(0.9293, grad_fn=<NllLossBackward>), tensor(0.8073, grad_fn=<NllLossBackward>), tensor(0.7959, grad_fn=<NllLossBackward>), tensor(0.8804, grad_fn=<NllLossBackward>), tensor(0.8815, grad_fn=<NllLossBackward>), tensor(0.7625, grad_fn=<NllLossBackward>), tensor(0.9279, grad_fn=<NllLossBackward>), tensor(1.0514, grad_fn=<NllLossBackward>), tensor(0.9357, grad_fn=<NllLossBackward>), tensor(1.0041, grad_fn=<NllLossBackward>), tensor(0.8848, grad_fn=<NllLossBackward>), tensor(1.0385, grad_fn=<NllLossBackward>), tensor(0.9491, grad_fn=<NllLossBackward>), tensor(0.8774, grad_fn=<NllLossBackward>), tensor(0.8260, grad_fn=<NllLossBackward>), tensor(0.8605, grad_fn=<NllLossBackward>), tensor(0.9383, grad_fn=<NllLossBackward>), tensor(0.8736, grad_fn=<NllLossBackward>), tensor(0.7820, grad_fn=<NllLossBackward>), tensor(1.0201, grad_fn=<NllLossBackward>), tensor(0.8496, grad_fn=<NllLossBackward>), tensor(1.0134, grad_fn=<NllLossBackward>), tensor(0.9571, grad_fn=<NllLossBackward>), tensor(1.1956, grad_fn=<NllLossBackward>), tensor(0.9594, grad_fn=<NllLossBackward>), tensor(1.0589, grad_fn=<NllLossBackward>), tensor(0.9974, grad_fn=<NllLossBackward>), tensor(0.9294, grad_fn=<NllLossBackward>), tensor(0.7751, grad_fn=<NllLossBackward>), tensor(0.7726, grad_fn=<NllLossBackward>), tensor(1.0034, grad_fn=<NllLossBackward>), tensor(0.8072, grad_fn=<NllLossBackward>), tensor(1.0605, grad_fn=<NllLossBackward>), tensor(0.8859, grad_fn=<NllLossBackward>), tensor(0.8938, grad_fn=<NllLossBackward>), tensor(0.8192, grad_fn=<NllLossBackward>), tensor(1.1637, grad_fn=<NllLossBackward>), tensor(1.0486, grad_fn=<NllLossBackward>), tensor(1.1639, grad_fn=<NllLossBackward>), tensor(0.9652, grad_fn=<NllLossBackward>), tensor(1.0594, grad_fn=<NllLossBackward>), tensor(0.6642, grad_fn=<NllLossBackward>), tensor(0.9638, grad_fn=<NllLossBackward>), tensor(1.0374, grad_fn=<NllLossBackward>), tensor(0.9621, grad_fn=<NllLossBackward>), tensor(0.8344, grad_fn=<NllLossBackward>), tensor(1.0670, grad_fn=<NllLossBackward>), tensor(0.7855, grad_fn=<NllLossBackward>), tensor(0.9991, grad_fn=<NllLossBackward>), tensor(1.0008, grad_fn=<NllLossBackward>), tensor(0.9948, grad_fn=<NllLossBackward>), tensor(0.9256, grad_fn=<NllLossBackward>), tensor(0.7419, grad_fn=<NllLossBackward>), tensor(1.1246, grad_fn=<NllLossBackward>), tensor(0.8116, grad_fn=<NllLossBackward>), tensor(1.1818, grad_fn=<NllLossBackward>), tensor(0.9337, grad_fn=<NllLossBackward>), tensor(0.9565, grad_fn=<NllLossBackward>), tensor(0.9352, grad_fn=<NllLossBackward>), tensor(0.8042, grad_fn=<NllLossBackward>), tensor(1.0758, grad_fn=<NllLossBackward>), tensor(1.1637, grad_fn=<NllLossBackward>), tensor(0.9549, grad_fn=<NllLossBackward>), tensor(0.8633, grad_fn=<NllLossBackward>), tensor(0.9258, grad_fn=<NllLossBackward>), tensor(0.8991, grad_fn=<NllLossBackward>), tensor(0.9680, grad_fn=<NllLossBackward>), tensor(0.9509, grad_fn=<NllLossBackward>), tensor(0.8870, grad_fn=<NllLossBackward>), tensor(0.9632, grad_fn=<NllLossBackward>), tensor(0.7846, grad_fn=<NllLossBackward>), tensor(1.1276, grad_fn=<NllLossBackward>), tensor(0.9512, grad_fn=<NllLossBackward>), tensor(0.8627, grad_fn=<NllLossBackward>), tensor(0.8277, grad_fn=<NllLossBackward>), tensor(0.9117, grad_fn=<NllLossBackward>), tensor(0.7890, grad_fn=<NllLossBackward>), tensor(0.8260, grad_fn=<NllLossBackward>), tensor(1.0201, grad_fn=<NllLossBackward>), tensor(0.8905, grad_fn=<NllLossBackward>), tensor(0.9050, grad_fn=<NllLossBackward>), tensor(0.6738, grad_fn=<NllLossBackward>), tensor(0.9003, grad_fn=<NllLossBackward>), tensor(0.9887, grad_fn=<NllLossBackward>), tensor(0.9673, grad_fn=<NllLossBackward>), tensor(0.8800, grad_fn=<NllLossBackward>), tensor(0.9187, grad_fn=<NllLossBackward>), tensor(0.7812, grad_fn=<NllLossBackward>), tensor(0.8649, grad_fn=<NllLossBackward>), tensor(1.1438, grad_fn=<NllLossBackward>), tensor(0.8562, grad_fn=<NllLossBackward>), tensor(0.7580, grad_fn=<NllLossBackward>), tensor(0.7091, grad_fn=<NllLossBackward>), tensor(0.8953, grad_fn=<NllLossBackward>), tensor(1.0433, grad_fn=<NllLossBackward>), tensor(0.8905, grad_fn=<NllLossBackward>), tensor(0.9605, grad_fn=<NllLossBackward>), tensor(0.8965, grad_fn=<NllLossBackward>), tensor(0.7797, grad_fn=<NllLossBackward>), tensor(1.0141, grad_fn=<NllLossBackward>), tensor(0.7732, grad_fn=<NllLossBackward>), tensor(0.9813, grad_fn=<NllLossBackward>), tensor(0.9438, grad_fn=<NllLossBackward>), tensor(1.0097, grad_fn=<NllLossBackward>), tensor(1.1550, grad_fn=<NllLossBackward>), tensor(0.8062, grad_fn=<NllLossBackward>), tensor(1.0100, grad_fn=<NllLossBackward>), tensor(0.9799, grad_fn=<NllLossBackward>), tensor(0.9622, grad_fn=<NllLossBackward>), tensor(0.9002, grad_fn=<NllLossBackward>), tensor(0.9504, grad_fn=<NllLossBackward>), tensor(0.8332, grad_fn=<NllLossBackward>), tensor(0.9160, grad_fn=<NllLossBackward>), tensor(0.8373, grad_fn=<NllLossBackward>), tensor(0.9443, grad_fn=<NllLossBackward>), tensor(0.9612, grad_fn=<NllLossBackward>), tensor(0.9074, grad_fn=<NllLossBackward>), tensor(0.8262, grad_fn=<NllLossBackward>), tensor(0.8926, grad_fn=<NllLossBackward>), tensor(0.8997, grad_fn=<NllLossBackward>), tensor(0.9905, grad_fn=<NllLossBackward>), tensor(1.0282, grad_fn=<NllLossBackward>), tensor(0.9237, grad_fn=<NllLossBackward>), tensor(0.9351, grad_fn=<NllLossBackward>), tensor(0.7665, grad_fn=<NllLossBackward>), tensor(0.8442, grad_fn=<NllLossBackward>), tensor(0.9401, grad_fn=<NllLossBackward>), tensor(1.0166, grad_fn=<NllLossBackward>), tensor(0.7738, grad_fn=<NllLossBackward>), tensor(0.9131, grad_fn=<NllLossBackward>), tensor(0.8070, grad_fn=<NllLossBackward>), tensor(0.8315, grad_fn=<NllLossBackward>), tensor(0.9208, grad_fn=<NllLossBackward>), tensor(1.0913, grad_fn=<NllLossBackward>), tensor(0.7597, grad_fn=<NllLossBackward>), tensor(0.9536, grad_fn=<NllLossBackward>), tensor(0.9609, grad_fn=<NllLossBackward>), tensor(1.0100, grad_fn=<NllLossBackward>), tensor(0.9981, grad_fn=<NllLossBackward>), tensor(1.1752, grad_fn=<NllLossBackward>), tensor(0.8756, grad_fn=<NllLossBackward>), tensor(1.0413, grad_fn=<NllLossBackward>), tensor(0.8934, grad_fn=<NllLossBackward>), tensor(0.9744, grad_fn=<NllLossBackward>), tensor(0.6703, grad_fn=<NllLossBackward>), tensor(0.8039, grad_fn=<NllLossBackward>), tensor(0.8165, grad_fn=<NllLossBackward>), tensor(0.8865, grad_fn=<NllLossBackward>), tensor(1.0032, grad_fn=<NllLossBackward>), tensor(0.8531, grad_fn=<NllLossBackward>), tensor(1.0102, grad_fn=<NllLossBackward>), tensor(0.8960, grad_fn=<NllLossBackward>), tensor(0.7905, grad_fn=<NllLossBackward>), tensor(0.7988, grad_fn=<NllLossBackward>), tensor(0.9265, grad_fn=<NllLossBackward>), tensor(1.0486, grad_fn=<NllLossBackward>), tensor(0.9196, grad_fn=<NllLossBackward>), tensor(0.7221, grad_fn=<NllLossBackward>), tensor(0.9302, grad_fn=<NllLossBackward>), tensor(1.1644, grad_fn=<NllLossBackward>), tensor(0.8650, grad_fn=<NllLossBackward>), tensor(0.8795, grad_fn=<NllLossBackward>), tensor(0.9812, grad_fn=<NllLossBackward>), tensor(0.9101, grad_fn=<NllLossBackward>), tensor(0.9048, grad_fn=<NllLossBackward>), tensor(0.9477, grad_fn=<NllLossBackward>), tensor(0.8180, grad_fn=<NllLossBackward>), tensor(0.8985, grad_fn=<NllLossBackward>), tensor(0.7812, grad_fn=<NllLossBackward>), tensor(0.8934, grad_fn=<NllLossBackward>), tensor(0.8487, grad_fn=<NllLossBackward>), tensor(0.8081, grad_fn=<NllLossBackward>), tensor(0.8361, grad_fn=<NllLossBackward>), tensor(0.8072, grad_fn=<NllLossBackward>), tensor(0.8366, grad_fn=<NllLossBackward>), tensor(0.9234, grad_fn=<NllLossBackward>), tensor(0.8934, grad_fn=<NllLossBackward>), tensor(0.9257, grad_fn=<NllLossBackward>), tensor(0.8038, grad_fn=<NllLossBackward>), tensor(1.2147, grad_fn=<NllLossBackward>), tensor(1.0568, grad_fn=<NllLossBackward>), tensor(1.0293, grad_fn=<NllLossBackward>), tensor(0.9047, grad_fn=<NllLossBackward>), tensor(0.9230, grad_fn=<NllLossBackward>), tensor(0.9505, grad_fn=<NllLossBackward>), tensor(1.0614, grad_fn=<NllLossBackward>), tensor(0.9446, grad_fn=<NllLossBackward>), tensor(0.8774, grad_fn=<NllLossBackward>), tensor(1.0629, grad_fn=<NllLossBackward>), tensor(0.9400, grad_fn=<NllLossBackward>), tensor(0.9153, grad_fn=<NllLossBackward>), tensor(0.8929, grad_fn=<NllLossBackward>), tensor(0.9067, grad_fn=<NllLossBackward>), tensor(0.8810, grad_fn=<NllLossBackward>), tensor(0.8500, grad_fn=<NllLossBackward>), tensor(1.1115, grad_fn=<NllLossBackward>), tensor(0.8186, grad_fn=<NllLossBackward>), tensor(0.9543, grad_fn=<NllLossBackward>), tensor(0.8640, grad_fn=<NllLossBackward>), tensor(0.9566, grad_fn=<NllLossBackward>), tensor(0.9102, grad_fn=<NllLossBackward>), tensor(0.7699, grad_fn=<NllLossBackward>), tensor(0.8718, grad_fn=<NllLossBackward>), tensor(0.8858, grad_fn=<NllLossBackward>), tensor(0.8647, grad_fn=<NllLossBackward>), tensor(0.9795, grad_fn=<NllLossBackward>), tensor(0.8365, grad_fn=<NllLossBackward>), tensor(1.0956, grad_fn=<NllLossBackward>), tensor(0.8591, grad_fn=<NllLossBackward>), tensor(1.0262, grad_fn=<NllLossBackward>), tensor(0.8015, grad_fn=<NllLossBackward>), tensor(1.0270, grad_fn=<NllLossBackward>), tensor(1.0599, grad_fn=<NllLossBackward>), tensor(0.7981, grad_fn=<NllLossBackward>), tensor(1.0825, grad_fn=<NllLossBackward>), tensor(1.0464, grad_fn=<NllLossBackward>), tensor(0.9327, grad_fn=<NllLossBackward>), tensor(0.9520, grad_fn=<NllLossBackward>), tensor(0.8428, grad_fn=<NllLossBackward>), tensor(0.9267, grad_fn=<NllLossBackward>), tensor(1.0748, grad_fn=<NllLossBackward>), tensor(1.0109, grad_fn=<NllLossBackward>), tensor(0.8949, grad_fn=<NllLossBackward>), tensor(0.7733, grad_fn=<NllLossBackward>), tensor(0.8507, grad_fn=<NllLossBackward>), tensor(0.9067, grad_fn=<NllLossBackward>), tensor(0.9597, grad_fn=<NllLossBackward>), tensor(0.8316, grad_fn=<NllLossBackward>), tensor(0.9340, grad_fn=<NllLossBackward>), tensor(1.1236, grad_fn=<NllLossBackward>), tensor(0.9444, grad_fn=<NllLossBackward>), tensor(0.8699, grad_fn=<NllLossBackward>), tensor(0.8422, grad_fn=<NllLossBackward>), tensor(0.8869, grad_fn=<NllLossBackward>), tensor(0.8778, grad_fn=<NllLossBackward>), tensor(0.8870, grad_fn=<NllLossBackward>), tensor(0.9526, grad_fn=<NllLossBackward>), tensor(0.8768, grad_fn=<NllLossBackward>), tensor(0.7468, grad_fn=<NllLossBackward>), tensor(0.8853, grad_fn=<NllLossBackward>), tensor(0.8659, grad_fn=<NllLossBackward>), tensor(0.9962, grad_fn=<NllLossBackward>), tensor(0.8667, grad_fn=<NllLossBackward>), tensor(0.8458, grad_fn=<NllLossBackward>), tensor(0.7821, grad_fn=<NllLossBackward>), tensor(1.1506, grad_fn=<NllLossBackward>), tensor(0.8059, grad_fn=<NllLossBackward>), tensor(0.7282, grad_fn=<NllLossBackward>), tensor(0.8890, grad_fn=<NllLossBackward>), tensor(0.8649, grad_fn=<NllLossBackward>), tensor(0.9751, grad_fn=<NllLossBackward>), tensor(0.9198, grad_fn=<NllLossBackward>), tensor(1.0256, grad_fn=<NllLossBackward>), tensor(0.8471, grad_fn=<NllLossBackward>), tensor(0.8101, grad_fn=<NllLossBackward>), tensor(0.8515, grad_fn=<NllLossBackward>), tensor(1.0387, grad_fn=<NllLossBackward>), tensor(1.0235, grad_fn=<NllLossBackward>), tensor(0.9029, grad_fn=<NllLossBackward>), tensor(0.8609, grad_fn=<NllLossBackward>), tensor(0.8522, grad_fn=<NllLossBackward>), tensor(0.8012, grad_fn=<NllLossBackward>), tensor(0.7930, grad_fn=<NllLossBackward>), tensor(0.7402, grad_fn=<NllLossBackward>), tensor(1.0307, grad_fn=<NllLossBackward>), tensor(0.8009, grad_fn=<NllLossBackward>), tensor(0.7580, grad_fn=<NllLossBackward>), tensor(1.0707, grad_fn=<NllLossBackward>), tensor(0.8742, grad_fn=<NllLossBackward>), tensor(0.8228, grad_fn=<NllLossBackward>), tensor(1.1159, grad_fn=<NllLossBackward>), tensor(0.9853, grad_fn=<NllLossBackward>), tensor(1.0418, grad_fn=<NllLossBackward>), tensor(1.0171, grad_fn=<NllLossBackward>), tensor(0.8212, grad_fn=<NllLossBackward>), tensor(0.9539, grad_fn=<NllLossBackward>), tensor(0.9666, grad_fn=<NllLossBackward>), tensor(0.9575, grad_fn=<NllLossBackward>), tensor(0.7956, grad_fn=<NllLossBackward>), tensor(0.8344, grad_fn=<NllLossBackward>), tensor(0.8030, grad_fn=<NllLossBackward>), tensor(0.9738, grad_fn=<NllLossBackward>), tensor(0.9106, grad_fn=<NllLossBackward>), tensor(0.8099, grad_fn=<NllLossBackward>), tensor(0.7467, grad_fn=<NllLossBackward>), tensor(0.9345, grad_fn=<NllLossBackward>), tensor(0.8805, grad_fn=<NllLossBackward>), tensor(0.7637, grad_fn=<NllLossBackward>), tensor(0.9757, grad_fn=<NllLossBackward>), tensor(0.7886, grad_fn=<NllLossBackward>), tensor(0.9716, grad_fn=<NllLossBackward>), tensor(1.0494, grad_fn=<NllLossBackward>), tensor(0.7688, grad_fn=<NllLossBackward>), tensor(0.9329, grad_fn=<NllLossBackward>), tensor(0.8678, grad_fn=<NllLossBackward>), tensor(0.8481, grad_fn=<NllLossBackward>), tensor(0.7936, grad_fn=<NllLossBackward>), tensor(1.0041, grad_fn=<NllLossBackward>), tensor(0.8706, grad_fn=<NllLossBackward>), tensor(1.0219, grad_fn=<NllLossBackward>), tensor(1.0475, grad_fn=<NllLossBackward>), tensor(1.1634, grad_fn=<NllLossBackward>), tensor(1.0463, grad_fn=<NllLossBackward>), tensor(0.9321, grad_fn=<NllLossBackward>), tensor(1.0638, grad_fn=<NllLossBackward>), tensor(0.7942, grad_fn=<NllLossBackward>), tensor(0.8406, grad_fn=<NllLossBackward>), tensor(0.9632, grad_fn=<NllLossBackward>), tensor(0.8097, grad_fn=<NllLossBackward>), tensor(0.9189, grad_fn=<NllLossBackward>), tensor(0.9293, grad_fn=<NllLossBackward>), tensor(0.8514, grad_fn=<NllLossBackward>), tensor(0.8446, grad_fn=<NllLossBackward>), tensor(0.8661, grad_fn=<NllLossBackward>), tensor(0.8870, grad_fn=<NllLossBackward>), tensor(0.8313, grad_fn=<NllLossBackward>), tensor(0.8433, grad_fn=<NllLossBackward>), tensor(0.7481, grad_fn=<NllLossBackward>), tensor(1.0590, grad_fn=<NllLossBackward>), tensor(0.8955, grad_fn=<NllLossBackward>), tensor(0.9290, grad_fn=<NllLossBackward>), tensor(1.0664, grad_fn=<NllLossBackward>), tensor(0.8958, grad_fn=<NllLossBackward>), tensor(0.8262, grad_fn=<NllLossBackward>), tensor(1.0659, grad_fn=<NllLossBackward>), tensor(0.8116, grad_fn=<NllLossBackward>), tensor(0.8269, grad_fn=<NllLossBackward>), tensor(0.8438, grad_fn=<NllLossBackward>), tensor(0.8693, grad_fn=<NllLossBackward>), tensor(0.8359, grad_fn=<NllLossBackward>), tensor(0.8472, grad_fn=<NllLossBackward>), tensor(0.8846, grad_fn=<NllLossBackward>), tensor(0.9958, grad_fn=<NllLossBackward>), tensor(0.9083, grad_fn=<NllLossBackward>), tensor(0.8017, grad_fn=<NllLossBackward>), tensor(0.8954, grad_fn=<NllLossBackward>), tensor(0.9566, grad_fn=<NllLossBackward>), tensor(0.7670, grad_fn=<NllLossBackward>), tensor(0.8384, grad_fn=<NllLossBackward>), tensor(0.8831, grad_fn=<NllLossBackward>), tensor(0.9875, grad_fn=<NllLossBackward>), tensor(1.0234, grad_fn=<NllLossBackward>), tensor(0.9703, grad_fn=<NllLossBackward>), tensor(0.8668, grad_fn=<NllLossBackward>), tensor(0.8226, grad_fn=<NllLossBackward>), tensor(0.8558, grad_fn=<NllLossBackward>), tensor(0.7614, grad_fn=<NllLossBackward>), tensor(0.8528, grad_fn=<NllLossBackward>), tensor(0.7814, grad_fn=<NllLossBackward>), tensor(0.7805, grad_fn=<NllLossBackward>), tensor(0.9722, grad_fn=<NllLossBackward>), tensor(0.9276, grad_fn=<NllLossBackward>), tensor(1.0489, grad_fn=<NllLossBackward>), tensor(0.9774, grad_fn=<NllLossBackward>), tensor(0.8663, grad_fn=<NllLossBackward>), tensor(0.8649, grad_fn=<NllLossBackward>), tensor(0.9638, grad_fn=<NllLossBackward>), tensor(0.8809, grad_fn=<NllLossBackward>), tensor(0.9954, grad_fn=<NllLossBackward>), tensor(0.8773, grad_fn=<NllLossBackward>), tensor(1.1015, grad_fn=<NllLossBackward>), tensor(0.9155, grad_fn=<NllLossBackward>), tensor(1.0291, grad_fn=<NllLossBackward>), tensor(0.8084, grad_fn=<NllLossBackward>), tensor(0.8723, grad_fn=<NllLossBackward>), tensor(0.9768, grad_fn=<NllLossBackward>), tensor(0.8630, grad_fn=<NllLossBackward>), tensor(0.9218, grad_fn=<NllLossBackward>), tensor(0.9366, grad_fn=<NllLossBackward>), tensor(0.8981, grad_fn=<NllLossBackward>), tensor(0.8265, grad_fn=<NllLossBackward>), tensor(0.8063, grad_fn=<NllLossBackward>), tensor(0.8973, grad_fn=<NllLossBackward>), tensor(0.7543, grad_fn=<NllLossBackward>), tensor(0.6123, grad_fn=<NllLossBackward>), tensor(0.8505, grad_fn=<NllLossBackward>), tensor(0.9062, grad_fn=<NllLossBackward>), tensor(0.8303, grad_fn=<NllLossBackward>), tensor(0.7453, grad_fn=<NllLossBackward>), tensor(0.8052, grad_fn=<NllLossBackward>), tensor(0.9095, grad_fn=<NllLossBackward>), tensor(0.9269, grad_fn=<NllLossBackward>), tensor(1.0433, grad_fn=<NllLossBackward>), tensor(1.1111, grad_fn=<NllLossBackward>), tensor(0.9137, grad_fn=<NllLossBackward>), tensor(0.9487, grad_fn=<NllLossBackward>), tensor(0.9313, grad_fn=<NllLossBackward>), tensor(1.0660, grad_fn=<NllLossBackward>), tensor(0.9106, grad_fn=<NllLossBackward>), tensor(0.8112, grad_fn=<NllLossBackward>), tensor(0.9605, grad_fn=<NllLossBackward>), tensor(1.0250, grad_fn=<NllLossBackward>), tensor(1.1030, grad_fn=<NllLossBackward>), tensor(0.8800, grad_fn=<NllLossBackward>), tensor(0.7844, grad_fn=<NllLossBackward>), tensor(0.9381, grad_fn=<NllLossBackward>), tensor(1.0764, grad_fn=<NllLossBackward>), tensor(0.8628, grad_fn=<NllLossBackward>), tensor(0.7310, grad_fn=<NllLossBackward>), tensor(0.9074, grad_fn=<NllLossBackward>), tensor(0.9256, grad_fn=<NllLossBackward>), tensor(0.8658, grad_fn=<NllLossBackward>), tensor(0.9950, grad_fn=<NllLossBackward>), tensor(0.7515, grad_fn=<NllLossBackward>), tensor(0.9663, grad_fn=<NllLossBackward>), tensor(0.8410, grad_fn=<NllLossBackward>), tensor(0.9538, grad_fn=<NllLossBackward>), tensor(0.9363, grad_fn=<NllLossBackward>), tensor(0.7473, grad_fn=<NllLossBackward>), tensor(0.8026, grad_fn=<NllLossBackward>), tensor(0.9825, grad_fn=<NllLossBackward>), tensor(0.9852, grad_fn=<NllLossBackward>), tensor(0.7177, grad_fn=<NllLossBackward>), tensor(1.1265, grad_fn=<NllLossBackward>), tensor(0.9468, grad_fn=<NllLossBackward>), tensor(0.9898, grad_fn=<NllLossBackward>), tensor(1.0718, grad_fn=<NllLossBackward>), tensor(0.9530, grad_fn=<NllLossBackward>), tensor(0.7981, grad_fn=<NllLossBackward>), tensor(1.0085, grad_fn=<NllLossBackward>), tensor(0.8277, grad_fn=<NllLossBackward>), tensor(0.8520, grad_fn=<NllLossBackward>), tensor(0.8861, grad_fn=<NllLossBackward>), tensor(0.8644, grad_fn=<NllLossBackward>), tensor(0.8722, grad_fn=<NllLossBackward>), tensor(0.8421, grad_fn=<NllLossBackward>), tensor(1.0133, grad_fn=<NllLossBackward>), tensor(0.9128, grad_fn=<NllLossBackward>), tensor(0.9175, grad_fn=<NllLossBackward>), tensor(0.9207, grad_fn=<NllLossBackward>), tensor(0.8519, grad_fn=<NllLossBackward>), tensor(0.9993, grad_fn=<NllLossBackward>), tensor(0.8244, grad_fn=<NllLossBackward>), tensor(0.8882, grad_fn=<NllLossBackward>), tensor(0.8345, grad_fn=<NllLossBackward>), tensor(0.8745, grad_fn=<NllLossBackward>), tensor(0.9908, grad_fn=<NllLossBackward>), tensor(0.7331, grad_fn=<NllLossBackward>), tensor(0.7949, grad_fn=<NllLossBackward>), tensor(0.8470, grad_fn=<NllLossBackward>), tensor(0.9278, grad_fn=<NllLossBackward>), tensor(0.8783, grad_fn=<NllLossBackward>), tensor(0.8533, grad_fn=<NllLossBackward>), tensor(0.9308, grad_fn=<NllLossBackward>), tensor(0.9383, grad_fn=<NllLossBackward>), tensor(1.0610, grad_fn=<NllLossBackward>), tensor(0.8338, grad_fn=<NllLossBackward>), tensor(0.8970, grad_fn=<NllLossBackward>), tensor(0.7967, grad_fn=<NllLossBackward>), tensor(0.9302, grad_fn=<NllLossBackward>), tensor(0.7097, grad_fn=<NllLossBackward>), tensor(0.8956, grad_fn=<NllLossBackward>), tensor(0.9396, grad_fn=<NllLossBackward>), tensor(1.0828, grad_fn=<NllLossBackward>), tensor(0.8201, grad_fn=<NllLossBackward>), tensor(0.9407, grad_fn=<NllLossBackward>), tensor(0.8491, grad_fn=<NllLossBackward>), tensor(0.8277, grad_fn=<NllLossBackward>), tensor(0.7821, grad_fn=<NllLossBackward>), tensor(0.9307, grad_fn=<NllLossBackward>), tensor(0.9476, grad_fn=<NllLossBackward>), tensor(0.8494, grad_fn=<NllLossBackward>), tensor(0.8893, grad_fn=<NllLossBackward>), tensor(0.8918, grad_fn=<NllLossBackward>), tensor(0.7732, grad_fn=<NllLossBackward>), tensor(0.8136, grad_fn=<NllLossBackward>), tensor(0.9989, grad_fn=<NllLossBackward>), tensor(1.0104, grad_fn=<NllLossBackward>), tensor(1.0118, grad_fn=<NllLossBackward>), tensor(0.7897, grad_fn=<NllLossBackward>), tensor(1.0062, grad_fn=<NllLossBackward>), tensor(0.9337, grad_fn=<NllLossBackward>), tensor(0.9147, grad_fn=<NllLossBackward>), tensor(1.0320, grad_fn=<NllLossBackward>), tensor(1.0238, grad_fn=<NllLossBackward>), tensor(0.9118, grad_fn=<NllLossBackward>), tensor(0.7303, grad_fn=<NllLossBackward>), tensor(0.8524, grad_fn=<NllLossBackward>), tensor(0.8783, grad_fn=<NllLossBackward>), tensor(0.8125, grad_fn=<NllLossBackward>), tensor(0.9233, grad_fn=<NllLossBackward>), tensor(0.8971, grad_fn=<NllLossBackward>), tensor(0.7773, grad_fn=<NllLossBackward>), tensor(0.8818, grad_fn=<NllLossBackward>), tensor(0.7802, grad_fn=<NllLossBackward>), tensor(0.8941, grad_fn=<NllLossBackward>), tensor(0.7979, grad_fn=<NllLossBackward>), tensor(0.9457, grad_fn=<NllLossBackward>), tensor(1.1470, grad_fn=<NllLossBackward>), tensor(0.8554, grad_fn=<NllLossBackward>), tensor(0.6866, grad_fn=<NllLossBackward>), tensor(0.9405, grad_fn=<NllLossBackward>), tensor(0.8835, grad_fn=<NllLossBackward>), tensor(0.9056, grad_fn=<NllLossBackward>), tensor(0.7522, grad_fn=<NllLossBackward>), tensor(0.7992, grad_fn=<NllLossBackward>), tensor(0.9373, grad_fn=<NllLossBackward>), tensor(0.9027, grad_fn=<NllLossBackward>), tensor(1.0425, grad_fn=<NllLossBackward>), tensor(0.8597, grad_fn=<NllLossBackward>), tensor(0.7841, grad_fn=<NllLossBackward>), tensor(0.9774, grad_fn=<NllLossBackward>), tensor(0.8475, grad_fn=<NllLossBackward>), tensor(1.0474, grad_fn=<NllLossBackward>), tensor(0.7923, grad_fn=<NllLossBackward>), tensor(0.8562, grad_fn=<NllLossBackward>), tensor(0.9646, grad_fn=<NllLossBackward>), tensor(0.8356, grad_fn=<NllLossBackward>), tensor(0.6805, grad_fn=<NllLossBackward>), tensor(0.9055, grad_fn=<NllLossBackward>), tensor(0.8545, grad_fn=<NllLossBackward>), tensor(0.8312, grad_fn=<NllLossBackward>), tensor(0.8722, grad_fn=<NllLossBackward>), tensor(0.9059, grad_fn=<NllLossBackward>), tensor(0.7621, grad_fn=<NllLossBackward>), tensor(0.9609, grad_fn=<NllLossBackward>), tensor(0.8391, grad_fn=<NllLossBackward>), tensor(0.9689, grad_fn=<NllLossBackward>), tensor(0.8556, grad_fn=<NllLossBackward>), tensor(0.8268, grad_fn=<NllLossBackward>), tensor(0.9253, grad_fn=<NllLossBackward>), tensor(0.8797, grad_fn=<NllLossBackward>), tensor(1.0157, grad_fn=<NllLossBackward>), tensor(0.8077, grad_fn=<NllLossBackward>), tensor(0.9510, grad_fn=<NllLossBackward>), tensor(0.9208, grad_fn=<NllLossBackward>), tensor(0.8065, grad_fn=<NllLossBackward>), tensor(1.0652, grad_fn=<NllLossBackward>), tensor(0.9486, grad_fn=<NllLossBackward>), tensor(0.9915, grad_fn=<NllLossBackward>), tensor(0.9635, grad_fn=<NllLossBackward>), tensor(1.0161, grad_fn=<NllLossBackward>), tensor(0.9121, grad_fn=<NllLossBackward>), tensor(0.9419, grad_fn=<NllLossBackward>), tensor(0.8234, grad_fn=<NllLossBackward>), tensor(0.8735, grad_fn=<NllLossBackward>), tensor(0.8789, grad_fn=<NllLossBackward>), tensor(0.8107, grad_fn=<NllLossBackward>), tensor(0.9723, grad_fn=<NllLossBackward>), tensor(0.9827, grad_fn=<NllLossBackward>), tensor(1.1385, grad_fn=<NllLossBackward>), tensor(0.9304, grad_fn=<NllLossBackward>), tensor(0.9527, grad_fn=<NllLossBackward>), tensor(0.8333, grad_fn=<NllLossBackward>), tensor(0.8887, grad_fn=<NllLossBackward>), tensor(0.6722, grad_fn=<NllLossBackward>), tensor(0.9488, grad_fn=<NllLossBackward>), tensor(0.8039, grad_fn=<NllLossBackward>), tensor(0.9672, grad_fn=<NllLossBackward>), tensor(0.8906, grad_fn=<NllLossBackward>), tensor(0.8747, grad_fn=<NllLossBackward>), tensor(0.9255, grad_fn=<NllLossBackward>), tensor(0.9693, grad_fn=<NllLossBackward>), tensor(0.7241, grad_fn=<NllLossBackward>), tensor(0.8537, grad_fn=<NllLossBackward>), tensor(0.6636, grad_fn=<NllLossBackward>), tensor(0.7552, grad_fn=<NllLossBackward>), tensor(0.8684, grad_fn=<NllLossBackward>), tensor(0.9473, grad_fn=<NllLossBackward>), tensor(0.7713, grad_fn=<NllLossBackward>), tensor(1.0917, grad_fn=<NllLossBackward>), tensor(1.0705, grad_fn=<NllLossBackward>), tensor(0.9127, grad_fn=<NllLossBackward>), tensor(0.8534, grad_fn=<NllLossBackward>), tensor(0.8362, grad_fn=<NllLossBackward>), tensor(0.9123, grad_fn=<NllLossBackward>), tensor(0.9236, grad_fn=<NllLossBackward>), tensor(0.9021, grad_fn=<NllLossBackward>), tensor(0.8628, grad_fn=<NllLossBackward>), tensor(0.9729, grad_fn=<NllLossBackward>), tensor(0.8442, grad_fn=<NllLossBackward>), tensor(0.7277, grad_fn=<NllLossBackward>), tensor(0.9387, grad_fn=<NllLossBackward>), tensor(0.7900, grad_fn=<NllLossBackward>), tensor(1.0266, grad_fn=<NllLossBackward>), tensor(1.0465, grad_fn=<NllLossBackward>), tensor(0.8830, grad_fn=<NllLossBackward>), tensor(0.9724, grad_fn=<NllLossBackward>), tensor(0.9391, grad_fn=<NllLossBackward>), tensor(0.7769, grad_fn=<NllLossBackward>), tensor(0.8744, grad_fn=<NllLossBackward>), tensor(0.8225, grad_fn=<NllLossBackward>), tensor(0.8957, grad_fn=<NllLossBackward>), tensor(0.9317, grad_fn=<NllLossBackward>), tensor(1.0086, grad_fn=<NllLossBackward>), tensor(0.9295, grad_fn=<NllLossBackward>), tensor(0.9221, grad_fn=<NllLossBackward>), tensor(0.9028, grad_fn=<NllLossBackward>), tensor(0.7976, grad_fn=<NllLossBackward>), tensor(0.8817, grad_fn=<NllLossBackward>), tensor(0.8912, grad_fn=<NllLossBackward>), tensor(0.8816, grad_fn=<NllLossBackward>), tensor(0.9984, grad_fn=<NllLossBackward>), tensor(0.8546, grad_fn=<NllLossBackward>), tensor(1.0615, grad_fn=<NllLossBackward>), tensor(0.9101, grad_fn=<NllLossBackward>), tensor(0.7939, grad_fn=<NllLossBackward>), tensor(0.8991, grad_fn=<NllLossBackward>), tensor(0.8710, grad_fn=<NllLossBackward>), tensor(1.0994, grad_fn=<NllLossBackward>), tensor(1.0171, grad_fn=<NllLossBackward>), tensor(0.8455, grad_fn=<NllLossBackward>), tensor(0.9555, grad_fn=<NllLossBackward>), tensor(0.9869, grad_fn=<NllLossBackward>), tensor(0.9299, grad_fn=<NllLossBackward>), tensor(0.8310, grad_fn=<NllLossBackward>), tensor(0.9497, grad_fn=<NllLossBackward>), tensor(1.0322, grad_fn=<NllLossBackward>), tensor(0.7119, grad_fn=<NllLossBackward>), tensor(0.6989, grad_fn=<NllLossBackward>), tensor(0.6959, grad_fn=<NllLossBackward>), tensor(0.7482, grad_fn=<NllLossBackward>), tensor(0.9285, grad_fn=<NllLossBackward>), tensor(0.6495, grad_fn=<NllLossBackward>), tensor(0.7764, grad_fn=<NllLossBackward>), tensor(0.8891, grad_fn=<NllLossBackward>), tensor(0.9762, grad_fn=<NllLossBackward>), tensor(0.8038, grad_fn=<NllLossBackward>), tensor(0.7421, grad_fn=<NllLossBackward>), tensor(0.7059, grad_fn=<NllLossBackward>), tensor(0.8295, grad_fn=<NllLossBackward>), tensor(0.8371, grad_fn=<NllLossBackward>), tensor(1.0252, grad_fn=<NllLossBackward>), tensor(0.7972, grad_fn=<NllLossBackward>), tensor(0.7270, grad_fn=<NllLossBackward>), tensor(0.8896, grad_fn=<NllLossBackward>), tensor(0.8068, grad_fn=<NllLossBackward>), tensor(0.9343, grad_fn=<NllLossBackward>), tensor(0.8621, grad_fn=<NllLossBackward>), tensor(0.9009, grad_fn=<NllLossBackward>), tensor(1.0348, grad_fn=<NllLossBackward>), tensor(0.8265, grad_fn=<NllLossBackward>), tensor(1.0518, grad_fn=<NllLossBackward>), tensor(0.8763, grad_fn=<NllLossBackward>), tensor(0.7321, grad_fn=<NllLossBackward>), tensor(0.9302, grad_fn=<NllLossBackward>), tensor(0.7205, grad_fn=<NllLossBackward>), tensor(0.9511, grad_fn=<NllLossBackward>), tensor(0.8597, grad_fn=<NllLossBackward>), tensor(0.9077, grad_fn=<NllLossBackward>), tensor(0.8705, grad_fn=<NllLossBackward>), tensor(1.0865, grad_fn=<NllLossBackward>), tensor(0.9379, grad_fn=<NllLossBackward>), tensor(0.8513, grad_fn=<NllLossBackward>), tensor(0.7996, grad_fn=<NllLossBackward>), tensor(0.8270, grad_fn=<NllLossBackward>), tensor(0.6617, grad_fn=<NllLossBackward>), tensor(0.8625, grad_fn=<NllLossBackward>), tensor(0.9501, grad_fn=<NllLossBackward>), tensor(0.8872, grad_fn=<NllLossBackward>), tensor(0.7417, grad_fn=<NllLossBackward>), tensor(0.7987, grad_fn=<NllLossBackward>), tensor(0.8445, grad_fn=<NllLossBackward>), tensor(0.8950, grad_fn=<NllLossBackward>), tensor(0.7986, grad_fn=<NllLossBackward>), tensor(0.9110, grad_fn=<NllLossBackward>), tensor(1.0316, grad_fn=<NllLossBackward>), tensor(0.9339, grad_fn=<NllLossBackward>), tensor(0.8643, grad_fn=<NllLossBackward>), tensor(0.9690, grad_fn=<NllLossBackward>), tensor(0.9667, grad_fn=<NllLossBackward>), tensor(1.0391, grad_fn=<NllLossBackward>), tensor(1.0020, grad_fn=<NllLossBackward>), tensor(0.9293, grad_fn=<NllLossBackward>), tensor(0.9838, grad_fn=<NllLossBackward>), tensor(1.0383, grad_fn=<NllLossBackward>), tensor(0.7490, grad_fn=<NllLossBackward>), tensor(0.8903, grad_fn=<NllLossBackward>), tensor(0.9359, grad_fn=<NllLossBackward>), tensor(0.7789, grad_fn=<NllLossBackward>), tensor(0.7190, grad_fn=<NllLossBackward>), tensor(1.0048, grad_fn=<NllLossBackward>), tensor(0.6703, grad_fn=<NllLossBackward>), tensor(0.9002, grad_fn=<NllLossBackward>), tensor(1.0077, grad_fn=<NllLossBackward>), tensor(0.9030, grad_fn=<NllLossBackward>), tensor(1.0188, grad_fn=<NllLossBackward>), tensor(0.9019, grad_fn=<NllLossBackward>), tensor(0.9231, grad_fn=<NllLossBackward>), tensor(0.9487, grad_fn=<NllLossBackward>), tensor(0.9262, grad_fn=<NllLossBackward>), tensor(0.9928, grad_fn=<NllLossBackward>), tensor(1.0815, grad_fn=<NllLossBackward>), tensor(0.9492, grad_fn=<NllLossBackward>), tensor(1.0046, grad_fn=<NllLossBackward>), tensor(0.7791, grad_fn=<NllLossBackward>), tensor(0.9175, grad_fn=<NllLossBackward>), tensor(0.7843, grad_fn=<NllLossBackward>), tensor(0.9678, grad_fn=<NllLossBackward>), tensor(0.9776, grad_fn=<NllLossBackward>), tensor(1.1058, grad_fn=<NllLossBackward>), tensor(0.7860, grad_fn=<NllLossBackward>), tensor(0.6691, grad_fn=<NllLossBackward>), tensor(0.9856, grad_fn=<NllLossBackward>), tensor(0.9657, grad_fn=<NllLossBackward>), tensor(0.7868, grad_fn=<NllLossBackward>), tensor(0.7236, grad_fn=<NllLossBackward>), tensor(0.9457, grad_fn=<NllLossBackward>), tensor(0.9656, grad_fn=<NllLossBackward>), tensor(0.8496, grad_fn=<NllLossBackward>), tensor(0.9294, grad_fn=<NllLossBackward>), tensor(1.1563, grad_fn=<NllLossBackward>), tensor(1.0354, grad_fn=<NllLossBackward>), tensor(0.8178, grad_fn=<NllLossBackward>), tensor(0.9486, grad_fn=<NllLossBackward>), tensor(0.9308, grad_fn=<NllLossBackward>), tensor(0.9100, grad_fn=<NllLossBackward>), tensor(0.9021, grad_fn=<NllLossBackward>), tensor(0.9382, grad_fn=<NllLossBackward>), tensor(0.9656, grad_fn=<NllLossBackward>), tensor(0.9550, grad_fn=<NllLossBackward>), tensor(0.9287, grad_fn=<NllLossBackward>), tensor(0.8457, grad_fn=<NllLossBackward>), tensor(0.7724, grad_fn=<NllLossBackward>), tensor(0.8283, grad_fn=<NllLossBackward>), tensor(0.8678, grad_fn=<NllLossBackward>), tensor(1.0510, grad_fn=<NllLossBackward>), tensor(0.8896, grad_fn=<NllLossBackward>), tensor(0.8011, grad_fn=<NllLossBackward>), tensor(0.6939, grad_fn=<NllLossBackward>), tensor(0.9325, grad_fn=<NllLossBackward>), tensor(0.8642, grad_fn=<NllLossBackward>), tensor(0.8779, grad_fn=<NllLossBackward>), tensor(0.7232, grad_fn=<NllLossBackward>), tensor(0.8392, grad_fn=<NllLossBackward>), tensor(0.8526, grad_fn=<NllLossBackward>), tensor(0.8877, grad_fn=<NllLossBackward>), tensor(0.9541, grad_fn=<NllLossBackward>), tensor(0.9753, grad_fn=<NllLossBackward>), tensor(1.1603, grad_fn=<NllLossBackward>), tensor(0.9183, grad_fn=<NllLossBackward>), tensor(0.8472, grad_fn=<NllLossBackward>), tensor(0.8514, grad_fn=<NllLossBackward>), tensor(0.9316, grad_fn=<NllLossBackward>), tensor(0.8282, grad_fn=<NllLossBackward>), tensor(1.0041, grad_fn=<NllLossBackward>), tensor(0.9506, grad_fn=<NllLossBackward>), tensor(0.8502, grad_fn=<NllLossBackward>), tensor(0.8519, grad_fn=<NllLossBackward>), tensor(0.7996, grad_fn=<NllLossBackward>), tensor(0.8526, grad_fn=<NllLossBackward>), tensor(1.1038, grad_fn=<NllLossBackward>), tensor(0.9740, grad_fn=<NllLossBackward>), tensor(0.7830, grad_fn=<NllLossBackward>), tensor(0.9634, grad_fn=<NllLossBackward>), tensor(0.7686, grad_fn=<NllLossBackward>), tensor(0.7250, grad_fn=<NllLossBackward>), tensor(0.9331, grad_fn=<NllLossBackward>), tensor(0.7842, grad_fn=<NllLossBackward>), tensor(0.9371, grad_fn=<NllLossBackward>), tensor(0.8047, grad_fn=<NllLossBackward>), tensor(0.9347, grad_fn=<NllLossBackward>), tensor(0.9454, grad_fn=<NllLossBackward>), tensor(1.0114, grad_fn=<NllLossBackward>), tensor(0.9600, grad_fn=<NllLossBackward>), tensor(0.9775, grad_fn=<NllLossBackward>), tensor(0.9681, grad_fn=<NllLossBackward>), tensor(0.8633, grad_fn=<NllLossBackward>), tensor(0.7906, grad_fn=<NllLossBackward>), tensor(0.8682, grad_fn=<NllLossBackward>), tensor(0.8337, grad_fn=<NllLossBackward>), tensor(0.9358, grad_fn=<NllLossBackward>), tensor(0.9649, grad_fn=<NllLossBackward>), tensor(0.9829, grad_fn=<NllLossBackward>), tensor(0.9639, grad_fn=<NllLossBackward>), tensor(0.9411, grad_fn=<NllLossBackward>), tensor(1.0181, grad_fn=<NllLossBackward>), tensor(0.8867, grad_fn=<NllLossBackward>), tensor(0.9287, grad_fn=<NllLossBackward>), tensor(1.0288, grad_fn=<NllLossBackward>), tensor(1.0160, grad_fn=<NllLossBackward>), tensor(0.9021, grad_fn=<NllLossBackward>), tensor(0.9665, grad_fn=<NllLossBackward>), tensor(0.7839, grad_fn=<NllLossBackward>), tensor(0.8872, grad_fn=<NllLossBackward>), tensor(0.9802, grad_fn=<NllLossBackward>), tensor(0.8434, grad_fn=<NllLossBackward>), tensor(1.0741, grad_fn=<NllLossBackward>), tensor(0.9461, grad_fn=<NllLossBackward>), tensor(0.8619, grad_fn=<NllLossBackward>), tensor(0.8962, grad_fn=<NllLossBackward>), tensor(0.9181, grad_fn=<NllLossBackward>), tensor(1.0238, grad_fn=<NllLossBackward>), tensor(0.7545, grad_fn=<NllLossBackward>), tensor(0.9874, grad_fn=<NllLossBackward>), tensor(0.7253, grad_fn=<NllLossBackward>), tensor(0.8827, grad_fn=<NllLossBackward>), tensor(0.8377, grad_fn=<NllLossBackward>), tensor(0.7578, grad_fn=<NllLossBackward>), tensor(0.7950, grad_fn=<NllLossBackward>), tensor(0.7990, grad_fn=<NllLossBackward>), tensor(1.0533, grad_fn=<NllLossBackward>), tensor(0.8647, grad_fn=<NllLossBackward>), tensor(0.8837, grad_fn=<NllLossBackward>), tensor(0.8780, grad_fn=<NllLossBackward>), tensor(0.9916, grad_fn=<NllLossBackward>), tensor(0.9494, grad_fn=<NllLossBackward>), tensor(0.7671, grad_fn=<NllLossBackward>), tensor(1.1167, grad_fn=<NllLossBackward>), tensor(0.9340, grad_fn=<NllLossBackward>), tensor(0.7864, grad_fn=<NllLossBackward>), tensor(1.0008, grad_fn=<NllLossBackward>), tensor(0.9701, grad_fn=<NllLossBackward>), tensor(0.9948, grad_fn=<NllLossBackward>), tensor(0.8080, grad_fn=<NllLossBackward>), tensor(0.8149, grad_fn=<NllLossBackward>), tensor(0.7840, grad_fn=<NllLossBackward>), tensor(1.0882, grad_fn=<NllLossBackward>), tensor(0.6715, grad_fn=<NllLossBackward>), tensor(1.0095, grad_fn=<NllLossBackward>), tensor(1.0377, grad_fn=<NllLossBackward>), tensor(0.8787, grad_fn=<NllLossBackward>), tensor(0.9631, grad_fn=<NllLossBackward>), tensor(0.9075, grad_fn=<NllLossBackward>), tensor(0.8313, grad_fn=<NllLossBackward>), tensor(0.6936, grad_fn=<NllLossBackward>), tensor(0.8506, grad_fn=<NllLossBackward>), tensor(0.8736, grad_fn=<NllLossBackward>), tensor(0.9614, grad_fn=<NllLossBackward>), tensor(0.8869, grad_fn=<NllLossBackward>), tensor(0.9119, grad_fn=<NllLossBackward>), tensor(1.1059, grad_fn=<NllLossBackward>), tensor(0.8670, grad_fn=<NllLossBackward>), tensor(0.9361, grad_fn=<NllLossBackward>), tensor(0.9630, grad_fn=<NllLossBackward>), tensor(0.9752, grad_fn=<NllLossBackward>), tensor(1.0002, grad_fn=<NllLossBackward>), tensor(0.7990, grad_fn=<NllLossBackward>), tensor(0.8296, grad_fn=<NllLossBackward>), tensor(1.0429, grad_fn=<NllLossBackward>), tensor(1.0405, grad_fn=<NllLossBackward>), tensor(0.6340, grad_fn=<NllLossBackward>), tensor(0.8020, grad_fn=<NllLossBackward>), tensor(1.0758, grad_fn=<NllLossBackward>), tensor(1.0497, grad_fn=<NllLossBackward>), tensor(0.8975, grad_fn=<NllLossBackward>), tensor(0.8981, grad_fn=<NllLossBackward>), tensor(0.8306, grad_fn=<NllLossBackward>), tensor(0.9596, grad_fn=<NllLossBackward>), tensor(1.0795, grad_fn=<NllLossBackward>), tensor(0.9712, grad_fn=<NllLossBackward>), tensor(1.0517, grad_fn=<NllLossBackward>), tensor(0.7736, grad_fn=<NllLossBackward>), tensor(0.8580, grad_fn=<NllLossBackward>), tensor(0.8068, grad_fn=<NllLossBackward>), tensor(0.8865, grad_fn=<NllLossBackward>), tensor(0.9711, grad_fn=<NllLossBackward>), tensor(0.8854, grad_fn=<NllLossBackward>), tensor(0.8137, grad_fn=<NllLossBackward>), tensor(0.8547, grad_fn=<NllLossBackward>), tensor(0.7271, grad_fn=<NllLossBackward>), tensor(0.8213, grad_fn=<NllLossBackward>), tensor(0.8967, grad_fn=<NllLossBackward>), tensor(0.9754, grad_fn=<NllLossBackward>), tensor(0.7113, grad_fn=<NllLossBackward>), tensor(0.8330, grad_fn=<NllLossBackward>), tensor(0.8736, grad_fn=<NllLossBackward>), tensor(0.8244, grad_fn=<NllLossBackward>), tensor(0.9641, grad_fn=<NllLossBackward>), tensor(1.0676, grad_fn=<NllLossBackward>), tensor(1.0179, grad_fn=<NllLossBackward>), tensor(0.8907, grad_fn=<NllLossBackward>), tensor(0.8427, grad_fn=<NllLossBackward>), tensor(0.9874, grad_fn=<NllLossBackward>), tensor(0.8819, grad_fn=<NllLossBackward>), tensor(1.2427, grad_fn=<NllLossBackward>), tensor(0.9754, grad_fn=<NllLossBackward>), tensor(0.9302, grad_fn=<NllLossBackward>), tensor(0.9726, grad_fn=<NllLossBackward>), tensor(0.9132, grad_fn=<NllLossBackward>), tensor(0.8154, grad_fn=<NllLossBackward>), tensor(1.0745, grad_fn=<NllLossBackward>), tensor(0.7763, grad_fn=<NllLossBackward>), tensor(0.8648, grad_fn=<NllLossBackward>), tensor(0.8668, grad_fn=<NllLossBackward>), tensor(0.9546, grad_fn=<NllLossBackward>), tensor(0.8690, grad_fn=<NllLossBackward>), tensor(0.7738, grad_fn=<NllLossBackward>), tensor(0.9741, grad_fn=<NllLossBackward>), tensor(0.8333, grad_fn=<NllLossBackward>), tensor(0.7537, grad_fn=<NllLossBackward>), tensor(0.8153, grad_fn=<NllLossBackward>), tensor(0.9984, grad_fn=<NllLossBackward>), tensor(0.7693, grad_fn=<NllLossBackward>), tensor(0.9503, grad_fn=<NllLossBackward>), tensor(1.0003, grad_fn=<NllLossBackward>), tensor(0.8309, grad_fn=<NllLossBackward>), tensor(0.8217, grad_fn=<NllLossBackward>), tensor(0.9270, grad_fn=<NllLossBackward>), tensor(0.8810, grad_fn=<NllLossBackward>), tensor(1.1250, grad_fn=<NllLossBackward>), tensor(0.7914, grad_fn=<NllLossBackward>), tensor(0.9813, grad_fn=<NllLossBackward>), tensor(0.8674, grad_fn=<NllLossBackward>), tensor(0.8124, grad_fn=<NllLossBackward>), tensor(0.9107, grad_fn=<NllLossBackward>), tensor(1.0879, grad_fn=<NllLossBackward>), tensor(0.9504, grad_fn=<NllLossBackward>), tensor(0.9215, grad_fn=<NllLossBackward>), tensor(0.9780, grad_fn=<NllLossBackward>), tensor(0.7892, grad_fn=<NllLossBackward>), tensor(0.9769, grad_fn=<NllLossBackward>), tensor(1.0303, grad_fn=<NllLossBackward>), tensor(0.8223, grad_fn=<NllLossBackward>), tensor(0.6938, grad_fn=<NllLossBackward>), tensor(0.9264, grad_fn=<NllLossBackward>), tensor(0.9452, grad_fn=<NllLossBackward>), tensor(1.1259, grad_fn=<NllLossBackward>), tensor(0.7941, grad_fn=<NllLossBackward>), tensor(0.8799, grad_fn=<NllLossBackward>), tensor(0.8338, grad_fn=<NllLossBackward>), tensor(0.9465, grad_fn=<NllLossBackward>), tensor(0.8822, grad_fn=<NllLossBackward>), tensor(1.0287, grad_fn=<NllLossBackward>), tensor(1.1128, grad_fn=<NllLossBackward>), tensor(0.6533, grad_fn=<NllLossBackward>), tensor(0.8664, grad_fn=<NllLossBackward>), tensor(0.9639, grad_fn=<NllLossBackward>), tensor(0.9032, grad_fn=<NllLossBackward>), tensor(0.8109, grad_fn=<NllLossBackward>), tensor(0.8217, grad_fn=<NllLossBackward>), tensor(0.8467, grad_fn=<NllLossBackward>), tensor(0.8529, grad_fn=<NllLossBackward>), tensor(0.8378, grad_fn=<NllLossBackward>), tensor(0.9076, grad_fn=<NllLossBackward>), tensor(0.9502, grad_fn=<NllLossBackward>), tensor(0.8980, grad_fn=<NllLossBackward>), tensor(0.9590, grad_fn=<NllLossBackward>), tensor(0.8821, grad_fn=<NllLossBackward>), tensor(0.9437, grad_fn=<NllLossBackward>), tensor(0.9251, grad_fn=<NllLossBackward>), tensor(0.8552, grad_fn=<NllLossBackward>), tensor(0.9037, grad_fn=<NllLossBackward>), tensor(1.0527, grad_fn=<NllLossBackward>), tensor(0.9067, grad_fn=<NllLossBackward>), tensor(0.8773, grad_fn=<NllLossBackward>), tensor(0.9894, grad_fn=<NllLossBackward>), tensor(0.9289, grad_fn=<NllLossBackward>), tensor(0.8567, grad_fn=<NllLossBackward>), tensor(1.0463, grad_fn=<NllLossBackward>), tensor(1.0092, grad_fn=<NllLossBackward>), tensor(0.9646, grad_fn=<NllLossBackward>), tensor(0.8720, grad_fn=<NllLossBackward>), tensor(0.9377, grad_fn=<NllLossBackward>), tensor(0.8679, grad_fn=<NllLossBackward>), tensor(0.9268, grad_fn=<NllLossBackward>), tensor(1.0042, grad_fn=<NllLossBackward>), tensor(0.9665, grad_fn=<NllLossBackward>), tensor(0.9266, grad_fn=<NllLossBackward>), tensor(0.9217, grad_fn=<NllLossBackward>), tensor(0.7263, grad_fn=<NllLossBackward>), tensor(0.7948, grad_fn=<NllLossBackward>), tensor(0.8747, grad_fn=<NllLossBackward>), tensor(0.8950, grad_fn=<NllLossBackward>), tensor(0.9552, grad_fn=<NllLossBackward>), tensor(0.8407, grad_fn=<NllLossBackward>), tensor(1.0647, grad_fn=<NllLossBackward>), tensor(0.8673, grad_fn=<NllLossBackward>), tensor(0.9069, grad_fn=<NllLossBackward>), tensor(0.7801, grad_fn=<NllLossBackward>), tensor(1.0135, grad_fn=<NllLossBackward>), tensor(0.8900, grad_fn=<NllLossBackward>), tensor(0.7970, grad_fn=<NllLossBackward>), tensor(0.9366, grad_fn=<NllLossBackward>), tensor(0.8776, grad_fn=<NllLossBackward>), tensor(0.9767, grad_fn=<NllLossBackward>), tensor(0.8523, grad_fn=<NllLossBackward>), tensor(0.8805, grad_fn=<NllLossBackward>), tensor(0.9277, grad_fn=<NllLossBackward>), tensor(0.9646, grad_fn=<NllLossBackward>), tensor(0.9316, grad_fn=<NllLossBackward>), tensor(1.0018, grad_fn=<NllLossBackward>), tensor(1.0140, grad_fn=<NllLossBackward>), tensor(0.8776, grad_fn=<NllLossBackward>), tensor(1.0135, grad_fn=<NllLossBackward>), tensor(0.9218, grad_fn=<NllLossBackward>), tensor(1.0281, grad_fn=<NllLossBackward>), tensor(0.7880, grad_fn=<NllLossBackward>), tensor(0.8532, grad_fn=<NllLossBackward>), tensor(0.8777, grad_fn=<NllLossBackward>), tensor(0.8438, grad_fn=<NllLossBackward>), tensor(0.9180, grad_fn=<NllLossBackward>), tensor(0.9158, grad_fn=<NllLossBackward>), tensor(1.0680, grad_fn=<NllLossBackward>), tensor(0.8280, grad_fn=<NllLossBackward>), tensor(0.7654, grad_fn=<NllLossBackward>), tensor(0.9635, grad_fn=<NllLossBackward>), tensor(0.9582, grad_fn=<NllLossBackward>), tensor(0.7457, grad_fn=<NllLossBackward>), tensor(0.8819, grad_fn=<NllLossBackward>), tensor(0.9291, grad_fn=<NllLossBackward>), tensor(0.9622, grad_fn=<NllLossBackward>), tensor(0.7643, grad_fn=<NllLossBackward>), tensor(0.9377, grad_fn=<NllLossBackward>), tensor(0.7777, grad_fn=<NllLossBackward>), tensor(0.9232, grad_fn=<NllLossBackward>), tensor(0.9315, grad_fn=<NllLossBackward>), tensor(0.8251, grad_fn=<NllLossBackward>), tensor(1.0070, grad_fn=<NllLossBackward>), tensor(0.9764, grad_fn=<NllLossBackward>), tensor(0.8056, grad_fn=<NllLossBackward>), tensor(0.8780, grad_fn=<NllLossBackward>), tensor(1.0558, grad_fn=<NllLossBackward>), tensor(0.9102, grad_fn=<NllLossBackward>), tensor(0.8467, grad_fn=<NllLossBackward>), tensor(0.9546, grad_fn=<NllLossBackward>), tensor(0.8454, grad_fn=<NllLossBackward>), tensor(0.9412, grad_fn=<NllLossBackward>), tensor(0.7856, grad_fn=<NllLossBackward>), tensor(1.0555, grad_fn=<NllLossBackward>), tensor(0.9323, grad_fn=<NllLossBackward>), tensor(0.7797, grad_fn=<NllLossBackward>), tensor(0.7382, grad_fn=<NllLossBackward>), tensor(0.9999, grad_fn=<NllLossBackward>), tensor(0.9249, grad_fn=<NllLossBackward>), tensor(0.8702, grad_fn=<NllLossBackward>), tensor(1.0159, grad_fn=<NllLossBackward>), tensor(0.7728, grad_fn=<NllLossBackward>), tensor(0.8906, grad_fn=<NllLossBackward>), tensor(1.0672, grad_fn=<NllLossBackward>), tensor(0.9469, grad_fn=<NllLossBackward>), tensor(0.9698, grad_fn=<NllLossBackward>), tensor(0.9875, grad_fn=<NllLossBackward>), tensor(1.0708, grad_fn=<NllLossBackward>), tensor(0.9312, grad_fn=<NllLossBackward>), tensor(0.6923, grad_fn=<NllLossBackward>), tensor(0.9394, grad_fn=<NllLossBackward>), tensor(0.9741, grad_fn=<NllLossBackward>), tensor(0.9589, grad_fn=<NllLossBackward>), tensor(0.8846, grad_fn=<NllLossBackward>), tensor(0.8625, grad_fn=<NllLossBackward>), tensor(0.8603, grad_fn=<NllLossBackward>), tensor(0.8244, grad_fn=<NllLossBackward>), tensor(0.7858, grad_fn=<NllLossBackward>), tensor(0.9287, grad_fn=<NllLossBackward>), tensor(0.9731, grad_fn=<NllLossBackward>), tensor(0.9864, grad_fn=<NllLossBackward>), tensor(0.9920, grad_fn=<NllLossBackward>), tensor(0.8559, grad_fn=<NllLossBackward>), tensor(0.8318, grad_fn=<NllLossBackward>), tensor(0.9593, grad_fn=<NllLossBackward>), tensor(0.8977, grad_fn=<NllLossBackward>), tensor(0.8236, grad_fn=<NllLossBackward>), tensor(0.6730, grad_fn=<NllLossBackward>), tensor(1.0029, grad_fn=<NllLossBackward>), tensor(0.8987, grad_fn=<NllLossBackward>), tensor(1.0997, grad_fn=<NllLossBackward>), tensor(0.9828, grad_fn=<NllLossBackward>), tensor(0.8556, grad_fn=<NllLossBackward>), tensor(0.9678, grad_fn=<NllLossBackward>), tensor(0.9382, grad_fn=<NllLossBackward>), tensor(0.8662, grad_fn=<NllLossBackward>), tensor(0.8265, grad_fn=<NllLossBackward>), tensor(0.7439, grad_fn=<NllLossBackward>), tensor(0.8431, grad_fn=<NllLossBackward>), tensor(0.8502, grad_fn=<NllLossBackward>), tensor(0.8411, grad_fn=<NllLossBackward>), tensor(0.9126, grad_fn=<NllLossBackward>), tensor(0.8119, grad_fn=<NllLossBackward>), tensor(1.0781, grad_fn=<NllLossBackward>), tensor(0.8413, grad_fn=<NllLossBackward>), tensor(1.0762, grad_fn=<NllLossBackward>), tensor(1.0283, grad_fn=<NllLossBackward>), tensor(0.9361, grad_fn=<NllLossBackward>), tensor(0.9676, grad_fn=<NllLossBackward>), tensor(1.0803, grad_fn=<NllLossBackward>), tensor(0.9428, grad_fn=<NllLossBackward>), tensor(1.0200, grad_fn=<NllLossBackward>), tensor(1.0592, grad_fn=<NllLossBackward>), tensor(0.7635, grad_fn=<NllLossBackward>), tensor(0.7776, grad_fn=<NllLossBackward>), tensor(0.9546, grad_fn=<NllLossBackward>), tensor(0.9934, grad_fn=<NllLossBackward>), tensor(0.8254, grad_fn=<NllLossBackward>), tensor(0.7728, grad_fn=<NllLossBackward>), tensor(1.0293, grad_fn=<NllLossBackward>), tensor(0.9325, grad_fn=<NllLossBackward>), tensor(0.7935, grad_fn=<NllLossBackward>), tensor(0.9417, grad_fn=<NllLossBackward>), tensor(0.8419, grad_fn=<NllLossBackward>), tensor(0.8612, grad_fn=<NllLossBackward>), tensor(0.8711, grad_fn=<NllLossBackward>), tensor(1.0603, grad_fn=<NllLossBackward>), tensor(0.8981, grad_fn=<NllLossBackward>), tensor(0.7630, grad_fn=<NllLossBackward>), tensor(0.9555, grad_fn=<NllLossBackward>), tensor(0.8398, grad_fn=<NllLossBackward>), tensor(0.9434, grad_fn=<NllLossBackward>), tensor(0.8836, grad_fn=<NllLossBackward>), tensor(0.9033, grad_fn=<NllLossBackward>), tensor(0.8678, grad_fn=<NllLossBackward>), tensor(1.0042, grad_fn=<NllLossBackward>), tensor(0.9209, grad_fn=<NllLossBackward>), tensor(0.9878, grad_fn=<NllLossBackward>), tensor(0.9996, grad_fn=<NllLossBackward>), tensor(0.8187, grad_fn=<NllLossBackward>), tensor(0.9234, grad_fn=<NllLossBackward>), tensor(0.8676, grad_fn=<NllLossBackward>), tensor(1.0126, grad_fn=<NllLossBackward>), tensor(0.8742, grad_fn=<NllLossBackward>), tensor(0.8357, grad_fn=<NllLossBackward>), tensor(0.7359, grad_fn=<NllLossBackward>), tensor(0.8478, grad_fn=<NllLossBackward>), tensor(0.8044, grad_fn=<NllLossBackward>), tensor(0.8104, grad_fn=<NllLossBackward>), tensor(0.9529, grad_fn=<NllLossBackward>), tensor(1.0505, grad_fn=<NllLossBackward>), tensor(0.8006, grad_fn=<NllLossBackward>), tensor(1.0372, grad_fn=<NllLossBackward>), tensor(1.0082, grad_fn=<NllLossBackward>), tensor(0.9053, grad_fn=<NllLossBackward>), tensor(0.8789, grad_fn=<NllLossBackward>), tensor(1.1297, grad_fn=<NllLossBackward>), tensor(0.7669, grad_fn=<NllLossBackward>), tensor(0.9739, grad_fn=<NllLossBackward>), tensor(0.9421, grad_fn=<NllLossBackward>), tensor(0.8064, grad_fn=<NllLossBackward>), tensor(0.9668, grad_fn=<NllLossBackward>), tensor(0.7113, grad_fn=<NllLossBackward>), tensor(0.9770, grad_fn=<NllLossBackward>), tensor(0.9282, grad_fn=<NllLossBackward>), tensor(0.8024, grad_fn=<NllLossBackward>), tensor(0.9463, grad_fn=<NllLossBackward>), tensor(1.1068, grad_fn=<NllLossBackward>), tensor(0.9680, grad_fn=<NllLossBackward>), tensor(0.9394, grad_fn=<NllLossBackward>), tensor(0.9183, grad_fn=<NllLossBackward>), tensor(0.8367, grad_fn=<NllLossBackward>), tensor(0.7452, grad_fn=<NllLossBackward>), tensor(0.8351, grad_fn=<NllLossBackward>), tensor(0.7469, grad_fn=<NllLossBackward>), tensor(0.7103, grad_fn=<NllLossBackward>), tensor(0.7782, grad_fn=<NllLossBackward>), tensor(0.9038, grad_fn=<NllLossBackward>), tensor(0.8522, grad_fn=<NllLossBackward>), tensor(1.0059, grad_fn=<NllLossBackward>), tensor(0.8145, grad_fn=<NllLossBackward>), tensor(0.9518, grad_fn=<NllLossBackward>), tensor(0.6955, grad_fn=<NllLossBackward>), tensor(1.0382, grad_fn=<NllLossBackward>), tensor(0.6911, grad_fn=<NllLossBackward>), tensor(0.7793, grad_fn=<NllLossBackward>), tensor(0.7722, grad_fn=<NllLossBackward>), tensor(0.8519, grad_fn=<NllLossBackward>), tensor(0.8350, grad_fn=<NllLossBackward>), tensor(0.9574, grad_fn=<NllLossBackward>), tensor(0.9008, grad_fn=<NllLossBackward>), tensor(0.8006, grad_fn=<NllLossBackward>), tensor(0.8114, grad_fn=<NllLossBackward>), tensor(0.8244, grad_fn=<NllLossBackward>), tensor(0.8070, grad_fn=<NllLossBackward>), tensor(1.0344, grad_fn=<NllLossBackward>), tensor(0.9345, grad_fn=<NllLossBackward>), tensor(0.8591, grad_fn=<NllLossBackward>), tensor(0.9196, grad_fn=<NllLossBackward>), tensor(0.7018, grad_fn=<NllLossBackward>), tensor(0.8775, grad_fn=<NllLossBackward>), tensor(0.6689, grad_fn=<NllLossBackward>), tensor(0.6690, grad_fn=<NllLossBackward>), tensor(0.8748, grad_fn=<NllLossBackward>), tensor(0.7569, grad_fn=<NllLossBackward>), tensor(0.9842, grad_fn=<NllLossBackward>), tensor(0.4425, grad_fn=<NllLossBackward>)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "i1U_bchkmwUB"
      },
      "source": [
        "### Напишите цикл валидации\n",
        "Что он должен в себя включать:\n",
        "1. Получение предсказаний модели\n",
        "1. Расчет функции потерь\n",
        "1. Записывание значения лосса\n",
        "\n",
        "Также с помощью контекста ```with torch.no_grad():``` можно явно указать торчу не сохранять необходимые параметры для расчета градиентов. Обязательно для режима предсказания."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wgva1lKmwUC",
        "outputId": "ccc5ab25-e65b-4c54-f7a1-52a5fca334d0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "losses = list()\n",
        "\n",
        "# это переводит модель в режим предсказания\n",
        "# то есть фиксируются статистики батч норма, дропаут не выкидывает фичи\n",
        "model.eval()\n",
        "\n",
        "# заметьте, что мы поменяли наш лоадер на валидационный\n",
        "for x, y in valid_loader:\n",
        "    \n",
        "    with torch.no_grad():\n",
        "        # получение предсказаний модели\n",
        "        # расчет лосса\n",
        "        prediction = model.forward(x)\n",
        "        soft_pred = torch.softmax(prediction, dim=-1)\n",
        "        loss = criterion(soft_pred, y)\n",
        "        losses.append(loss)\n",
        "print(f\"Validation loss: {loss}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Validation loss: 1.64153254032135\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0ZJ7BOS8tPfw",
        "outputId": "e5cd8a62-b233-45a3-cd23-066facd0581e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(losses)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[tensor(1.5998), tensor(1.5964), tensor(1.6334), tensor(1.7022), tensor(1.6320), tensor(1.6187), tensor(1.6254), tensor(1.6774), tensor(1.6107), tensor(1.6250), tensor(1.5697), tensor(1.6126), tensor(1.5893), tensor(1.6721), tensor(1.6163), tensor(1.6124), tensor(1.6897), tensor(1.6053), tensor(1.6464), tensor(1.6765), tensor(1.6763), tensor(1.5916), tensor(1.6280), tensor(1.6227), tensor(1.6573), tensor(1.6653), tensor(1.6887), tensor(1.6624), tensor(1.6985), tensor(1.6531), tensor(1.6218), tensor(1.6491), tensor(1.6612), tensor(1.6744), tensor(1.6394), tensor(1.6899), tensor(1.7193), tensor(1.6749), tensor(1.6213), tensor(1.6562), tensor(1.6666), tensor(1.6583), tensor(1.6209), tensor(1.7025), tensor(1.6226), tensor(1.6880), tensor(1.6352), tensor(1.6961), tensor(1.6774), tensor(1.6508), tensor(1.6921), tensor(1.6533), tensor(1.6665), tensor(1.6394), tensor(1.6392), tensor(1.5897), tensor(1.6425), tensor(1.6405), tensor(1.6861), tensor(1.6372), tensor(1.7351), tensor(1.6501), tensor(1.6382), tensor(1.6476), tensor(1.6678), tensor(1.6356), tensor(1.6771), tensor(1.6531), tensor(1.6619), tensor(1.6217), tensor(1.5851), tensor(1.6233), tensor(1.6109), tensor(1.6237), tensor(1.6801), tensor(1.6254), tensor(1.6546), tensor(1.6719), tensor(1.6808), tensor(1.6617), tensor(1.6467), tensor(1.6453), tensor(1.6440), tensor(1.6632), tensor(1.6102), tensor(1.6477), tensor(1.6571), tensor(1.6485), tensor(1.6602), tensor(1.7298), tensor(1.6435), tensor(1.6099), tensor(1.6368), tensor(1.6567), tensor(1.6239), tensor(1.6302), tensor(1.6667), tensor(1.5954), tensor(1.6340), tensor(1.6153), tensor(1.5823), tensor(1.6254), tensor(1.5976), tensor(1.6310), tensor(1.6424), tensor(1.6419), tensor(1.6346), tensor(1.6696), tensor(1.6049), tensor(1.6922), tensor(1.6565), tensor(1.6403), tensor(1.5977), tensor(1.6810), tensor(1.6683), tensor(1.6822), tensor(1.6499), tensor(1.6763), tensor(1.6538), tensor(1.5926), tensor(1.6375), tensor(1.6199), tensor(1.6655), tensor(1.6318), tensor(1.6367), tensor(1.6072), tensor(1.6907), tensor(1.6928), tensor(1.6759), tensor(1.5693), tensor(1.6839), tensor(1.7243), tensor(1.6266), tensor(1.6341), tensor(1.5704), tensor(1.7118), tensor(1.7340), tensor(1.6958), tensor(1.6477), tensor(1.6270), tensor(1.6414), tensor(1.6565), tensor(1.6287), tensor(1.5994), tensor(1.6309), tensor(1.6481), tensor(1.6705), tensor(1.6676), tensor(1.6862), tensor(1.6416), tensor(1.6695), tensor(1.6503), tensor(1.6539), tensor(1.6275), tensor(1.6175), tensor(1.6648), tensor(1.6563), tensor(1.6389), tensor(1.6406), tensor(1.6715), tensor(1.5857), tensor(1.6465), tensor(1.6656), tensor(1.6501), tensor(1.6384), tensor(1.6931), tensor(1.6539), tensor(1.6714), tensor(1.6182), tensor(1.6461), tensor(1.6834), tensor(1.6500), tensor(1.6052), tensor(1.6527), tensor(1.6726), tensor(1.6753), tensor(1.6227), tensor(1.6616), tensor(1.6460), tensor(1.6161), tensor(1.6459), tensor(1.6384), tensor(1.6758), tensor(1.6474), tensor(1.6431), tensor(1.6594), tensor(1.6586), tensor(1.7040), tensor(1.7165), tensor(1.6943), tensor(1.6552), tensor(1.6865), tensor(1.6137), tensor(1.6963), tensor(1.7039), tensor(1.5954), tensor(1.6781), tensor(1.6807), tensor(1.6542), tensor(1.6299), tensor(1.6194), tensor(1.6128), tensor(1.6408), tensor(1.6634), tensor(1.6043), tensor(1.6683), tensor(1.6662), tensor(1.6880), tensor(1.6199), tensor(1.6423), tensor(1.6841), tensor(1.6927), tensor(1.6498), tensor(1.6320), tensor(1.5953), tensor(1.6586), tensor(1.6111), tensor(1.6530), tensor(1.6379), tensor(1.6301), tensor(1.6096), tensor(1.6335), tensor(1.6525), tensor(1.6003), tensor(1.6302), tensor(1.6406), tensor(1.6056), tensor(1.5839), tensor(1.6270), tensor(1.7018), tensor(1.6794), tensor(1.6470), tensor(1.6894), tensor(1.6954), tensor(1.6130), tensor(1.6489), tensor(1.6227), tensor(1.6221), tensor(1.6772), tensor(1.6743), tensor(1.6244), tensor(1.6407), tensor(1.6392), tensor(1.6502), tensor(1.6277), tensor(1.6903), tensor(1.6710), tensor(1.6193), tensor(1.6365), tensor(1.6808), tensor(1.6974), tensor(1.6647), tensor(1.6170), tensor(1.6385), tensor(1.6613), tensor(1.7077), tensor(1.6150), tensor(1.6429), tensor(1.6690), tensor(1.6316), tensor(1.6716), tensor(1.6314), tensor(1.6348), tensor(1.6907), tensor(1.6656), tensor(1.6270), tensor(1.6091), tensor(1.6163), tensor(1.6328), tensor(1.6246), tensor(1.6368), tensor(1.6675), tensor(1.6747), tensor(1.6114), tensor(1.6505), tensor(1.6672), tensor(1.6323), tensor(1.6231), tensor(1.6911), tensor(1.6737), tensor(1.6598), tensor(1.6409), tensor(1.6339), tensor(1.6318), tensor(1.6337), tensor(1.6255), tensor(1.6693), tensor(1.7067), tensor(1.6400), tensor(1.5954), tensor(1.6404), tensor(1.6858), tensor(1.6499), tensor(1.6504), tensor(1.6417), tensor(1.6755), tensor(1.6316), tensor(1.6863), tensor(1.6310), tensor(1.6908), tensor(1.6891), tensor(1.6587), tensor(1.6269), tensor(1.6486), tensor(1.6597), tensor(1.6223), tensor(1.6067), tensor(1.6480), tensor(1.6740), tensor(1.6744), tensor(1.6343), tensor(1.6315), tensor(1.6122), tensor(1.6914), tensor(1.6005), tensor(1.6165), tensor(1.6447), tensor(1.6476), tensor(1.6258), tensor(1.6425), tensor(1.6405), tensor(1.6257), tensor(1.6384), tensor(1.5658), tensor(1.6920), tensor(1.6580), tensor(1.6466), tensor(1.6691), tensor(1.6839), tensor(1.6450), tensor(1.6521), tensor(1.6453), tensor(1.6503), tensor(1.6233), tensor(1.7135), tensor(1.6524), tensor(1.6330), tensor(1.6420), tensor(1.6466), tensor(1.6715), tensor(1.6172), tensor(1.6133), tensor(1.6647), tensor(1.6113), tensor(1.6346), tensor(1.6782), tensor(1.6426), tensor(1.6947), tensor(1.6222), tensor(1.6599), tensor(1.6923), tensor(1.6101), tensor(1.6402), tensor(1.6200), tensor(1.6390), tensor(1.6143), tensor(1.6479), tensor(1.6599), tensor(1.6354), tensor(1.5994), tensor(1.6715), tensor(1.6709), tensor(1.6637), tensor(1.6152), tensor(1.6367), tensor(1.6403), tensor(1.6640), tensor(1.6398), tensor(1.6851), tensor(1.6712), tensor(1.6663), tensor(1.6626), tensor(1.6826), tensor(1.6046), tensor(1.6306), tensor(1.6607), tensor(1.6113), tensor(1.6522), tensor(1.6757), tensor(1.6077), tensor(1.6568), tensor(1.6743), tensor(1.6315), tensor(1.6611), tensor(1.6737), tensor(1.6903), tensor(1.6958), tensor(1.6567), tensor(1.6172), tensor(1.6558), tensor(1.6415)]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol_kM9k1mwUM"
      },
      "source": [
        "### Проведите обучение несколько эпох\n",
        "Одна эпоха - это один проход по датасету.  \n",
        "Шаги:\n",
        "- Поменяйте что-нибудь в модели, добавить дропаут и тд\n",
        "- Остановите обучение с помощью early stopping\n",
        "- Добавьте расчет метрик во время обучения и предсказания (например, micro F1). Чтобы это сделать вы можете, например, сохранять предсказания модели\n",
        "- После обучения нарисуйте как по мере обучения меняется функция потерь на тренировочном и валидационном датасете, как меняется метрики\n",
        "- Опционально: постройте confusion matrix\n",
        "\n",
        "Подсказки:\n",
        "- Чтобы корректно сохранять предсказания нужно переменную отсоединить от графа, то есть сделать ```x.detach()```"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "K-SXhpIM2S8t"
      },
      "source": [
        "!pip install pytorch_lightning\n",
        "from pytorch_lightning.callbacks.early_stopping import EarlyStopping"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8BbyH5Ag1Oda"
      },
      "source": [
        "class DeepAverageNetwork(nn.Module):\n",
        "    \n",
        "    def __init__(self, embeddings, linear_1_size, linear_2_size, n_classes, loss):\n",
        "        super().__init__()\n",
        "        self.log('train_loss', loss)\n",
        "        self.embedding_layer = nn.Embedding.from_pretrained(embeddings, padding_idx=0)\n",
        "        self.dropout = nn.Dropout(p=0.1)\n",
        "        self.batch_norm = nn.BatchNorm1d(num_features=embeddings.shape[-1])\n",
        "        self.linear_1 = nn.Linear(in_features=embeddings.shape[-1], out_features=linear_1_size)\n",
        "        self.linear_2 = nn.Linear(in_features=linear_1_size, out_features=linear_2_size)\n",
        "        self.linear_3 = nn.Linear(in_features=linear_2_size, out_features=n_classes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.embedding_layer(x)\n",
        "        x = x.sum(dim=1)\n",
        "        x = self.batch_norm(x)\n",
        "        x = self.linear_1(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.linear_2(x)\n",
        "        x = torch.relu(x)\n",
        "        x = self.linear_3(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yB_6hGEhmwUO"
      },
      "source": [
        "losses = list()\n",
        "trainer = Trainer(callbacks=[EarlyStopping(monitor='val_loss')])\n",
        "model.train()\n",
        "for n_epoch in range(2):\n",
        "  for x, y in train_loader:\n",
        "    prediction = model.forward(x)\n",
        "    loss = criterion(prediction, y)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    optimizer.zero_grad()\n",
        "    losses.append(loss)\n",
        "  print(f\"Train loss: {loss}\")\n",
        "  for x, y in valid_loader:\n",
        "    with torch.no_grad():\n",
        "      prediction = model.forward(x)\n",
        "      soft_pred = torch.softmax(prediction, dim=-1)\n",
        "      loss = criterion(soft_pred, y)\n",
        "      losses.append(loss)\n",
        "  print(f\"Validation loss: {loss}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5renhj2mwUT"
      },
      "source": [
        "### Важные и не очень интуитивные моменты про LSTM и CNN в торче"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XmrM4ZJmmwUU"
      },
      "source": [
        "По умолчанию LSTM принимает данные с такой размерностью:\n",
        "```python\n",
        "(seq_len, batch, input_size)\n",
        "```\n",
        "Сделано это с целью оптимизации на более низком уровне.  \n",
        "Мы оперируем такими объектами:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "Чтобы LSTM у нас заработала правильно, мы можем либо передать параметр ```batch_first=True``` во время инициализации слоя,\n",
        "либо транспонировать (поменять) первую и вторую размерность у нашего x перед подачей в слой.  \n",
        "[Подробнее про LSTM](https://pytorch.org/docs/stable/nn.html#lstm)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orDn0foymwUV"
      },
      "source": [
        "- 128 - размер батча\n",
        "- 64 - длина последовательности (количество слов)\n",
        "- 1024 - эмбеддинг слова"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAfL-HX5mwUW"
      },
      "source": [
        "x = torch.rand(128, 64, 1024)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SN5XNWgTmwUc"
      },
      "source": [
        "# первый способ\n",
        "lstm = torch.nn.LSTM(1024, 512, batch_first=True)\n",
        "\n",
        "pred, mem = lstm(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "36fzFo1KmwUh"
      },
      "source": [
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iDUskIK_mwUm"
      },
      "source": [
        "# второй способ\n",
        "lstm = torch.nn.LSTM(1024, 512)\n",
        "\n",
        "# меняем размерность batch и seq_len местами\n",
        "x_transposed = x.transpose(0, 1)\n",
        "pred_transposed, mem = lstm(x_transposed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ntjtdkMVmwUw"
      },
      "source": [
        "# у нас все еще осталась размерность (seq_len, batch, input_size)\n",
        "pred_transposed.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdJu3uRemwU1"
      },
      "source": [
        "# просто транспонируем еще раз\n",
        "pred = pred_transposed.transpose(0, 1)\n",
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4mxfZg8PmwU6"
      },
      "source": [
        "### Conv1d & MaxPool1d\n",
        "Примерно такая же ситуация происходит со сверточными слоями и пулингами.  \n",
        "1d реализация как раз для текстов, в ней матрица-фильтр ходит только по одной размерности.  \n",
        "[Подробнее про CNN](https://pytorch.org/docs/stable/nn.html#conv1d)  \n",
        "[Подробнее про пулинг](https://pytorch.org/docs/stable/nn.html#maxpool1d)  \n",
        "Ожидается такая размерность:\n",
        "```python\n",
        "(batch, input_size, seq_len)\n",
        "```\n",
        "Мы все еще хоти подавать такую размерность:\n",
        "```python\n",
        "(batch, seq_len, input_size)\n",
        "```\n",
        "В случае со свертками и пулингами у нас есть вариант только транспонировать x перед подачей и транспонировать полученный результат. Обратите внимание, что транспонируем мы первую и вторую размерность (индексация с нуля)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QHNejHyvmwU7"
      },
      "source": [
        "x.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LfCzYVHbmwVB"
      },
      "source": [
        "# in_channels - размер входных эмбеддингов\n",
        "# out_channels - количество/какой размер эмбеддингов мы хотим получить\n",
        "# kernel_size - размер окна/н-граммы\n",
        "cnn = torch.nn.Conv1d(in_channels=1024, out_channels=512, kernel_size=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2vJAwFoTmwVG"
      },
      "source": [
        "# выпадет ошибка, посмотрите какая\n",
        "# pred = cnn(x)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DVHgByh2mwVV"
      },
      "source": [
        "x_transposed = x.transpose(1, 2)\n",
        "x_transposed.shape\n",
        "# перевели в (batch, input_size, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MulbXtNemwVb"
      },
      "source": [
        "pred_transposed = cnn(x_transposed)\n",
        "pred_transposed.shape\n",
        "# осталась разрмерность (batch, output_size, seq_len)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLnUJz9tmwVn"
      },
      "source": [
        "# переведем обратно в (batch, seq_len, input_size)\n",
        "pred = pred_transposed.transpose(1, 2)\n",
        "pred.shape"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qsrsvOlUmwVt"
      },
      "source": [
        "### Еще важный момент про LSTM\n",
        "\n",
        "The input can also be a packed variable length sequence. See [torch.nn.utils.rnn.pack_padded_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence) or [torch.nn.utils.rnn.pack_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence) for details.\n",
        "\n",
        "Это внутренняя конструкция торча, которая позволяет не читать токен ```PAD```, но все еще работать с батчами. То есть внутри батча мы можем передать лстмке, что у нас данные переменной длины. Не забудьте что на выход отдается [torch.nn.utils.rnn.PackedSequence](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.PackedSequence)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PkL1r6VGmwVw"
      },
      "source": [
        "## Домашнее задание\n",
        "\n",
        "1. Сделать класс нейронки, вписать необходимые операции, архитектура ниже\n",
        "1. Написать обучалку (обобщить то, что было выше)\n",
        "1. Добавить логирование\n",
        "    1. Сохранять лосс на каждой итерции обучения __0.25 балла__\n",
        "    1. Каждую эпоху сохранять лосс трейна и тест __0.25 балла__\n",
        "    1. Каждую эпоху рассчитывать метрики __0.25 балла__\n",
        "    1. Добавить прогресс бар, в котором показывается усредненный лосс последних 500-та итераций __0.25 балла__\n",
        "1. Добавить early stopping __0.5 балла__\n",
        "1. Нарисовать графики лосса, метрик, конфьюжин матрицу __0.5 балла__\n",
        "\n",
        "\n",
        "### Архитектура (что можно попробовать)\n",
        "1. Предобученные эмбеддинги. Почитайте [здесь](https://pytorch.org/docs/stable/nn.html#embedding) (from_pretrained) как вставить свои эмбеддинги, выше мы читали матрицу эмбеддингов. __0 баллов__\n",
        "1. Дообучить эмбеддинги отдельно от сети. __2 балла__\n",
        "1. Дообучить эмбеддинги вместе с сетью и с другим learning rate (указывается в оптимизаторе). __2 балла__\n",
        "1. Bidirectional LSTM. __1 балл__\n",
        "1. Несколько параллельных CNN с разными размерами окна и mean/max over time пулингами к ним и дальнейшей конкатенацией. __2 балла__\n",
        "1. Несколько последовательных CNN. __1 балла__\n",
        "1. Разные окна и residual к предыдущему пункту. __2 балла__\n",
        "1. Предыдущий пункт сделан без ошибок (замаскированы свертки паддингов). __2 балла__\n",
        "1. Написать правильный правильный mean/max пулинг, который не учитывает паддинги, точнее их маскирует. __2 балла__\n",
        "1. Добавить [torch.nn.utils.rnn.pack_padded_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_padded_sequence) и [torch.nn.utils.rnn.pack_sequence()](https://pytorch.org/docs/stable/nn.html#torch.nn.utils.rnn.pack_sequence) для LSTM. Инфа [здесь](#Еще-важный-момент-про-LSTM) __2 балла__\n",
        "1. Добавить spatial дропаут для входа LSTM (не просто стандартный пункт при инициализации LSTM) __1 балл__\n",
        "1. Добавить BatchNorm/LayerNorm/Dropout/Residual/etc __1 балл__\n",
        "1. Добавить шедуллер __1 балл__\n",
        "1. Обучать на GPU __2 балла__\n",
        "1. Сделать transfer learning с собственно обученной языковой модели, обученной на любых данных, например, unlabeled. __7 баллов__\n",
        "1. your madness\n",
        "\n",
        "## 10 баллов максимум\n",
        "\n",
        "# По итогам напишите результаты экспериментов\n",
        "# Что получилось, а что нет\n",
        "# Почему, выводы"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICEx-xAomwVx"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}