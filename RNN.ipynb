{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "RNN.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyNJdh/wzW1wnmNSk01bjCyD",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Compling/blob/master/RNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "08qLj9RGYuqr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "9fb8ba78-41ec-4d00-8d6a-5c41c46fd426"
      },
      "source": [
        "import nltk\n",
        "nltk.download('treebank')"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]   Package treebank is already up-to-date!\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBGFvZZTZa_Z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tagged_sentences = nltk.corpus.treebank.tagged_sents()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yRn9XJ8lZf3_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "db03180c-2037-4a58-d6cc-c020ae4b1b26"
      },
      "source": [
        "tagged_sentences[0]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Pierre', 'NNP'),\n",
              " ('Vinken', 'NNP'),\n",
              " (',', ','),\n",
              " ('61', 'CD'),\n",
              " ('years', 'NNS'),\n",
              " ('old', 'JJ'),\n",
              " (',', ','),\n",
              " ('will', 'MD'),\n",
              " ('join', 'VB'),\n",
              " ('the', 'DT'),\n",
              " ('board', 'NN'),\n",
              " ('as', 'IN'),\n",
              " ('a', 'DT'),\n",
              " ('nonexecutive', 'JJ'),\n",
              " ('director', 'NN'),\n",
              " ('Nov.', 'NNP'),\n",
              " ('29', 'CD'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6lyNLJ-na7we",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences, sentence_tags =[], [] \n",
        "for tagged_sentence in tagged_sentences:\n",
        "    sentence, tags = zip(*tagged_sentence)\n",
        "    sentences.append(sentence)\n",
        "    sentence_tags.append(tags)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SZtg_64cbBYG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "sent_train, sent_test, tag_train, tag_test = train_test_split(sentences, sentence_tags, test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92h_CcnTeQPm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from collections import Counter, Iterable\n",
        "vocab = Counter()\n",
        "for sent in sent_train:\n",
        "    sent = [word.lower() for word in sent]\n",
        "    vocab.update(sent)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMf_oEz6fNpE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filtered_vocab = {word for word in vocab if vocab[word] > 5}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d3PPMeLIfTs7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "word2id = {'PAD':0,'UNK':1}    \n",
        "for i,word in enumerate(filtered_vocab):\n",
        "      word2id[word] = i + 2\n",
        "\n",
        "id2word = {i:word for word, i in word2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1VKbp5YefXMf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "tag2id = {'PAD':0}  \n",
        "for tags in tag_train:\n",
        "    for tag in tags:\n",
        "      if tag.lower() not in tag2id:\n",
        "        tag2id[tag.lower()] = len(tag2id)\n",
        "\n",
        "id2tag = {i:tag for tag, i in tag2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LtikhwmJZ9t3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "char2id = {'UNK': 1, 'PAD':0}\n",
        "chars = set(chain(*chain(*sent_train)))\n",
        "chars = {ch.lower() for ch in chars}\n",
        "for ch in chars:\n",
        "  if ch.lower not in char2id:\n",
        "    char2id[ch.lower()] = len(char2id)\n",
        "id2char = {i:ch for ch, i in char2id.items()}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YWRwpTz0ftO5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def data2ints(data, smth2id):\n",
        "  int_data = []\n",
        "  for seq in data:\n",
        "      int_seq = []\n",
        "      for i in seq:\n",
        "          try:\n",
        "            int_seq.append(smth2id[i.lower()])\n",
        "          except KeyError:\n",
        "            int_seq.append(smth2id['UNK'])\n",
        "  \n",
        "      int_data.append(int_seq)\n",
        "  return int_data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "87vr_yf3fxuZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_ids, X_test_ids = data2ints(sent_train, word2id), data2ints(sent_test, word2id)\n",
        "y_train_ids, y_test_ids = data2ints(tag_train, tag2id), data2ints(tag_test, tag2id)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q0oUC9qAf4Ea",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "MAX_LEN = min(max(len(x) for x in sent_train), 120)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3TPoNu-TRUE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from itertools import chain\n",
        "max_char_len = [[len(word) for word in sent] for sent in sent_train]\n",
        "max_char_len = max(chain(*max_char_len))\n",
        "max_char_len = min(max_char_len, 16)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrnRweSVLyzz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_char_train_ids = [[[char2id.get(ch.lower(), 1) for ch in word] for word in sent] for sent in sent_train]\n",
        "X_char_test_ids = [[[char2id.get(ch.lower(), 1) for ch in word] for word in sent] for sent in sent_test]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUNwx6K4IlPv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_char_train = pad_sequences([pad_sequences(ids, maxlen=max_char_len, padding='post') for ids in X_char_train_ids], maxlen=MAX_LEN, padding='post')\n",
        "X_char_test = pad_sequences([pad_sequences(ids, maxlen=max_char_len, padding='post') for ids in X_char_test_ids], maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtD46taUh1tL",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "X_train, X_test = pad_sequences(X_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(X_test_ids, maxlen=MAX_LEN, padding='post')\n",
        "y_train_pad, y_test_pad = pad_sequences(y_train_ids, maxlen=MAX_LEN, padding='post'), pad_sequences(y_test_ids, maxlen=MAX_LEN, padding='post')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nGON5Tfdi35v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.utils import to_categorical\n",
        "y_train, y_test = to_categorical(y_train_pad, num_classes=len(tag2id)), to_categorical(y_test_pad, num_classes=len(tag2id))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hZRO5PMEj6KI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Activation, Dropout, LSTM, GRU, Bidirectional, TimeDistributed, InputLayer, Embedding, Conv1D, Input, Flatten, concatenate\n",
        "from tensorflow.keras.models import Model\n",
        "model = Sequential()\n",
        "\n",
        "word_in = Input(shape=(MAX_LEN,))\n",
        "emb_word = Embedding(len(word2id), 60, mask_zero=True)(word_in)\n",
        "word_enc = Bidirectional(LSTM(256, return_sequences=True))(emb_word)\n",
        "\n",
        "char_in = Input(shape=(MAX_LEN, max_char_len))\n",
        "emb_char = TimeDistributed(Embedding(len(char2id), 8, input_length=max_char_len, mask_zero=False))(char_in)\n",
        "conv_char = TimeDistributed(Conv1D(128, 3, 1, padding='same'))(emb_char)\n",
        "flat_char = TimeDistributed(Flatten())(conv_char)\n",
        "\n",
        "x = concatenate([word_enc, flat_char])\n",
        "main_lstm = Bidirectional(LSTM(128, return_sequences=True))(x)\n",
        "out = TimeDistributed(Dense(len(tag2id), activation='softmax'))(main_lstm)\n",
        "model = Model([word_in, char_in], out)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='Adam', \n",
        "                   metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o941ZKWrGRwf",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        },
        "outputId": "7e42086f-9ef5-430e-bb32-177fee9e6363"
      },
      "source": [
        "model.fit([X_train, X_char_train], y_train, validation_data=([X_test, X_char_test], y_test), batch_size=128, epochs=20, shuffle=True)"
      ],
      "execution_count": 78,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "25/25 [==============================] - 211s 8s/step - loss: 0.6835 - accuracy: 0.0626 - val_loss: 0.6078 - val_accuracy: 0.0353\n",
            "Epoch 2/20\n",
            "25/25 [==============================] - 207s 8s/step - loss: 0.5761 - accuracy: 0.0586 - val_loss: 0.4965 - val_accuracy: 0.0760\n",
            "Epoch 3/20\n",
            "25/25 [==============================] - 211s 8s/step - loss: 0.4287 - accuracy: 0.0943 - val_loss: 0.3364 - val_accuracy: 0.1112\n",
            "Epoch 4/20\n",
            "25/25 [==============================] - 204s 8s/step - loss: 0.2798 - accuracy: 0.1339 - val_loss: 0.2229 - val_accuracy: 0.1462\n",
            "Epoch 5/20\n",
            "25/25 [==============================] - 201s 8s/step - loss: 0.1870 - accuracy: 0.1649 - val_loss: 0.1549 - val_accuracy: 0.1673\n",
            "Epoch 6/20\n",
            "25/25 [==============================] - 208s 8s/step - loss: 0.1351 - accuracy: 0.1796 - val_loss: 0.1177 - val_accuracy: 0.1783\n",
            "Epoch 7/20\n",
            "25/25 [==============================] - 207s 8s/step - loss: 0.1035 - accuracy: 0.1871 - val_loss: 0.0969 - val_accuracy: 0.1829\n",
            "Epoch 8/20\n",
            "25/25 [==============================] - 207s 8s/step - loss: 0.0865 - accuracy: 0.1911 - val_loss: 0.0840 - val_accuracy: 0.1864\n",
            "Epoch 9/20\n",
            "25/25 [==============================] - 207s 8s/step - loss: 0.0738 - accuracy: 0.1945 - val_loss: 0.0773 - val_accuracy: 0.1872\n",
            "Epoch 10/20\n",
            "25/25 [==============================] - 205s 8s/step - loss: 0.0666 - accuracy: 0.1961 - val_loss: 0.0716 - val_accuracy: 0.1884\n",
            "Epoch 11/20\n",
            "25/25 [==============================] - 212s 8s/step - loss: 0.0604 - accuracy: 0.1976 - val_loss: 0.0662 - val_accuracy: 0.1905\n",
            "Epoch 12/20\n",
            "25/25 [==============================] - 208s 8s/step - loss: 0.0549 - accuracy: 0.1993 - val_loss: 0.0622 - val_accuracy: 0.1912\n",
            "Epoch 13/20\n",
            "25/25 [==============================] - 207s 8s/step - loss: 0.0509 - accuracy: 0.2003 - val_loss: 0.0608 - val_accuracy: 0.1920\n",
            "Epoch 14/20\n",
            "25/25 [==============================] - 208s 8s/step - loss: 0.0470 - accuracy: 0.2015 - val_loss: 0.0562 - val_accuracy: 0.1933\n",
            "Epoch 15/20\n",
            "25/25 [==============================] - 198s 8s/step - loss: 0.0432 - accuracy: 0.2025 - val_loss: 0.0556 - val_accuracy: 0.1932\n",
            "Epoch 16/20\n",
            "25/25 [==============================] - 195s 8s/step - loss: 0.0399 - accuracy: 0.2036 - val_loss: 0.0523 - val_accuracy: 0.1945\n",
            "Epoch 17/20\n",
            "25/25 [==============================] - 198s 8s/step - loss: 0.0362 - accuracy: 0.2048 - val_loss: 0.0522 - val_accuracy: 0.1943\n",
            "Epoch 18/20\n",
            "25/25 [==============================] - 196s 8s/step - loss: 0.0337 - accuracy: 0.2055 - val_loss: 0.0509 - val_accuracy: 0.1945\n",
            "Epoch 19/20\n",
            "25/25 [==============================] - 201s 8s/step - loss: 0.0314 - accuracy: 0.2061 - val_loss: 0.0494 - val_accuracy: 0.1951\n",
            "Epoch 20/20\n",
            "25/25 [==============================] - 202s 8s/step - loss: 0.0291 - accuracy: 0.2068 - val_loss: 0.0483 - val_accuracy: 0.1952\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7f0797fc24a8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 78
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAK1kaURfQcG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from nltk.tokenize import word_tokenize"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3MnzafUafU1z",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tagger(sent):\n",
        "  if isinstance(sent, str):\n",
        "    sent = word_tokenize(sent)\n",
        "  if not isinstance(sent, Iterable):\n",
        "    raise TypeError('Not a string')\n",
        "  else:\n",
        "    sent_len = len(sent)\n",
        "    char_s = [[[char2id.get(char.lower(), 1) for char in word] for word in sent_p] for sent_p in [sent]]\n",
        "    char_s = pad_sequences([pad_sequences(ids, maxlen=max_char_len, padding='post') for ids in char_s], maxlen=MAX_LEN, padding='post')\n",
        "    word_s = [word2id.get(word.lower(), 1) for word in sent]\n",
        "    word_s = pad_sequences([word_s], maxlen=MAX_LEN, padding='post')\n",
        "    prediction = model.predict([word_s, char_s])\n",
        "    prediction = [id2tag[tag] for tag in np.argmax(prediction, axis=2)[0, :sent_len]]\n",
        "    return list(zip(sent, prediction))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_YS3ojLJhFC-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 697
        },
        "outputId": "22a39d75-008d-435c-f8c5-acb92372e1a8"
      },
      "source": [
        "import numpy as np\n",
        "tagger(sent_train[np.random.randint(0, len(sent_test) + 1)])"
      ],
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('The', 'dt'),\n",
              " ('Labor', 'nnp'),\n",
              " ('Department', 'nnp'),\n",
              " ('cited', 'nnp'),\n",
              " ('USX', 'nnp'),\n",
              " ('Corp.', 'nnp'),\n",
              " ('for', 'in'),\n",
              " ('numerous', 'jj'),\n",
              " ('health', 'nn'),\n",
              " ('and', 'cc'),\n",
              " ('safety', 'nn'),\n",
              " ('violations', 'nns'),\n",
              " ('at', 'in'),\n",
              " ('two', 'cd'),\n",
              " ('Pennsylvania', 'jj'),\n",
              " ('plants', 'nns'),\n",
              " (',', ','),\n",
              " ('and', 'cc'),\n",
              " ('proposed', 'vbd'),\n",
              " ('$', '$'),\n",
              " ('7.3', 'cd'),\n",
              " ('million', 'cd'),\n",
              " ('*U*', '-none-'),\n",
              " ('in', 'in'),\n",
              " ('fines', 'nns'),\n",
              " (',', ','),\n",
              " ('the', 'dt'),\n",
              " ('largest', 'jjs'),\n",
              " ('penalty', 'nn'),\n",
              " ('ever', 'rb'),\n",
              " ('proposed', 'vbn'),\n",
              " ('*', '-none-'),\n",
              " ('for', 'in'),\n",
              " ('alleged', 'vbn'),\n",
              " ('workplace', 'nn'),\n",
              " ('violations', 'nns'),\n",
              " ('by', 'in'),\n",
              " ('an', 'dt'),\n",
              " ('employer', 'nn'),\n",
              " ('.', '.')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 87
        }
      ]
    }
  ]
}