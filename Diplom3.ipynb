{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled11.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOFHYQGYKK4arw2vjE0kNSI",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Vakhranev/Compling/blob/master/Diplom3.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6Fjsy7qUP5Dr"
      },
      "source": [
        "import pandas as pd"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V15AjyLhP-XA"
      },
      "source": [
        "import numpy as np"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "flVb34q-qV-F"
      },
      "source": [
        "from google.colab import drive"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JjvEs1oPqcfy",
        "outputId": "5997d465-e83a-4516-c26b-3bcc6828825c"
      },
      "source": [
        "drive.mount('/content/drive')"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TFCc5ghEzQVA",
        "outputId": "d1f1413e-0b4c-481b-b477-ecca09af989e"
      },
      "source": [
        "!pip install pynput"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting pynput\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/f7/cb6e7edb8bb46bb38ac8c4f8065e6e3abaaef3436ecd7fe139ca5ba93c3c/pynput-1.7.3-py2.py3-none-any.whl (99kB)\n",
            "\u001b[K     |████████████████████████████████| 102kB 4.3MB/s \n",
            "\u001b[?25hCollecting python-xlib>=0.17; \"linux\" in sys_platform\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/c3/45ecfd3e6a541bb4b383fc320a32762703cfe28763c131d71f4183ace819/python_xlib-0.30-py2.py3-none-any.whl (178kB)\n",
            "\u001b[K     |████████████████████████████████| 184kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from pynput) (1.15.0)\n",
            "Collecting evdev>=1.3; \"linux\" in sys_platform\n",
            "  Downloading https://files.pythonhosted.org/packages/4d/ec/bb298d36ed67abd94293253e3e52bdf16732153b887bf08b8d6f269eacef/evdev-1.4.0.tar.gz\n",
            "Building wheels for collected packages: evdev\n",
            "  Building wheel for evdev (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for evdev: filename=evdev-1.4.0-cp37-cp37m-linux_x86_64.whl size=97415 sha256=e34e1489995e4bae0d03e782bc51c4e8e828cb0f52a604eaccc7bad4fa0c0869\n",
            "  Stored in directory: /root/.cache/pip/wheels/66/35/1d/38b2de1421ede48ebf0107faea56163d07059110b116a794a3\n",
            "Successfully built evdev\n",
            "Installing collected packages: python-xlib, evdev, pynput\n",
            "Successfully installed evdev-1.4.0 pynput-1.7.3 python-xlib-0.30\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3I4pj-0Hm_JL",
        "outputId": "e969ecae-17e3-4cf4-f06f-970e0c5ed7bf"
      },
      "source": [
        "!pip install patool"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting patool\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/43/94/52243ddff508780dd2d8110964320ab4851134a55ab102285b46e740f76a/patool-1.12-py2.py3-none-any.whl (77kB)\n",
            "\r\u001b[K     |████▎                           | 10kB 14.6MB/s eta 0:00:01\r\u001b[K     |████████▌                       | 20kB 19.4MB/s eta 0:00:01\r\u001b[K     |████████████▊                   | 30kB 11.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 40kB 8.7MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 51kB 5.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 61kB 6.5MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 71kB 6.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 81kB 4.2MB/s \n",
            "\u001b[?25hInstalling collected packages: patool\n",
            "Successfully installed patool-1.12\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kQuffDZnHau"
      },
      "source": [
        "import patoolib"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NpYKO8Hfq8Py"
      },
      "source": [
        "archive = '/content/drive/My Drive/lenta-ru-news.rar'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 103
        },
        "id": "cKGXHhrmnLEn",
        "outputId": "78e45834-160c-4b29-8664-4ff09b31630f"
      },
      "source": [
        "patoolib.extract_archive(archive)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "patool: Extracting /content/drive/My Drive/lenta-ru-news.rar ...\n",
            "patool: running /usr/bin/unrar x -- \"/content/drive/My Drive/lenta-ru-news.rar\"\n",
            "patool:     with cwd='./Unpack_sk6yvh8u'\n",
            "patool: ... /content/drive/My Drive/lenta-ru-news.rar extracted to `lenta-ru-news.csv'.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'lenta-ru-news.csv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IQfMeLOuSjVS"
      },
      "source": [
        "corpora = pd.read_csv('lenta-ru-news.csv',engine='python', error_bad_lines=False)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P4L8CwAyTlAl",
        "outputId": "57970527-d1af-4c77-912b-26f02d15385d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "corpora.head()"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>title</th>\n",
              "      <th>text</th>\n",
              "      <th>topic</th>\n",
              "      <th>tags</th>\n",
              "      <th>date</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://lenta.ru/news/1914/09/16/hungarnn/</td>\n",
              "      <td>1914. Русские войска вступили в пределы Венгрии</td>\n",
              "      <td>Бои у Сопоцкина и Друскеник закончились отступ...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://lenta.ru/news/1914/09/16/lermontov/</td>\n",
              "      <td>1914. Празднование столетия М.Ю. Лермонтова от...</td>\n",
              "      <td>Министерство народного просвещения, в виду про...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/16</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://lenta.ru/news/1914/09/17/nesteroff/</td>\n",
              "      <td>1914. Das ist Nesteroff!</td>\n",
              "      <td>Штабс-капитан П. Н. Нестеров на днях, увидев в...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://lenta.ru/news/1914/09/17/bulldogn/</td>\n",
              "      <td>1914. Бульдог-гонец под Льежем</td>\n",
              "      <td>Фотограф-корреспондент Daily Mirror рассказыва...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/17</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://lenta.ru/news/1914/09/18/zver/</td>\n",
              "      <td>1914. Под Люблином пойман швабский зверь</td>\n",
              "      <td>Лица, приехавшие в Варшаву из Люблина, передаю...</td>\n",
              "      <td>Библиотека</td>\n",
              "      <td>Первая мировая</td>\n",
              "      <td>1914/09/18</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                           url  ...        date\n",
              "0   https://lenta.ru/news/1914/09/16/hungarnn/  ...  1914/09/16\n",
              "1  https://lenta.ru/news/1914/09/16/lermontov/  ...  1914/09/16\n",
              "2  https://lenta.ru/news/1914/09/17/nesteroff/  ...  1914/09/17\n",
              "3   https://lenta.ru/news/1914/09/17/bulldogn/  ...  1914/09/17\n",
              "4       https://lenta.ru/news/1914/09/18/zver/  ...  1914/09/18\n",
              "\n",
              "[5 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DQurJOoTv5H",
        "outputId": "e958d3d6-d88f-49bf-fec5-4cd1f6cba154",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "corpora['text'].head()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    Бои у Сопоцкина и Друскеник закончились отступ...\n",
              "1    Министерство народного просвещения, в виду про...\n",
              "2    Штабс-капитан П. Н. Нестеров на днях, увидев в...\n",
              "3    Фотограф-корреспондент Daily Mirror рассказыва...\n",
              "4    Лица, приехавшие в Варшаву из Люблина, передаю...\n",
              "Name: text, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GVcrViOPWcU9"
      },
      "source": [
        "import re"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zhTN8bdSUk29",
        "outputId": "c034d499-6ccb-4efa-8ac4-073063ae5a63",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_corpora = []\n",
        "for text in corpora['text']:\n",
        "  split_regex = re.compile(r'[.|!|?|…]')\n",
        "  sentences = filter(lambda t: t, [t.strip() for t in split_regex.split(str(text))])\n",
        "  for sentence in sentences:\n",
        "    new_corpora.append(sentence)\n",
        "print(len(new_corpora))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "9233828\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qUQbnlBEYEuB",
        "outputId": "de719fb5-6d29-415f-fae7-b1d77f2044b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "new_corpora[0:10]"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Бои у Сопоцкина и Друскеник закончились отступлением германцев',\n",
              " 'Неприятель, приблизившись с севера к Осовцу начал артиллерийскую борьбу с крепостью',\n",
              " 'В артиллерийском бою принимают участие тяжелые калибры',\n",
              " 'С раннего утра 14 сентября огонь достиг значительного напряжения',\n",
              " 'Попытка германской пехоты пробиться ближе к крепости отражена',\n",
              " 'В Галиции мы заняли Дембицу',\n",
              " 'Большая колонна, отступавшая по шоссе от Перемышля к Саноку, обстреливалась с высот нашей батареей и бежала, бросив парки, обоз и автомобили',\n",
              " 'Вылазки гарнизона Перемышля остаются безуспешными',\n",
              " 'При продолжающемся отступлении австрийцев обнаруживается полное перемешивание их частей, захватываются новые партии пленных, орудия и прочая материальная часть',\n",
              " 'На перевале Ужок мы разбили неприятельский отряд, взяли его артиллерию и много пленных и, продолжая преследовать, вступили в пределы Венгрии']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bZAeU9qnqZOC",
        "outputId": "97d4d083-12ab-4892-c6c1-14c5bb3f00e4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!pip install ufal.udpipe"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting ufal.udpipe\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/72/2b8b9dc7c80017c790bb3308bbad34b57accfed2ac2f1f4ab252ff4e9cb2/ufal.udpipe-1.2.0.3.tar.gz (304kB)\n",
            "\u001b[K     |████████████████████████████████| 307kB 5.3MB/s \n",
            "\u001b[?25hBuilding wheels for collected packages: ufal.udpipe\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x70ogR4Qxn7K"
      },
      "source": [
        "!pip install wget"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Gh4aDZpixwka"
      },
      "source": [
        "import wget\n",
        "import sys\n",
        "udpipe_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
        "modelfile = wget.download(udpipe_url)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UYJ2SPs5yQ_N"
      },
      "source": [
        "def process(pipeline, text='Строка', keep_pos=True, keep_punct=False):\n",
        "   entities = {'PROPN'}\n",
        "   named = False  # переменная для запоминания того, что нам встретилось имя собственное\n",
        "   memory = []\n",
        "   mem_case = None\n",
        "   mem_number = None\n",
        "   tagged_propn = []\n",
        "# обрабатываем текст, получаем результат в формате conllu:\n",
        "   processed = pipeline.process(text)\n",
        "# пропускаем строки со служебной информацией:\n",
        "   content = [l for l in processed.split('\\n') if not l.startswith('#')]\n",
        "# извлекаем из обработанного текста леммы, тэги и морфологические характеристики\n",
        "   tagged = [w.split('\\t') for w in content if w]\n",
        "   for t in tagged:\n",
        "       if len(t) != 10: # если список короткий — строчка не содержит разбора, пропускаем\n",
        "           continue\n",
        "       (word_id,token,lemma,pos,xpos,feats,head,deprel,deps,misc) = t \n",
        "       if not lemma or not token: # если слово пустое — пропускаем\n",
        "           continue\n",
        "       if pos in entities: # здесь отдельно обрабатываем имена собственные — они требуют особого обращения\n",
        "           if '|' not in feats:\n",
        "               tagged_propn.append('%s_%s_%s_%s_%s_%s' % (word_id, token, lemma, pos, head, deprel))\n",
        "               continue\n",
        "           morph = {el.split('=')[0]: el.split('=')[1] for el in feats.split('|')}\n",
        "           if 'Case' not in morph or 'Number' not in morph:\n",
        "               tagged_propn.append('%s_%s_%s_%s_%s_%s' % (word_id, token, lemma, pos, head, deprel))\n",
        "               continue\n",
        "           if not named:\n",
        "               named = True\n",
        "               mem_case = morph['Case']\n",
        "               mem_number = morph['Number']\n",
        "           if morph['Case'] == mem_case and morph['Number'] == mem_number:\n",
        "               memory.append(lemma)\n",
        "               if 'SpacesAfter=\\\\n' in misc or 'SpacesAfter=\\s\\\\n' in misc:\n",
        "                   named = False\n",
        "                   past_lemma = '::'.join(memory)\n",
        "                   memory = []\n",
        "                   tagged_propn.append(past_lemma + '_PROPN ')\n",
        "           else:\n",
        "               named = False\n",
        "               past_lemma = '::'.join(memory)\n",
        "               memory = []\n",
        "               tagged_propn.append(past_lemma + '_PROPN ')\n",
        "               tagged_propn.append('%s_%s_%s_%s_%s_%s' % (word_id, token, lemma, pos, head, deprel))\n",
        "       else:\n",
        "           if not named:\n",
        "               tagged_propn.append('%s_%s_%s_%s_%s_%s' % (word_id, token, lemma, pos, head, deprel))\n",
        "           else:\n",
        "               named = False\n",
        "               past_lemma = '::'.join(memory)\n",
        "               memory = []\n",
        "               tagged_propn.append(past_lemma + '_PROPN ')\n",
        "               tagged_propn.append('%s_%s_%s_%s_%s_%s' % (word_id, token, lemma, pos, head, deprel))\n",
        "   if not keep_punct: # обрабатываем случай, когда пользователь попросил не сохранять пунктуацию (по умолчанию она сохраняется)\n",
        "       tagged_propn = [word for word in tagged_propn if word.split('_')[1] != 'PUNCT']\n",
        "   if not keep_pos:\n",
        "       tagged_propn = [word.split('_')[0] for word in tagged_propn]\n",
        "   return tagged_propn"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhBa9_Xozs02"
      },
      "source": [
        "from ufal.udpipe import Model, Pipeline\n",
        "import os\n",
        "import re\n",
        "def tag_ud(text='Текст нужно передать функции в виде строки!', modelfile='udpipe_syntagrus.model'):\n",
        "   udpipe_model_url = 'https://rusvectores.org/static/models/udpipe_syntagrus.model'\n",
        "   udpipe_filename = udpipe_model_url.split('/')[-1]\n",
        "   if not os.path.isfile(modelfile):\n",
        "       print('UDPipe model not found. Downloading...', file=sys.stderr)\n",
        "       wget.download(udpipe_model_url)\n",
        "   #print('\\nLoading the model...', file=sys.stderr)\n",
        "   model = Model.load(modelfile)\n",
        "   process_pipeline = Pipeline(model, 'tokenize', Pipeline.DEFAULT, Pipeline.DEFAULT, 'conllu')\n",
        "   #print('Processing input...', file=sys.stderr)\n",
        "   lines = text.split('\\n')\n",
        "   tagged = []\n",
        "   for line in lines:\n",
        "# line = unify_sym(line.strip()) # здесь могла бы быть ваша функция очистки текста\n",
        "       output = process(process_pipeline, text=line)\n",
        "       tagged_line = ' '.join(output)\n",
        "       tagged.append(tagged_line)\n",
        "   return '\\n'.join(tagged)\n",
        "text = new_corpora[80000:100000]\n",
        "for sentence in text:\n",
        "   processed_text = tag_ud(text=sentence, modelfile=modelfile)\n",
        "   #print(processed_text[:350])\n",
        "   with open('my_text.txt', 'a', encoding='utf-8') as out:\n",
        "       out.write(processed_text + '\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGbS5w8jaE_r"
      },
      "source": [
        "import nltk"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "di7f3w9ZatJw"
      },
      "source": [
        "nltk.download('punkt')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EQO9mUQhkSre"
      },
      "source": [
        "new_corpora = open(\"my_text.txt\", encoding=\"UTF-8\", errors='ignore')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szLXqVvzaIg7"
      },
      "source": [
        "tokens=[]\n",
        "for sentence in new_corpora:\n",
        "  tokens.append(nltk.word_tokenize(sentence))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d0I63eV-eAeS"
      },
      "source": [
        "tokens[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-ml532Zfg9I1"
      },
      "source": [
        "law_corpora=[]\n",
        "for sentence in tokens:\n",
        "  for token in sentence:\n",
        "    if \"_суд_\" in token:\n",
        "      if sentence not in law_corpora:\n",
        "        law_corpora.append(sentence)\n",
        "    elif \"_судья_\" in token:\n",
        "      if sentence not in law_corpora:\n",
        "        law_corpora.append(sentence)\n",
        "    elif \"_адвокат_\" in token:\n",
        "      if sentence not in law_corpora:\n",
        "        law_corpora.append(sentence)\n",
        "    elif \"_прокурор_\" in token:\n",
        "      if sentence not in law_corpora:\n",
        "        law_corpora.append(sentence)\n",
        "    else:\n",
        "      pass\n",
        "print(len(law_corpora))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "80Rh5PVLh4JQ"
      },
      "source": [
        "law_corpora[0:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C3LdUA18kKI9"
      },
      "source": [
        "with open(\"law_corpora.txt\", \"w\") as file:\n",
        "  print(law_corpora, file=file, sep=\"\\n\")\n",
        "file.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E7J2KSMJJ2Lo"
      },
      "source": [
        "count=0\n",
        "for sentence in tokens:\n",
        "  count += len(sentence)\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EVDios2gKPKM"
      },
      "source": [
        "count=0\n",
        "for sentence in law_corpora:\n",
        "  count += len(sentence)\n",
        "print(count)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TEd9vRdqlG2T"
      },
      "source": [
        "len(tokens)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}